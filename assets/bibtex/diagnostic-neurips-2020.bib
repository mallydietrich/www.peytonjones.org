@inproceedings{wang2021results,
author = {Wang, Zichao and Lamb, Angus and Saveliev, Evgeny and Zaykov, Yordan and Cameron, Pashmina and Hernandez-Lobato,  Jose Miguel and Turner, Richard E. and Baraniuk,  Richard G. and Peyton Jones, Simon and Barton,  Craig and Woodhead,  Simon and Zhang, Cheng},
title = {Results and Insights from Diagnostic Questions: The NeurIPS 2020 Education Challenge},
booktitle = {NeurIPS Competition},
year = {2021},
month = {April},
abstract = {This competition concerns educational diagnostic questions, which are pedagogically effective, multiple-choice questions (MCQs) whose distractors embody misconceptions. With a large and ever-increasing number of such questions, it becomes overwhelming for teachers to know which questions are the best ones to use for their students. We thus seek to answer the following question: how can we use data on hundreds of millions of answers to MCQs to drive automatic personalized learning in large-scale learning scenarios where manual personalization is infeasible? Success in using MCQ data at scale helps build more intelligent, personalized learning platforms that ultimately improve the quality of education en masse. To this end, we introduce a new, large-scale, real-world dataset and formulate 4 data mining tasks on MCQs that mimic real learning scenarios and target various aspects of the above question in a competition setting at NeurIPS 2020. We report on our NeurIPS competition in which nearly 400 teams submitted approximately 4000 submissions, with encouragingly diverse and effective approaches to each of our tasks},
url = {https://www.microsoft.com/en-us/research/publication/results-and-insights-from-diagnostic-questions-the-neurips-2020-education-challenge/},
note = {To appear in PMLR proceeding of NeurIPS competition},
}