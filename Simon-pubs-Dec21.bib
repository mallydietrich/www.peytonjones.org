# Simon's publications at Dec 2021
# Dumped from Microsoft Research

@inproceedings{beale1981an,
author = {Beale, NCL and Peyton Jones, Simon},
title = {An Ada-compatible specification language},
booktitle = {Proc ACM conference},
year = {1981},
month = {January},
abstract = {This paper describes a notation for the formal specification of software packages. The main influences are the guarded commands of Dijkstra and the Algebraic Semantics of Guttag. However, a novel operator denoted by % is introduced, which allows algorithms to be abstracted in a specification, thereby creating a true specification language rather than another higher level language. The notation, called ADL/1, is designed to be used in conjunction with ADA but is equally suitable for other languages, and has been used for real time software written in Assembler and in a PASCAL-like language.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/an-ada-compatible-specification-language/},
pages = {139-143},
edition = {Proc ACM conference},
}
@inproceedings{peytonjones1982an,
author = {Peyton Jones, Simon},
title = {An investigation of the relative efficiencies of lambda expressions and combinators},
booktitle = {Proc ACM symposium on Lisp and functional programming},
year = {1982},
month = {August},
abstract = {In  "A new implementation for applicative languages" Turner uses combinators to implement lambda expressions.  This paper describes an experimental investigation of the efficiency of Turner's technique compared to more traditional reducers.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/an-investigation-of-the-relative-efficiencies-of-lambda-expressions-and-combinators/},
pages = {150-158},
edition = {Proc ACM symposium on Lisp and functional programming},
}
@article{peytonjones1985yacc,
author = {Peyton Jones, Simon},
title = {Yacc in Sasl — an Exercise in Functional Programming},
year = {1985},
month = {August},
abstract = {Among the advantages claimed for a purely functional programming style is ease of designing and implementing large programs. However, little experience of actually doing so has been gained so far. The experience of writing a particular medium sized program in a functional language is described here, with particular emphasis on the differences in programming style that were appropriate. This is compared with the experience of writing a very similar program in an imperative language. The main conclusions appear to be that the functional version was significantly easier to write, and was considerably smaller, though not by as large a factor as is sometimes claimed; that strong typing is, if anything, more desirable than in imperative systems; and that the question of debugging functional programs needs further research attention.},
url = {https://www.microsoft.com/en-us/research/publication/yacc-in-sasl-an-exercise-in-functional-programming/},
pages = {807-820},
journal = {Software—Practice & Experience},
volume = {15},
edition = {Software—Practice & Experience},
}
@article{peytonjones1986parsing,
author = {Peyton Jones, Simon},
title = {Parsing distfix operators},
year = {1986},
month = {February},
abstract = {The advantages of user-defined distfix operators – a syntactic convenience that enhances the readability of programs – can be obtained as an extension of almost any programming language without requiring dynamic changes to the parser.},
url = {https://www.microsoft.com/en-us/research/publication/parsing-distfix-operators/},
pages = {118-122},
journal = {Communications of the ACM},
volume = {29},
edition = {Communications of the ACM},
}
@book{peytonjones1987the,
author = {Peyton Jones, Simon},
title = {The Implementation of Functional Programming Languages},
year = {1987},
month = {January},
abstract = {My 1987 book is now out of print, but it is available here in its entirety in PDF form, in one of two formats:

 	single-page portrait
 	double-page landscape

Both are fully searchable, thanks to OCR and Norman Ramsey.

Errata

 	Section 5.2.4, p87.  We need an extra rule

match us [] E = E
This accounts for the possibility that in the constructor rule (Section 5.2.4) there may be some non-nullary constructors for which there are no equations.


 	P168, line 2, "VAR" should be "TVAR".},
publisher = {Prentice Hall},
url = {https://www.microsoft.com/en-us/research/publication/the-implementation-of-functional-programming-languages/},
}
@inproceedings{jones1987grip,
author = {Jones, SL Peyton and Clack, Chris and Salkild, Jon and Hardie, Mark and Peyton Jones, Simon},
title = {GRIP - a high-performance architecture for parallel graph reduction},
booktitle = {Proc IFIP conference on Functional Programming Languages and Computer Architecture, Portland},
year = {1987},
month = {September},
abstract = {GRIP is a high-performance parallel machine designed to execute functional programs using supercombinator graph reduction. It uses a high-bandwidth bus to provide access to a large, distributed shared memory, using intelligent memory units and packet-switching protocols to increase the number of processors which the bus can support. GRIP is also being programmed to support parallel Prolog and DACTL.
We outline GRIP’s architecture and firmware, discuss the major design issues, and describe the current state of the project and our plans for the future.},
publisher = {Springer Verlag LNCS 274},
url = {https://www.microsoft.com/en-us/research/publication/grip-a-high-performance-architecture-for-parallel-graph-reduction/},
pages = {98-112},
edition = {Proc IFIP conference on Functional Programming Languages and Computer Architecture, Portland},
}
@inproceedings{jones1988functional,
author = {Jones, SL Peyton and Clack, Chris and Salkild, Jon and Hardie, Mark and Peyton Jones, Simon},
title = {Functional programming on the GRIP multiprocessor},
booktitle = {IEE Seminar on Digital Parallel Processors, Lisbon, Portugal},
year = {1988},
month = {January},
abstract = {Most MIMD computer architectures can be classified as tightly-coupled or loosely-coupled, depending on the relative latencies seen by a processor accessing different parts of its address space. By adding microprogrammable functionality to the memory units, the authors have developed a MIMD computer architecture which explores the middle region of this spectrum. This has resulted in an unusual and flexible bus-based multiprocessor, which is being used as a base for research in parallel functional programming languages. The authors introduce parallel functional programming, and describe the architecture of the GRIP multiprocessor},
publisher = {IEE},
url = {https://www.microsoft.com/en-us/research/publication/functional-programming-on-the-grip-multiprocessor/},
edition = {IEE Seminar on Digital Parallel Processors, Lisbon, Portugal},
}
@article{jones1989parallel,
author = {Jones, SL Peyton and Peyton Jones, Simon},
title = {Parallel implementations of functional programming languages},
year = {1989},
month = {April},
abstract = {One of the most attractive features of functional programming languages is their suitability for programming parallel computers. This paper is devoted to discussion of such a claim. Firstly, parallel functional programming is discussed from the programmer's point of view. Secondly, since most parallel functional language implementations are based on the concept of graph reduction, the issues raised by graph reduction are discussed. Finally, the paper concludes with a case study of a particular parallel graph reduction machine and a survey of other parallel architectures.},
url = {https://www.microsoft.com/en-us/research/publication/parallel-implementations-of-functional-programming-languages/},
pages = {175-186},
journal = {Computer Journal},
volume = {32},
edition = {Computer Journal},
number = {2},
}
@inproceedings{jones1989high-performance,
author = {Jones, SL Peyton and Clack, C and Salkild, J and Peyton Jones, Simon},
title = {High-performance parallel graph reduction},
booktitle = {Proc Parallel Architectures and Languages Europe (PARLE), Lecture notes in Computer Science},
year = {1989},
month = {June},
abstract = {Parallel graph reduction is an attractive implementation for functional programming languages because of its simplicity and inherently distributed nature. This paper outlines some of the issues raised by parallel compiled graph reduction, and presents the approach we have adopted for our parallel machine, GRIP.



We concentrate on two main areas:


 	
Static and dynamic techniques to control the growth of parallelism, so as to provide enough parallelism of an appropriate granularity to keep the machine busy without swamping it.

 	
Dynamic techniques to exploit the memory hierarchy, so that frequently-referenced data is held near to the processor that references it.},
publisher = {Springer Verlag},
url = {https://www.microsoft.com/en-us/research/publication/high-performance-parallel-graph-reduction/},
pages = {193-206},
volume = {365},
edition = {Proc Parallel Architectures and Languages Europe (PARLE), Lecture notes in Computer Science},
}
@inproceedings{jones1991unboxed,
author = {Jones, SL Peyton and Launchbury, J and Peyton Jones, Simon},
title = {Unboxed values as first class citizens},
series = {Lecture Notes in Computer Science},
booktitle = {ACM Conference on Functional Programming and Computer Architecture (FPCA'91)},
year = {1991},
month = {January},
abstract = {The code compiled from a non-strict functional program usually manipulates heap- allocated boxed numbers. Compilers for such languages often go to considerable trouble to optimise operations on boxed numbers into simpler operations on their unboxed forms. These optimisations are usually handled in an ad hoc manner in the code generator, because earlier phases of the compiler have no way to talk about unboxed values.
We present a new approach, which makes unboxed values into (nearly) first-class citizens. The language, including its type system, is extended to handle unboxed values. The optimisation of boxing and unboxing operations can now be reinterpreted as a set of correctness-preserving program transformations. Indeed the particular transformations required are ones which a compiler would want to implement anyway. The compiler becomes both simpler and more modular.
Two other benefits accrue. Firstly, the results of strictness analysis can be exploited within the same uniform transformational framework. Secondly, new algebraic data types with unboxed components can be declared. Values of these types can be manipulated much more efficiently than the corresponding boxed versions. Both a static and a dynamic semantics are given for the augmented language. The denotational dynamic semantics is notable for its use of unpointed domains.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/unboxed-values-as-first-class-citizens/},
pages = {636-666},
volume = {523},
edition = {ACM Conference on Functional Programming and Computer Architecture (FPCA'91)},
}
@article{jones1991a,
author = {Jones, SL Peyton and Lester, D and Peyton Jones, Simon},
title = {A modular fully-lazy lambda lifter in Haskell},
year = {1991},
month = {May},
abstract = {An important step in many compilers for functional languages is lambda lifting. In this thesis, Hughes showed that by doing lambda lifting in a particular way, a useful property called full laziness can be preserved (Hughes [1983]). Full laziness has been seen as intertwined with lambda lifting ever since. We show that, on the contrary, full laziness can be regarded as a completely separate process to lambda lifting, thus making it easy to use different lambda lifters following a full-laziness transformation, or to use the full-laziness transformation in compilers which do not require lambda lifting. On the way, we present the complete code for our modular fully-lazy lambda lifter, written in the Haskell function programming language.},
publisher = {Wiley},
url = {https://www.microsoft.com/en-us/research/publication/a-modular-fully-lazy-lambda-lifter-in-haskell/},
pages = {479-506},
journal = {Software Practice and Experience},
volume = {21},
number = {5},
}
@inproceedings{akerholt1991a,
author = {Akerholt, G and Hammond, K and Jones, SL Peyton and Trinder, P and Peyton Jones, Simon},
title = {A parallel functional database on GRIP},
booktitle = {Proc Workshop on the Parallel Implementation of Functional Languages, Southampton},
year = {1991},
month = {June},
abstract = {GRIP is a shared-memory multiprocessor designed for efficient parallel evaluation of functional languages, using compiled graph reduction. This paper investigates the feasibility of processing persistent data on GRIP, and presents results obtained from a pilot implementation. A database implemented in a pure functional language must be modified non-destructively, i.e. the original database must be preserved and a new copy constructed. The naive implementation provides evidence for the feasibility of data processing in the form of modest real-time speed-ups, and acceptable real-time performance. The functional database is also used to investigate the GRIP architecture, compared with an idealised machine. The particular features investigated are the thread-creation costs and caching of GRIP’s distributed memory.},
url = {https://www.microsoft.com/en-us/research/publication/a-parallel-functional-database-grip/},
pages = {9-29},
edition = {Proc Workshop on the Parallel Implementation of Functional Languages, Southampton},
note = {CSTR 91-07, Department of Computer Science, University of Southampton},
}
@inproceedings{hammond1991profiling,
author = {Hammond, K and Jones, SL Peyton and Peyton Jones, Simon},
title = {Profiling scheduling strategies on the GRIP parallel reducer},
booktitle = {Proc 1992 Workshop on Parallel Implementations of Functional Languages, Aachen},
year = {1991},
month = {August},
abstract = {It is widely claimed that functional languages are particularly suitable for programming parallel computers. A claimed advantage is that the programmer is not burdened with details of task creation, placement, scheduling, and synchronisation, these decisions being taken by the system instead. Leaving aside the question of whether a pure functional language is expressive enough to encompass all the parallel algorithms we might wish to program, there remains the question of how effectively the compiler and run-time system map the program onto a real parallel system, a task usually carried out mostly by the programmer. This is the question we address in this paper.

We first introduce the system architecture of GRIP, a shared-memory parallel machine supporting an implementation of the functional language Haskell. GRIP executes functional programs in parallel using compiled supercombinator graph reduction, a form of declarative rule system.

We then describe several strategies for run-time resource control which we have tried, presenting comprehensive measurements of their effectiveness. We are particularly concerned with strategies controlling task creation, in order to improve task granularity and minimise communication overheads. This is, so far as we know, one of the first attempts to make a systematic study of task-control strategies in a high-performance parallel functional-language system. GRIP's high absolute performance render these results credible for real applications.},
url = {https://www.microsoft.com/en-us/research/publication/profiling-scheduling-strategies-on-the-grip-parallel-reducer/},
edition = {Proc 1992 Workshop on Parallel Implementations of Functional Languages, Aachen},
}
@book{jones1992implementing,
author = {Jones, SL Peyton and Lester, DR and Peyton Jones, Simon},
title = {Implementing functional languages: a tutorial},
booktitle = {Implementing functional languages: a tutorial},
year = {1992},
month = {January},
abstract = {This book gives a practical approach to understanding implementations of non-strict functional languages using lazy graph reduction. The book is intended to be a source of practical labwork material, to help make functional-language implementations `come alive', by helping the reader to develop, modify and experiment with some non-trivial compilers.

The unusual aspect of the book is that it is meant to be executed as well as read. Rather than merely presenting an abstract description of each implementation technique, we present the code for a complete working prototype of each major method, and then work through a series of improvements to it. All of the code is available in machine-readable form.
Overview of the book
The principal content of the book is a series of implementations of a small functional language called the Core language. The Core language is designed to be as small as possible, so that it is easy to implement, but still rich enough to allow modern non-strict functional languages to be translated into it without losing efficiency. It is described in detail in Chapter 1, in which we also develop a parser and pretty-printer for the Core language.

Appendix B contains a selection of Core-language programs for use as test programs thoughout the book.

The main body of the book consists of four distinct implementations of the Core language.

 	Chapter 2 describes the most direct implementation, based on template instantiation.
 	Chapter 3 introduces the G-machine, and shows how to compile the program to sequences of instructions (G-code) which can be further translated to machine code.
 	Chapter 4 repeats the same exercise for a different abstract machine, the Three Instruction Machine (TIM), whose evaluation model is very different from that of the G-machine. The TIM was developed more recently than the G-machine, so there is much less other literature about it. Chapter 4 therefore contains a rather more detailed development of the TIM's evaluation model than that given for the G-machine.
 	Finally, Chapter 5 adds a new dimension by showing how to compile functional programs for a parallel G-machine.

For each of these implementations we discuss two main parts, the compiler and the machine interpreter. The compiler takes a Core-language program and translates it into a form suitable for execution by the machine interpreter.

The machine interpreter simulates the execution of the compiled program. In each case the interpreter is modelled as a state transition system so that there is a very clear connection between the machine interpreter and a `real' implementation.

One important way in which the Core language is restrictive is in its lack of local function definitions. There is a well-known transformation, called lambda lifting, which turns local function definitions into global ones, thus enabling local function definitions to be written freely and transformed out later. In Chapter 6 we develop a suitable lambda lifter. This chapter is more than just a re-presentation of standard material. Full laziness is a property of functional programs which had previously been seen as inseparable from lambda lifting. In Chapter 6 we show that they are in fact quite distinct, and show how to implement full laziness in a separate pass from lambda lifting.
Typographical errors
Here are some typographical errors, spotted by various readers. Page numbers refer to the online versions (which differ from the printed version).

 	Page 128, second to last paragraph of section 3.7, first sentence. "addis" should be "is a".
 	Page 134, the code for i'. The "n" under the big brace symbol should say "n pairs".
 	Page 135. Equation 3.36 should have "NConstr", not "Constr".
 	Page 230, second paragraph. "There one final gloss..." should be "There is one final gloss...".
 	Page 278, the definition of nfib. Replace "n==0" by "n<=1".

Now, alas, out of print. However the full text of the book is available above. You can order a nicely-bound copy from http://www.cafepress.com/haskell_books. Thanks to John Meacham for setting this up.

There is also a tutor's guide available.

 },
publisher = {Prentice Hall},
url = {https://www.microsoft.com/en-us/research/publication/implementing-functional-languages-a-tutorial/},
}
@unpublished{jones1992a,
author = {Jones, SL Peyton and Wadler, PL and Peyton Jones, Simon},
title = {A static semantics for Haskell},
year = {1992},
month = {February},
abstract = {This apper gives a static semantics for a large subset of Haskell, including giving a translations into a language without overloading.

It is our intention to cover the complete language in due course.

One innovative aspect is the use of ideas from the second-order lambda calculus to record type information in the program.},
url = {https://www.microsoft.com/en-us/research/publication/a-static-semantics-for-haskell/},
}
@misc{peytonjones1992profiling,
author = {Peyton Jones, Simon},
title = {Profiling Lazy Functional Languages Working Paper},
year = {1992},
month = {May},
abstract = {Profiling tools, which measure and display the dynamic space and time behaviour of programs, are essential for identifying execution bottlenecks. A variety of such tools exist for conventional languages, but almost none for non-strict functional languages. There is a good reason for this: lazy evaluation means that the program is executed in an order which is not immediately apparent from the source code, so it is difficult to relate dynamically-gathered statistics back to the original source.
We present a new technique which solves this problem. The framework is general enough to prole both space and time behaviour. Better still, it is cheap to implement, and we describe how to do so in the context of the Spineless Tagless G-machine.},
url = {https://www.microsoft.com/en-us/research/publication/profiling-lazy-functional-languages-working-paper/},
}
@article{jones1992implementing,
author = {Jones, Peyton and L, Simon and Peyton Jones, Simon},
title = {Implementing Lazy Functional Languages on Stock Hardware: The Spineless Tagless G-machine},
year = {1992},
month = {July},
abstract = {The Spineless Tagless G-machine is an abstract machine designed to support non- strict higher-order functional languages. This presentation of the machine falls into three parts. Firstly, we give a general discussion of the design issues involved in implementing non-strict functional languages.
Next, we present the STG language, an austere but recognisably-functional language, which as well as a denotational meaning has a well-defined operational semantics. The STG language is the \abstract machine code" for the Spineless Tagless G-machine.
Lastly, we discuss the mapping of the STG language onto stock hardware. The success of an abstract machine model depends largely on how efficient this mapping can be made, though this topic is often relegated to a short section. Instead, we give a detailed discussion of the design issues and the choices we have made. Our principal target is the C language, treating the C compiler as a portable assembler.},
publisher = {Cambridge University Press},
url = {https://www.microsoft.com/en-us/research/publication/implementing-lazy-functional-languages-on-stock-hardware-the-spineless-tagless-g-machine/},
pages = {127-202},
journal = {Journal of Functional Programming},
volume = {2},
edition = {Journal of Functional Programming},
}
@inproceedings{peytonjones1993imperative,
author = {Peyton Jones, Simon and Wadler, PL},
title = {Imperative functional programming},
booktitle = {20th ACM Symposium on Principles of Programming Languages (POPL'93)},
year = {1993},
month = {January},
abstract = {We present a new model, based on monads, for performing input/output in a non-strict, purely functional language. It is composable, extensible, efficient, requires no extensions to the type system, and extends smoothly to incorporate mixed-language working and in-place array updates.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/imperative-functional-programming/},
pages = {71-84},
edition = {20th ACM Symposium on Principles of Programming Languages (POPL'93)},
note = {POPL 2003: ten-year most-influential paper award},
}
@inproceedings{gill1993a,
author = {Gill, A and Launchbury, J and Jones, SL Peyton and Peyton Jones, Simon},
title = {A short cut to deforestation},
booktitle = {ACM Conference on Functional Programming and Computer Architecture (FPCA'93)},
year = {1993},
month = {January},
abstract = {Lists are often used as "glue" to connect separate parts of a program together. We propose an automatic technique for improving the efficiency of such programs, by removing many of these intermediate lists, based on a single, simple, local transformation. We have implemented the method in the Glasgow Haskell compiler.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/a-short-cut-to-deforestation/},
pages = {223-232},
edition = {ACM Conference on Functional Programming and Computer Architecture (FPCA'93)},
note = {ISBN 0-89791-595-X},
}
@misc{sansom1993generational,
author = {Sansom, PM and Jones, SL Peyton and Peyton Jones, Simon},
title = {Generational garbage collection for Haskell},
year = {1993},
month = {January},
abstract = {This paper examines the use of generational garbage collection techniques for a lazy implementation of a non-strict functional language. Detailed measurements which demonstrate that a generational garbage collector can substantially out-perform non-generational collectors, despite the frequency of write operations in the underlying implementation, are presented.

Our measurements are taken from a state-of-the-art compiled implementation for Haskell, running substantial benchmark programs. We make measurements of dynamic properties (such as object lifetimes) which affect generational collectors, study their interaction with a simple generational scheme, make direct performance comparisons with simpler collectors, and quantify the interaction with a paging system.

The generational collector is demonstrably superior. At least for our benchmarks, it reduces the net storage management overhead, and it allows larger programs to be run on a given machine before thrashing ensues.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/generational-garbage-collection-for-haskell/},
pages = {106-116},
edition = {ACM Conference on Functional Programming and Computer Architecture (FPCA'93)},
note = {ACM Conference on Functional Programming and Computer Architecture (FPCA'93)},
}
@misc{peytonjones1993measuring,
author = {Peyton Jones, Simon and Partain, Will},
title = {Measuring the effectiveness of a simple strictness analyser},
series = {Workshops in Computing},
year = {1993},
month = {January},
abstract = {We describe a simple strictness analyser for purely-functional programs, who how its results are used to improve programs, and provide measurements of the effects of these improvements. These measurements are given both in terms of overall run-time, and in terms of internal operations such as allocations, updates, etc. Despite its simplicity, the analyser handles higher-order functions, and non-flat domains provided they are non-recursive.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/measuring-the-effectiveness-of-a-simple-strictness-analyser/},
pages = {201-220},
edition = {Functional Programming, Glasgow 1993},
note = {Functional Programming, Glasgow 1993},
}
@inproceedings{jones1993the,
author = {Jones, SL Peyton and Hammond, K and Partain, WD and Wadler, PL and Hall, CV and Peyton Jones, Simon},
title = {The Glasgow Haskell Compiler: a technical overview},
booktitle = {Proceedings of Joint Framework for Information Technology Technical Conference, Keele},
year = {1993},
month = {March},
abstract = {We give an overview of the Glasgow Haskell compiler, focusing especially on way in which we have been able to exploit the rich theory of functional languages to give very practical improvements in the compiler.

The compiler is portable, modular, generates good code, and is freely available.},
publisher = {DTI/SERC},
url = {https://www.microsoft.com/en-us/research/publication/the-glasgow-haskell-compiler-a-technical-overview/},
pages = {249-257},
edition = {Proceedings of Joint Framework for Information Technology Technical Conference, Keele},
}
@inbook{akerholt1993processing,
author = {Akerholt, G and Hammond, K and Trinder, P and Jones, SL Peyton and Peyton Jones, Simon},
title = {Processing transactions on GRIP, a parallel graph reducer},
booktitle = {Proc Parallel Architectures and Languages Europe (PARLE), Munich},
year = {1993},
month = {June},
abstract = {The GRIP architecture allows efficient execution of functional programs on a multi-processor built from standard hardware components. State-of-the-art compilation techniques are combined with sophisticated runtime resource-control to give good parallel performance. This paper reports the results of running GRIP on an application which is apparently unsuited to the basic functional model: a database transaction manager incorporating updates as well as lookup transactions. The results obtained show good relative speedups for GRIP, with real performance advantages over the same application executing on sequential machines.},
url = {https://www.microsoft.com/en-us/research/publication/processing-transactions-on-grip-a-parallel-graph-reducer/},
pages = {634-647},
edition = {Proc Parallel Architectures and Languages Europe (PARLE), Munich},
}
@article{peytonjones1993how,
author = {Peyton Jones, Simon},
title = {How to give a good research talk},
year = {1993},
month = {November},
abstract = {Giving a good research talk is not easy. We try to identify some things which we have found helpful, in the hope that they may be useful to you.},
url = {https://www.microsoft.com/en-us/research/publication/how-to-give-a-good-research-talk/},
pages = {9-12},
journal = {SIGPLAN Notices},
volume = {28},
edition = {SIGPLAN Notices},
number = {11},
}
@inproceedings{hammond1994type,
author = {Hammond, K and Jones, SL Peyton and Wadler, PL and Hall, CV and Peyton Jones, Simon},
title = {Type classes in Haskell},
booktitle = {ACM Transactions on Programming Languages and Systems, European Symposium on Programming (ESOP'94)},
year = {1994},
month = {April},
abstract = {This paper defines a set of type inference rules for resolving overloading introducted by type classes. Programs including type classes are transformed into ones which may be typed by the Hindley-Milner inference rules. In contrast to an other work on type classes, the rules presented here relate directly to user programs. An innovative aspect of this work in the use of second-order lambda calculus to record type information in the program.},
publisher = {Springer Verlag LNCS 788},
url = {https://www.microsoft.com/en-us/research/publication/type-classes-in-haskell/},
pages = {241-256},
volume = {18},
edition = {ACM Transactions on Programming Languages and Systems, European Symposium on Programming (ESOP'94)},
}
@inproceedings{launchbury1994lazy,
author = {Launchbury, J and Jones, SL Peyton and Peyton Jones, Simon},
title = {Lazy functional state threads},
booktitle = {ACM Conference on Programming Languages Design and Implementation, Orlando (PLDI'94)},
year = {1994},
month = {June},
abstract = {Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a non-strict, purely-functional language.

The security of the encapsulation is assured by the type system, using parametricity. Intriguingly, this parametricity requires the provision of a (single) constant with a rank-2 polymorphic type.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/lazy-functional-state-threads/},
pages = {24-35},
edition = {ACM Conference on Programming Languages Design and Implementation, Orlando (PLDI'94)},
}
@inproceedings{sansom1995time,
author = {Sansom, PM and Jones, SL Peyton and Peyton Jones, Simon},
title = {Time and space profiling for non-strict, higher-order functional languages},
booktitle = {22nd ACM Symposium on Principles of Programming Languages (POPL'95)},
year = {1995},
month = {January},
abstract = {We present the first profiler for a compiled, non-strict, higher-order, purely functional language capable of measuring time as well as space usage. Our profiler is implemented in a production-quality optimising compiler for Haskell, has low overheads, and can successfully profile large applications.A unique feature of our approach is that we give a formal specification of the attribution of execution costs to cost centres. This specification enables us to discuss our design decisions in a precise framework. Since it is not obvious how to map this specification onto a particular implementation, we also present an implementation-oriented operational semantics, and prove it equivalent to the specification.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/time-and-space-profiling-for-non-strict-higher-order-functional-languages-2/},
pages = {355-366},
edition = {22nd ACM Symposium on Principles of Programming Languages (POPL'95)},
}
@inproceedings{sansom1995time,
author = {Sansom, Patrick M. and Peyton Jones, Simon},
title = {Time and space profiling for non-strict higher-order functional languages},
booktitle = {22nd ACM Symposium on Principles of Programming Languages (POPL'95)},
year = {1995},
month = {January},
abstract = {We present the first profiler for a compiled, non-strict, higher-order, purely functional language capable of measuring time as well as space usage. Our profiler is implemented in a production-quality optimising compiler for Haskell, has low overheads, and can successfully profile large applications.
A unique feature of our approach is that we give a formal specification of the attribution of execution costs to cost centres. This specification enables us to discuss our design decisions in a precise framework. Since it is not obvious how to map this specification onto a particular implementation, we also present an implementation-oriented operational semantics, and prove it equivalent to the specification.},
url = {https://www.microsoft.com/en-us/research/publication/time-space-profiling-non-strict-functional-languages/},
pages = {355-366},
edition = {22nd ACM Symposium on Principles of Programming Languages (POPL'95)},
}
@inproceedings{finne1995composing,
author = {Finne, S. and Peyton Jones, Simon},
title = {Composing Haggis},
booktitle = {Proc 5th Eurographics Workshop on Programming Paradigms in Graphics, Maastricht},
year = {1995},
month = {September},
abstract = {Haggis is a purely-functional, multi-threaded user interface framework for composing interactive applications. It provides a compositional view of the world of user interface applications, applying to all aspects of the interface the principle of building a component from parts. Interactive components are viewed as virtual I/O devices that are composed together to make up complete applications. To fully support this style of programming, Haggis makes good use of the integral an extensible, modular and simple programming model for writing user interface applications at a high level of abstraction.

Two key ingredients that Haggis relies on to provide its compositional style are concurrency and monads, making it possible to write multi-threaded functional programs that interact with the Real World comfortably.},
publisher = {Eurographics},
url = {https://www.microsoft.com/en-us/research/publication/composing-haggis/},
edition = {Proc 5th Eurographics Workshop on Programming Paradigms in Graphics, Maastricht},
}
@article{launchbury1995state,
author = {Launchbury, John and Peyton Jones, Simon},
title = {State in Haskell},
year = {1995},
month = {December},
abstract = {Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a nonstrict, purely functional language. The security of the encapsulation is assured by the type system, using parametricity. The same framework is also used to handle input/output operations (state changes on the external world) and calls to C.},
publisher = {Kluwer Academic},
url = {https://www.microsoft.com/en-us/research/publication/state-in-haskell/},
pages = {293-342},
journal = {Lisp and Symbolic Computation},
}
@inproceedings{peytonjones1996concurrent,
author = {Peyton Jones, Simon and Gordon, Andy and Finne, Sigbjorn},
title = {Concurrent Haskell},
booktitle = {POPL '96 Proceedings of the 23rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {1996},
month = {January},
abstract = {Some applications are most easily expressed in a programming language that supports concurrency, notably interactive and distributed systems. We propose extensions to the purely-functional language Haskell that allow it to express explicitly concurrent applications; we call the resulting language Concurrent Haskell. The resulting system appears to be both expressive and efficient, and we give a number of examples of useful abstractions that can be built from our primitives. We have developed a freely-available implementation of Concurrent Haskell, and are now using it as a substrate for a graphical user interface toolkit.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/concurrent-haskell/},
pages = {295-308},
edition = {POPL '96 Proceedings of the 23rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
}
@inproceedings{finne1996pictures,
author = {Finne, Sigbjorn and Peyton Jones, Simon},
title = {Pictures: A Structured Graphics Model},
year = {1996},
month = {January},
abstract = {We present a simple, device independent model for describing two dimensional raphics using a functional language. Graphical scenes or pictures are represented as values that functions can manipulate and inspect to create new values. Complete pictures are constructed by repeatedly composing such picture values together using picture combinators. A novel aspect of the model presented is its use of structured translation to abstractly express the geometric composition of arbitrary pictures. The structured graphics model presented has been implemented in Haskell, and we also give an overview of a general rendering framework for traversing a picture value. Applications of this renderer include both output to various graphical systems, testing for picking or selection of a picture and the computation of the bounding box of an arbitrary picture. The graphics model forms the basis for all graphical output in a user interface framework being developed in Haskell.},
publisher = {Springer-Verlag},
url = {https://www.microsoft.com/en-us/research/publication/pictures-a-structured-graphics-model/},
}
@inbook{peytonjones1996compiling,
author = {Peyton Jones, Simon},
title = {Compiling Haskell by Program Transformation: A Report from the Trenches},
booktitle = {Proceedings European Symposium on Programming (ESOP'96)},
year = {1996},
month = {January},
abstract = {Many compilers do some of their work by means of correctness-preserving, and hopefully performance-improving, program transformations. The Glasgow Haskell Compiler (GHC) takes this idea of "compilation by transformation" as its war-cry, trying to express as much as possible of the compilation process in the form of program transformations.

This paper reports on our practical experience of the transformational approach to compilation, in the context of a substantial compiler.


See "A transformation-based optimiser for Haskell" (SCP 1997) for a journal version of this paper.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/compiling-haskell-by-program-transformation-a-report-from-the-trenches/},
volume = {1058},
edition = {Lecture Notes in Computer Science},
}
@misc{partain1996let-floating,
author = {Partain, WD and Santos, A and Peyton Jones, Simon},
title = {Let-floating: moving bindings to give faster programs},
year = {1996},
month = {May},
abstract = {Virtually every compiler performs transformations on the program it is compiling in an attempt to improve efficiency. Despite their importance, however, there have been few systematic attempts to categorise such transformations and measure their impact. In this paper we describe a particular group of transformations - the "let-floating" transformations - and give detailed measurements of their effect in an optimising compiler for the non-strict functional language Haskell. Let-floating has not received much explicit attention in the past, but our measurements show that it is an important group of transformations (at least for lazy languages), offering a reduction of more than 30% in heap allocation and 15% in execution time.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/},
edition = {ACM SIGPLAN International Conference on Functional Programming (ICFP'96)},
note = {ACM SIGPLAN International Conference on Functional Programming (ICFP'96)},
}
@misc{trinder1996gum,
author = {Trinder, PW and Hammond, K and Mattson, JS and Partridge, AS and Peyton Jones, Simon},
title = {GUM: a portable parallel implementation of Haskell},
year = {1996},
month = {May},
abstract = {GUM is portable, parallel implementation of the Haskell functional language which has been publicly released with version 0.26 of the Glasgow Haskell Compiler (GHC). GUM is message-based, and portability is facilitated by using the PVM communications-harness available on most multi-processors, including shared-memory and distributed-memory machines. For example GUM is available by FTP for a Sun SPARCserver multiprocessor and for a networks of Sun SPARC workstations.

High message-latency in distributed machines is ameliorated by sending messages asynchronously, and by sending large packets of related data in each message. Initial performance figures demonstrate absolute speedups relative to the best sequential compiler technology. To improve the performance of a parallel Haskell program GUM provides tools for monitoring and visualising the behaviour of threads and of PEs during execution.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/gum-a-portable-parallel-implementation-of-haskell/},
edition = {ACM Conference on Programming Languages Design and Implementation (PLDI'96)},
note = {ACM Conference on Programming Languages Design and Implementation (PLDI'96)},
}
@inproceedings{finne1996pictures,
author = {Finne, SO and Jones, SL Peyton and Peyton Jones, Simon},
title = {Pictures: A Simple Structured Graphics Model},
series = {Workshops in Computing},
booktitle = {Proc Glasgow Functional Programming Workshop},
year = {1996},
month = {July},
abstract = {We present in this paper a simple, device-independent model for describing two-dimensional graphics using a functional language. Graphical scenes, or pictures, are represented as values that functions can manipulate and inspect to create new values. Complete pictures are constructed by repeatedly composing such picture values together using picture combinators. A novel aspect of the model presented is its use of structured translation to abstractly express the geometric composition of arbitrary pictures.
The structured graphics model presented has been implemented in Haskell, and we also give an overview of a general rendering framework for traversing a picture value. Applications of this renderer include both output to various graphical systems, testing for picking or selection of a picture and the computation of the bounding box of an arbitrary picture. The graphics model forms the basis for all graphical output in a user interface framework being developed in Haskell.},
url = {https://www.microsoft.com/en-us/research/publication/pictures-a-simple-structured-graphics-model/},
edition = {Proc Glasgow Functional Programming Workshop},
}
@inproceedings{jones1996bulk,
author = {Jones, SL Peyton and Peyton Jones, Simon},
title = {Bulk types with class},
booktitle = {Electronic proceedings of the 1996 Glasgow Functional Programming Workshop},
year = {1996},
month = {September},
abstract = {Bulk types - such as lists, bags, ets, finite maps, and priority queues - are ubiquitous in programming. Yet many languages don't support them well, even though they have received a great deeal of attention, especially from the database community. Haskell is currently among the culprits.

This paper has two aims: to identify some of the technical difficulties, and to attempt to address them using Haskell's constructor classes.},
url = {https://www.microsoft.com/en-us/research/publication/bulk-types-with-class/},
edition = {Electronic proceedings of the 1996 Glasgow Functional Programming Workshop},
}
@inproceedings{nicklisch1996an,
author = {Nicklisch, Jan and Peyton Jones, Simon},
title = {An Exploration of Modular Programs},
booktitle = {The Glasgow Workshop on Functional Programming, 1996},
year = {1996},
month = {October},
abstract = {Recently, Mark Jones introduced first class structures as a means to express modular structure. In this paper we elaborate on this idea by comparing the module systems of Standard ML and Haskell 1.3, widely used functional languages, and a Haskell variant equipped with such first class structures. Moreover, we look at another obvious and well-known extension to Hindley-Milner type systems, namely higher order type variables, to explore its usefulness in solving problems occuring when one attempts to structure larger programs into maintainable pieces. We argue that there are surprisingly few applications where the module system currently provided by Haskell cannot keep pace iwth Standard ML's expressiveness. when one adds first class structures to Haskell, the module system reaches the expressiveness of Standard ML and even exceeds it.},
url = {https://www.microsoft.com/en-us/research/publication/an-exploration-of-modular-programs/},
edition = {The Glasgow Workshop on Functional Programming, 1996},
}
@inproceedings{oliva1997c-,
author = {Oliva, Dino and Nordin, T. and Peyton Jones, Simon},
title = {C-: A Portable Assembly Language},
series = {LNCS},
booktitle = {Proceedings of the 1997 Workshop on Implementing Functional Languages},
year = {1997},
month = {January},
abstract = {Of late it has become very common for resarch compilerrs to emit C as their target code, relying on a C compiler to generate machine code. In effect, C is being used as a portable compiler target language. It offers a simple and effective way of avoiding the need to re-implement effective register allocation, instruction selection, and instruction scheduling, and so on, all for a variety of target architectures. The trouble is that C was designed as a programming language not as a compiler target language, and is not very suitable for the latter purpose. The obvious thing to do is to define a language that is designed as a portable target language. This describes C–, a portable compiler target language, or assembler. C– has to strike a balance between being high-level enough to allow the back end a fair crack of the whip, while being low level enough to give the front end the control it needs. It is not clear that a path exists between these two rocks; the ghost of UNCOL lurks ominously in the shadows. Yet the increasing popularity of C as a compiler target language (despite its unsuitability) suggests strong demand, and provides an existence proof that something useful can be done.},
publisher = {Springer Verlag},
url = {https://www.microsoft.com/en-us/research/publication/c-a-portable-assembly-language/},
pages = {1–19},
volume = {1467},
edition = {Proceedings of the 1997 Workshop on Implementing Functional Languages},
}
@article{sansom1997formally-based,
author = {Sansom, Patrick M. and Peyton Jones, Simon},
title = {Formally-Based Profiling for Higher-Order Functional Languages},
year = {1997},
month = {February},
abstract = {We present the first source-level profiler for a compiled, nonstrict, higher-order, purely functional language capable of measuring time as well as space usage. Our profiler is implemented in a production-quality optimizing compiler for Haskell and can successfully profile large applications. A unique feature of our approach is that we give a formal specification of the attribution of execution costs to cost centers. This specification enables us to discuss our design decisions in a precise framework, prove properties about the attribution of costs, and examine the effects of different program transformations on the attribution of costs. Since it is not obvious how to map this specification onto a particular implementation, we also present an implementation-oriented operational semantics, and prove it equivalent to the specification.},
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/formally-based-profiling-for-higher-order-functional-languages/},
journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
volume = {19},
number = {2},
}
@inproceedings{peytonjones1997type,
author = {Peyton Jones, Simon and Jones, Mark and Meijer, Erik},
title = {Type classes: an exploration of the design space},
booktitle = {Haskell workshop},
year = {1997},
month = {January},
abstract = {When type classes were first introduced in Haskell they were regarded as a fairly experimental language feature, and therefore warranted a fairly conservative design. Since that time, practical experience has convinced many programmers of the benefits and convenience of type classes. However, on occasion, these same programmers have discovered examples where seemingly natural applications for type class overloading are prevented by the restrictions imposed by the Haskell design.

It is possible to extend the type class mechanism of Haskell in various ways to overcome these limitations, but such proposals must be designed with great care. For example, several different extensions have been implemented in Gofer. Some of these, particularly the support for multi-parameter classes, have proved to be very useful, but interactions between other aspects of the design have resulted in a type system that is both unsound and undecidable. Another illustration is the introduction of constructor classes in Haskell 1.3, which came without the proper generalization of the notion of a context. As a consequence, certain quite reasonable programs are not typable.

In this paper we review the rationale behind the design of Haskell's class system, we identify some of the weaknesses in the current situation, and we explain the choices that we face in attempting to remove them.},
url = {https://www.microsoft.com/en-us/research/publication/type-classes-an-exploration-of-the-design-space/},
edition = {Haskell workshop},
}
@misc{peytonjones1997declarative,
author = {Peyton Jones, Simon},
title = {Declarative Systems Architecture: A Quantitative Approach (AQUA)},
year = {1997},
month = {January},
abstract = {This report summarises the achievements of AQUA project which ran from February 1993 to 1996.


The goal of the project was "to begin the quantitative feedback process in the field of declarative systems architecture". Specifically, the project concerned "compilers and runtime resource management for non-strict functional languages such as Haskell, on both sequential and parallel platforms".

 

A secondary, but important, goal articulated in the proposal was to contribute to the maturing of functional programming languages, helping to move them from the laboratory and into the hands of users.},
url = {https://www.microsoft.com/en-us/research/publication/declarative-systems-architecture-a-quantitative-approach-aqua/},
}
@inproceedings{nordin1997green,
author = {Nordin, T and Jones, SL Peyton and Reid, Alastair and Peyton Jones, Simon},
title = {Green Card: a foreign-language interface for Haskell},
booktitle = {Haskell workshop},
year = {1997},
month = {February},
abstract = {No abstract available.},
url = {https://www.microsoft.com/en-us/research/publication/green-card-a-foreign-language-interface-for-haskell/},
edition = {Haskell workshop},
}
@inbook{meijer1997henk,
author = {Meijer, E and Peyton Jones, Simon},
title = {Henk: a typed intermediate language},
booktitle = {Types in Compilation},
year = {1997},
month = {May},
abstract = {There is growing interst in the use of richly-typed intermediate languages in sophisticated compilers for higher-order, typed source languages. these intermediate languages are typically stratified, involving terms, types, and kinds. As the sophistication of the type system increases, these three levels begin to look more and more similar, so an attractive approach is to use a single syntax, and a single data type in the compiler, to represent all three. The theory of so-called pure type systems makes precisely such an identification. This paper describes Henk, a new typed intermediate language based closely on a particular pure type system, the lambda cube. On the way we giv a tutorial introduction to the lambda cube.},
url = {https://www.microsoft.com/en-us/research/publication/henk-a-typed-intermediate-language/},
edition = {Types in Compilation},
}
@article{peytonjones1997a,
author = {Peyton Jones, Simon and Santos, Andre},
title = {A transformation-based optimiser for Haskell},
year = {1997},
month = {October},
abstract = {Many compilers do some of their work by means of correctness-preserving, and hopefully performance-improving, program transformations. The Glasgow Haskell Compiler (GHC) takes this idea of "compilation by transformation" as its war-cry, trying to express as much as possible of the compilation process in the form of program transformations.

This paper reports on our practical experience of the transformational approach to compilation, in the context of a substantial compiler.


This is a journal version of "Compilation by program transformation: a report from the trenches" (ESOP'96)},
url = {https://www.microsoft.com/en-us/research/publication/a-transformation-based-optimiser-for-haskell/},
journal = {Science of Computer Programming},
volume = {32},
number = {1},
}
@misc{peytonjones1997parallel,
author = {Peyton Jones, Simon},
title = {PARallel Database Engine (Parade) Final Report},
year = {1997},
month = {December},
abstract = {This report summarises the achievements of the EPSRC Parade project (GRJ/53348), which ran from June 1994 to September 1997. We have made contributions in the following three areas.

 	Parallel Language Support (Section 2). We have implemented a robust, portable runtime system and compiler support for Glasgow Parallel Haskell. The system supports a complete parallel development environment providing an integrated simulator and sophisticated proling tools in addition to physical implementations on a variety of parallel machines.
Despite sustained research interest in parallel functional programming, our implementation is one of the first to be made publicly available, and to be widely used outside the research group that developed it.
 	Large-scale data-intensive parallel programming (Section 3). In collaboration with groups at Durham University and the Centre for Transport Studies, London we have developed and measured several large parallel data-intensive programs. We have demonstrated wall-clock speedups for both text- book and, more significantly, real problems on both distributed-memory and shared-memory architectures.
 	Parallel Programming (Section 4). Motivated by our studies of large-scale data-intensive programs, we have developed evaluation strategies, a new programming abstraction that cleanly separates code describing the algorithm from that controlling the parallel behaviour. Evaluation strategies can be used to describe a wide range of control and data parallel programming paradigms, are user-extensible, can be nested or com- posed arbitrarily, and provide a simple framework for reasoning about parallel program behaviour.

Based on our experiences with using evaluation strategies, we are developing a methodology for constructing large parallel functional programs based on a combination of simulation, proling and performance measurement on real machines.},
url = {https://www.microsoft.com/en-us/research/publication/parallel-database-engine-parade-final-report/},
}
@inproceedings{shields1998dynamic,
author = {Shields, Mark and Sheard, Tim and Peyton Jones, Simon},
title = {Dynamic Typing By Staged Type Inference},
booktitle = {25th ACM Symposium on Principles of Programming Languages (POPL'98)},
year = {1998},
month = {January},
abstract = {Dynamic typing extends statically typed languages with a universal datatype, simplifying programs which must manipulate other programs as data, such as distributed, persistent, interpretive and generic programs. Current approaches, however, limit the use of polymorphism in dynamic values, and can be syntactically awkward.We introduce a new approach to dynamic typing, based on staged computation, which allows a single type-reconstruction algorithm to execute partly at compile time and partly at run-time. This approach seamlessly extends a single type system to accommodate types that are only known at run-time, while still supporting both type inference and polymorphism. The system is significantly more expressive than other approaches. Furthermore it can be implemented efficiently; most of the type inference is done at compile-time, leaving only some residual unification for run-time.We demonstrate our approach by examples in a small polymorphic functional language, and present its type system, type reconstruction algorithm, and operational semantics. Our proposal could also be readily adapted to many other programming languages.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/dynamic-typing-by-staged-type-inference/},
pages = {289-302},
edition = {25th ACM Symposium on Principles of Programming Languages (POPL'98)},
}
@article{trinder1998algorithm,
author = {Trinder, PW and Hammond, K and Loidl, H-W and Peyton Jones, Simon},
title = {Algorithm + Strategy = Parallelism},
year = {1998},
month = {January},
abstract = {The process of writing large parallel programs is complicated by the eed to specify both the parallel behaviour of the program and the algorithm that is to be used to compute its result. This paper introduces evaluation strategies: lazy higher-order functions that control the parallel evaluation of non-strict functional languages. Using evaluation strategies, it is possible to achieve a clean separation between algorithmic and behavioural code. The result is enhanced clarity and shorter parallel programs. Evaluation strategies are a very general concept: this paper shows how they can be used to model a wide range of commonly used programming paradigms, including divide-and-conquer parallelism, pipeline parallelism, producer/consumer parallelism, and data-oriented parallelism. Because they are based on unrestricted higher-order functions, they can also capture irregular parallel structures. Evaluation strategies are not just of theoretical interest: they have evolved out of our experience in parallelising several large-scale parallel applications, where they have proved invaluable in helping to manage the complexities of parallel behaviour. Some of these applications are described in detail. The largest application we have studied to date, Lolita, is a 40,000 line natural language engineering system. Initial results show that for these programs we can achieve acceptable parallel performance, for relatively little programming effort.},
publisher = {Cambridge University Press},
url = {https://www.microsoft.com/en-us/research/publication/algorithm-strategy-parallelism/},
pages = {23-60},
journal = {Journal of Functional Programming},
volume = {8},
}
@inproceedings{peytonjones1998bridging,
author = {Peyton Jones, Simon and Launchbury, John and Shields, Mark and Tolmach, Andrew},
title = {Bridging the Gulf: A Common Intermediate Language for ML and Haskell},
booktitle = {ACM Symposium on Principles of Programming Languages (POPL'98)},
year = {1998},
month = {January},
abstract = {Compilers for ML and Haskell use intermediate languages that incorporate deeply-embedded assumptions about order of evaluation and side effects. We propose an intermediate language into which one can compile both ML and Haskell, thereby facilitating the sharing of ideas and infrastructure, and supporting language developments that move each language in the direction of the other. Achieving this goal without compromising the ability to compile as good code as a more direct route turned out to be much more subtle than we expected. We address this challenge using monads and unpointed types, identify two alternative language designs, and explore the choices they embody.},
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/bridging-the-gulf-a-common-intermediate-language-for-ml-and-haskell/},
edition = {ACM Symposium on Principles of Programming Languages (POPL'98)},
}
@unpublished{marlow1998the,
author = {Marlow, Simon and Peyton Jones, Simon},
title = {The New GHC/Hugs Runtime System},
year = {1998},
month = {January},
abstract = {This paper describes the new runtime system being developed for the Glasgow Haskell Compiler. The goal is to provide support for mixed interpreted/compiled execution of Haskell programs, with Hugs as the interpreter. In the process, we've taken the opportunity to fix some of the deficiencies of the old system (such as garbage collection of CAFs), add some new features (cost-centre stack profiling, and a more flexible storage manager), and improve performance (one stack instead of two, better register usage on register-challenged architectures).

We also took the opportunity to design a clean, simple API to the runtime system that would allow it to be used in a variety of applications, from standalone Haskell binaries and interactive interpreters to encapsulated COM/CORBA objects.

The paper is now rather out of date, but it may be useful as background information.

 },
url = {https://www.microsoft.com/en-us/research/publication/the-new-ghchugs-runtime-system/},
}
@techreport{peytonjones1998machine-independent,
author = {Peyton Jones, Simon and Ramsey, Norman},
title = {Machine-independent support for garbage collection, debugging, exception handling, and concurrency},
year = {1998},
month = {January},
abstract = {For a compiler writer, generating good machine code for a variety of platforms is hard work. One might try to reuse a retargetable code generator from another compiler, but code generators are complex and difficult to use, and they limit one's choice of implementation language. One might try to use C as a portable assembly language, but C limits the compiler writer's flexibility and the performance of the resulting code. The wide use of C, despite these drawbacks, argues for a portable assembly language.

C-- is a new language designed expressly as a portable assembly language. C-- eliminates some of the performance problems associated with C, but in its originally-proposed form it does not provide adequate support for garbage collection, exception handling, and debugging. The problem is that neither the high-level compiler nor the C-- compiler has all of the information needed to support these run-time features. This paper proposes a three-part solution: new language constructs for C--, run-time support for C--, and restrictions on optimization of C-- programs.

The new C-- language constructs enable a high-level compiler to associate initialized data with spans of C-- source ranges and to specify "alternate continuations" for calls to procedures that might raise exceptions. The run-time support is an interface (specified in C) that the garbage collector, exception mechanism, and debugger can use to get access to both high-level and low-level information, provided that the C-- program is suspended at a safe point. High- and low-level information is coordinated by means of the C-- spans and a common numbering for variables. Finally, the C-- optimizer operates under the constraints that the debugger or garbage collector can change the values of local variables while execution is suspended, and that a procedure call with alternate continuations can return to more than one location.

This three-part solution also provides adequate support for concurrency, so the paper illustrates the problem and the proposed solution with examples from garbage collection, exception handling, debugging, and threads. The paper also includes a model of the dataflow behavior of C-- calls.

A number of open problems remain. The most serious have to do with apparent redundancies among spans and safe points, and with the interaction of debugging support with optimization.

 },
publisher = {University of Virginia},
url = {https://www.microsoft.com/en-us/research/publication/machine-independent-support-for-garbage-collection-debugging-exception-handling-and-concurrency/},
number = {MSR-TR-1998-1},
}
@inproceedings{finne1998h,
author = {Finne, Sigbjörn and Leijen, Daan and Meijer, Erik and Peyton Jones, Simon},
title = {H/Direct: A Binary Foreign Language Interface for Haskell},
booktitle = {International Conference on Functional Programming 1998 (ICFP'98)},
year = {1998},
month = {April},
abstract = {H/Direct is a foreign-language interface for the purely functional language Haskell. Rather than rely on host-language type signatures, H/Direct compiles Interface Definition Language (IDL) to Haskell stub code that marshals data across the interface. This approach allows Haskell to call both C and COM, and allows a Haskell component to be wrapped in a C or COM interface. IDL is a complex language and language mappings for IDL are usually described informally. In contrast, we provide a relatively formal and precise definition of the mapping between Haskell and IDL.

This paper has been submitted to the International Conference on Functional Programming 1998 (ICFP'98).},
publisher = {ACM SIGPLAN},
url = {https://www.microsoft.com/en-us/research/publication/hdirect-binary-foreign-language-interface-haskell/},
pages = {153-162},
edition = {International Conference on Functional Programming 1998 (ICFP'98)},
}
@manual{oliva1998the,
author = {Oliva, Dino and Iglesias, Pablo Nogueira and Peyton Jones, Simon and Nordin, Thomas},
title = {The C– Language Reference Manual},
year = {1998},
month = {April},
abstract = {C-- is a portable assembly language designed to be a good backend for high level languages (particularly for those that make use of garbage-collection) and to run fast on a number of todays major
computer architectures. It is also designed to have as few dependencies as possible on the underlying hardware, but speed and ease of use has sometimes taken precedence over orthogonality and minimality. C-- should be rich enough to be a viable backend for most mainstream and research compilers.
This paper should be sufficiently self-supporting so that anyone who knows an imperative language and is acquainted with computers should be able to write her/his own C-- programs after reading this document.},
url = {https://www.microsoft.com/en-us/research/publication/the-c-language-reference-manual/},
}
@inproceedings{peytonjones1998scripting,
author = {Peyton Jones, Simon and Meijer, Erik and Leijen, Daan},
title = {Scripting COM components in Haskell},
booktitle = {Fifth International Conference on Software Reuse},
year = {1998},
month = {June},
abstract = {The expressiveness of higher-order, typed languages such as Haskell or ML makes them an attractive medium in which to write software components. Hitherto, however, their use has been limited by the all or-nothing problem: it is hard to write just part of an application in these languages.
Component-based programming using a binary standard such as Microsoft's Component Object Model (COM) offers a solution to this dilemma, by specifying a language-independent interface between components. This paper reports about our experience with exploiting this opportunity in the purely-functional language Haskell. We describe a design for integrating COM components into Haskell programs, and we demonstrate why someone might want to script their COM components in this way.
 },
publisher = {IEEE Computer Society Press},
url = {https://www.microsoft.com/en-us/research/publication/scripting-com-components-haskell/},
edition = {Fifth International Conference on Software Reuse},
}
@inproceedings{jr1998gph,
author = {Jr, E. Barry and Loidl, Hans-Wolfgang and Hammond, Kevin and Davis, M. Kei and Trinder, Philip W. and Junaidu, Sahalu B. and Peyton Jones, Simon},
title = {GPH : An Architecture Independent Functional Language},
year = {1998},
month = {July},
abstract = {In principle, pure functional languages promise straightforward architecture-independent parallelism. We investigate the validity of this claim in the context of our highly-portable implementation of an implicitly-parallel functional language: the GUM implementation of Glasgow Parallel Haskell (GPH). We discuss architecture independence at two levels: low-level (i.e. the implementation) and high-level (i.e. the programmer).

Low-level architecture independence is achieved by chosing a message-passing model for GUM, and implementing it using portable C and a widely-supported message-passing library like PVM. In fact GUM is largely independent of the message-passing library, and has been adapted to use MPI and the CM-5 CMMD libraries as well as PVM. As a result, GUM is easily ported, and is currently available on seven platforms including shared-memory machines, distributed-memory machines, and networks of workstations. We provide indicative measurements of how efficient and effective our architecture-independent runtime system is across a range of architectures.

The GPH programming model provides higher-level architecture independence. The parallelism in GPH is mainly implicit, and hence relatively small parts of the program need to be changed for a new architecture. The coordination that is required is expressed with a new high-level construct, evaluation strategies. Evaluation strategies provide a clean separation between algorithm and coordination, easing the task of changing either facet to suit new parallel environments. Moreover, GPH programs can systematically be developed for multiple target architectures, using a suite of simulation, profiling and visualisation tools. Much of the development is architecture-independent but, once a particular target architecture has been selected, the tools are parameterised to support tuning for that architecture. We demonstrate the systematic development of two real programs to the point of achieving good speedups on four architectures.},
url = {https://www.microsoft.com/en-us/research/publication/gph-an-architecture-independent-functional-language/},
}
@inproceedings{moran1999imprecise,
author = {Moran, Andy and Lassen, Soeren and Peyton Jones, Simon},
title = {Imprecise exceptions, co-inductively},
series = {Electronic Notes in Theoretical Computer Science},
booktitle = {Higher Order Operational Techniques in Semantics: Third International Workshop},
year = {1999},
month = {January},
abstract = {In a recent paper, Peyton Jones et al proposed a design for imprecise exceptions in the lazy functional programming language Haskell. The main contribution of the design was that it allowed the language to continue to enjoy its current rich algebra of transformations. However, the denotational semantics used to formalise the design does not combine easily with other extensions, most notably that of concurrency. We present an alternative semantics for a lazy functional language with imprecise exceptions which is entirely operational in nature, and combines well with other extensions, such as I/O and concurrency. The semantics is based upon a convergence relation, which describes evaluation, and an exceptional convergence relation, which describes the raising of exceptions. Convergence and exceptional convergence lead naturally to a simple notion of refinement, where a term $M$ is refined by $N$ whenever they have identical convergent behaviour, and any exception raised by $N$ can also be raised by $M$. We are able to validate many call-by-name equivalences and standard program transformations, including the ubiquitous strictness transformation.},
publisher = {Elsevier},
url = {https://www.microsoft.com/en-us/research/publication/imprecise-exceptions-co-inductively/},
pages = {137-156},
edition = {Higher Order Operational Techniques in Semantics: Third International Workshop},
}
@inproceedings{jones1999lightweight,
author = {Jones, Mark P and Peyton Jones, Simon},
title = {Lightweight Extensible Records for Haskell},
organization = {ACM},
booktitle = {Haskell Workshop},
year = {1999},
month = {October},
abstract = {In early versions of Haskell, the only direct way to construct values of user-defined datatypes was by applying a constructor function to an appropriate sequence of arguments, and the only direct way to extract component values was by pattern matching. Both rely on a positional notation for datatype components, which is awkward and error-prone when dealing with datatypes that have more than a couple of components. To remedy some of these problems, later versions of Haskell introduced a mechanism for labeled fields that allows components to be set and extracted by using the name of an associated selector function. While this has been useful in practice, it also has several significant problems. For example, record types are not lightweight because they must be declared before values of those types can be constructed. More seriously, no field name can be used in more than one datatype.

In this paper, we present a concrete proposal for replacing the labeled field mechanisms of Haskell with a more flexible system of records that avoids the problems described above. With a theoretical foundation in the earlier work of Gaster and Jones, our system offers lightweight, extensible records and a complement of polymorphic operations for manipulating them. On a more concrete level, our proposal is a direct descendent of the Trex implementation ("typed records with extensibility") in Hugs, but freed from the constraints of that setting, where compatibility with Haskell 98 was a major concern.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/lightweight-extensible-records-for-haskell/},
note = {Paris},
}
@inproceedings{wyk1999aspect-oriented,
author = {Wyk, Eric van and Moor, Oege de and Peyton Jones, Simon},
title = {Aspect-oriented compilers},
booktitle = {GCSE'99 - Generative and Component-Based Software Engineering.},
year = {1999},
month = {January},
abstract = {Lazy evaluation allows compiler writers to ignore a separatation into passes, and to focus on the logical structure of their compiler instead. This is also a feature of attribute grammars, which can be viewed as a particular style of lazy functional program. Compilers written in attribute grammar style are typically structured by production. It is hard to structure them by semantic aspect, such as "environment" or "lexical level", and it is certainly not possible to view these aspects as separate units of compilation.

In this paper we propose a technique for making compiler aspects first class objects, that can be stored, manipulated, and combined. We propose a modest set of combinators that achieve this task in Haskell. The combinator library is an application of recent work on polymorphic type systems for record operations, in particular that of Gaster and Jones, and also of a technique due to Remy which types symmetric record concatenation "for free".},
url = {https://www.microsoft.com/en-us/research/publication/aspect-oriented-compilers/},
edition = {GCSE'99 - Generative and Component-Based Software Engineering.},
}
@inproceedings{peytonjones1999c,
author = {Peyton Jones, Simon and Ramsey, Norman and Reig, Fermin},
title = {C–: a portable assembly language that supports garbage collection},
booktitle = {International Conference on Principles and Practice of Declarative Programming},
year = {1999},
month = {January},
abstract = {For a compiler writer, generating good machine code for a variety of platforms is hard work. One might try to reuse a retargetable code generator, but code generators are complex and difficult to use, and they limit one's choice of implementation language. One might try to use C as a portable assembly language, but C limits the compiler writer's flexibility and the performance of the resulting code. The wide use of C, despite these drawbacks, argues for a portable assembly language. C-- is a new language designed expressly for this purpose. The use of a portable assembly language introduces new problems in the support of such high-level run-time services as garbage collection, exception handling, concurrency, profiling, and debugging. We address these problems by combining the C-- language with a C-- run-time interface. The combination is designed to allow the compiler writer a choice of source-language semantics and implementation techniques, while still providing good performance.},
url = {https://www.microsoft.com/en-us/research/publication/portable-assembly-language-supports-garbage-collection/},
pages = {1-28},
edition = {International Conference on Principles and Practice of Declarative Programming},
}
@inproceedings{wansbrough1999once,
author = {Wansbrough, K and Peyton Jones, Simon},
title = {Once Upon a Polymorphic Type},
booktitle = {26th ACM Symposium on Principles of Programming Languages (POPL'99)},
year = {1999},
month = {January},
abstract = {We present a sound type-based `usage analysis' for a realistic lazy functional language. Accurate information on the usage of program subexpressions in a lazy functional language permits a compiler to perform a number of useful optimisations. However, existing analyses are either ad-hoc and approximate, or defined over restricted languages.

Our work extends the Once Upon A Type system of Turner, Mossin, and Wadler (FPCA'95). Firstly, we add type polymorphism, an essential feature of typed functional programming languages. Secondly, we include general Haskell-style user-defined algebraic data types. Thirdly, we explain and solve the `poisoning problem', which causes the earlier analysis to yield poor results. Interesting design choices turn up in each of these areas.

Our analysis is sound with respect to a Launchbury-style operational semantics, and it is straightforward to implement. Good results have been obtained from a prototype implementation, and we intend to integrate the system into a production compiler.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/once-upon-a-polymorphic-type/},
pages = {15-28},
edition = {26th ACM Symposium on Principles of Programming Languages (POPL'99)},
note = {Submitted to The Twenty-sixth ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'99)},
}
@inproceedings{peytonjones1999a,
author = {Peyton Jones, Simon and Hoare, Tony and Reid, Alastair and Marlow, Simon and Henderson, Fergus},
title = {A Semantics for Imprecise Exceptions},
booktitle = {Proceedings of the ACM SIGPLAN '99 Conference on Programming Language Design and Implementation},
year = {1999},
month = {May},
abstract = {Some modern superscalar microprocessors provide only imprecise exceptions. That is, they do not guarantee to report the same exception that would be encountered by a straightforward sequential execution of the program. In exchange, they offer increased performance or decreased chip area (which amount to much the same thing). This performance/precision tradeoff has not so far been much explored at the programming language level. In this paper we propose a design for imprecise exceptions in the lazy functional programming language Haskell. We discuss several designs, and conclude that imprecision is essential if the language is still to enjoy its current rich algebra of transformations. We sketch a precise semantics for the language extended with exceptions. The paper shows how to extend Haskell with exceptions without crippling the language or its compilers. We do not yet have enough experience of using the new mechanism to know whether it strikes an appropriate balance between expressiveness and performance.},
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/a-semantics-for-imprecise-exceptions/},
pages = {25-36},
edition = {Proceedings of the ACM SIGPLAN '99 Conference on Programming Language Design and Implementation},
}
@inproceedings{peytonjones1999calling,
author = {Peyton Jones, Simon and Meijer, Erik and Leijen, Daan and Finne, Sigbjörn},
title = {Calling Hell from Heaven and Heaven from Hell},
booktitle = {The International Conference on Functional Programming (ICFP'99), Paris, France},
year = {1999},
month = {September},
abstract = {The increasing popularity of component-based programming tools offer a big opporunity to designers of advanced programming languages, such as Haskell. If we can package our programs as COM objects, then it is easy to integrate them into applications written in other languages. In earlier work we described a preliminary integration of Haskell with Microsoft's Component Object Model (COM), focusing on how Haskell can create and invoke COM objects. This paper develops that work, concentrating on the mechanisms that support externally-callable Haskell functions, and the encapsulation of a Haskell program as a COM object.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/calling-hell-from-heaven-and-heaven-from-hell/},
pages = {114-125},
edition = {The International Conference on Functional Programming (ICFP'99), Paris, France},
note = {Also appeared in ACM SIGPLAN Notices 34, 9, (Sep. 1999)},
}
@inproceedings{peytonjones1999stretching,
author = {Peyton Jones, Simon and Marlow, Simon and Elliott, Conal},
title = {Stretching the storage manager: weak pointers and stable names in Haskell},
series = {LNCS},
booktitle = {Proceedings of the 11th International Workshop on the Implementation of Functional Languages},
year = {1999},
month = {September},
abstract = {Every now and then, a user of the Glasgow Haskell Compiler asks for a feature that requires specialised support from the storage manager. Memo functions, pointer equality, external pointers, finalizers, and weak pointers, are all examples. We take memo functions as our exemplar because they turn out to be the trickiest to support. We present no fewer than four distinct mechanisms that are needed to support memo tables, and that (in various combinations) satisfy a variety of other needs. The resulting set of primitives is undoubtedly powerful and useful. Whether they are too powerful is not yet clear. While the focus of our discussion is on Haskell, there is nothing Haskell-specific about most of the primitives, which could readily be used in other settings.


Errata: In Figure 3, the function not_found should have a formal parameter sn, and the call to not_found (four lines above its definition) should pass sn as an argument.},
publisher = {Springer-Verlag},
url = {https://www.microsoft.com/en-us/research/publication/stretching-the-storage-manager-weak-pointers-and-stable-names-in-haskell/},
edition = {Proceedings of the 11th International Workshop on the Implementation of Functional Languages},
note = {(Submitted to ICFP'99.)},
}
@inbook{peytonjones1999engineering,
author = {Peyton Jones, Simon and Loidl, Hans-Wolfgang and Trinder, Philip W. and Hammond, Kevin and Junaidu, Sahalu B. and Morgan, Richard G.},
title = {Engineering Parallel Symbolic Programs in GpH},
booktitle = {Concurrency - Practice and Experience},
year = {1999},
month = {October},
abstract = {We investigate the claim that functional languages offer low-cost parallelism in the context of symbolic programs on modest parallel architectures. In our investigation we present the first comparative study of the construction of large applications in a parallel functional language, in our case in Glasgow Parallel Haskell (GPH). The applications cover a range of application areas, use several parallel programming paradigms, and are measured on two very different parallel architectures.

On the applications level the most significant result is that we are able to achieve modest wall-clock speedups (between factors of 2 and 10) over the optimised sequential versions for all but one of the programs. Speedups are obtained even for programs that were not written with the intention of being parallelised. These gains are achieved with a relatively small programmer-effort. One reason for the relative ease of parallelisation is the use of evaluation strategies, a new parallel programming technique that separates the algorithm from the coordination of parallel behaviour.

On the language level we show that the combination of lazy and parallel evaluation is useful for achieving a high level of abstraction. In particular we can describe top-level parallelism, and also preserve module abstraction by describing parallelism over the data structures provided at the module interface (``data-oriented parallelism''). Furthermore, we find that the determinism of the language is helpful, as is the largely-implicit nature of parallelism in GPH.
@Article[cpe,
  author = 	 [Loidl, H-W. and Trinder, P.W. and Hammond, K. and
                  Junaidu, S.B. and Morgan, R.G. and [Peyton Jones], S.L.],
  title = 	 [[Engineering Parallel Symbolic Programs in GPH]],
  journal = 	 [Concurrency --- Practice and Experience],
  year = 	 1999,
  volume =       [11],
  issue =        [12],
  pages =        [701--752],
  url =          [http://www.cee.hw.ac.uk/\~[]dsg/gph/papers/ps/cpe.ps.gz],
]

 },
url = {https://www.microsoft.com/en-us/research/publication/engineering-parallel-symbolic-programs-in-gph/},
pages = {701-752},
volume = {11},
edition = {Concurrency - Practice and Experience},
number = {12},
}
@inproceedings{trinder2000the,
author = {Trinder, P.W. and Loidl, H-W. and Barry, E. and Hammond, K. and Klusik, U. and Peyton Jones, Simon},
title = {The Multi-Architecture Performance of the Parallel Functional Language GPH},
series = {Lecture Notes in Computer Science},
booktitle = {Euro-Par 2000 "” Parallel Processing},
year = {2000},
month = {January},
abstract = {In principle, functional languages promise straightforward architecture-independent parallelism, because of their high level descrip­tion of parallelism, dynamic management of parallelism and deterministic semantics. However, these language features come at the expense of a so­phisticated compiler and/or runtime-system. The problem we address is whether such an elaborate system can deliver acceptable performance on a variety of parallel architectures. In particular we report performance measurements for the GUM runtime-system on eight parallel architec­tures, including massively parallel, distributed-memory, shared-memory and workstation networks.},
publisher = {Springer-Verlag},
url = {https://www.microsoft.com/en-us/research/publication/the-multi-architecture-performance-of-the-parallel-functional-language-gph/},
edition = {Euro-Par 2000 — Parallel Processing},
}
@inproceedings{marlow2000non-stop,
author = {Marlow, Simon and Peyton Jones, Simon},
title = {Non-stop Haskell},
booktitle = {ICFP '00: Proceedings of the fifth ACM SIGPLAN international conference on Functional programming},
year = {2000},
month = {January},
abstract = {We describe an efficient technique for incorporating Baker's incremental garbage collection algorithm into the Spineless Tagless G-machine on stock hardware. This algorithm eliminates the stop/go execution associated with bulk copying collection algorithms, allowing the system to place an upper bound on the pauses due to garbage collection. The technique exploits the fact that objects are always accessed by jumping to code rather than being explicitly dereferenced. It works by modifying the entry code-pointer when an object is in the transient state of being evacuated but not scavenged. An attempt to enter it from the mutator causes the object to "self-scavenge" transparently before resetting its entry code pointer.

We describe an implementation of the scheme in v4.01 of the Glasgow Haskell Compiler and report performance results obtained by executing a range of applications. These experiments show that the read barrier can be implemented in dynamic dispatching systems such as the STG-machine with very short mutator pause times and with negligible overhead on execution time.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/non-stop-haskell/},
pages = {257-267},
isbn = {1-58113-202-6},
edition = {ICFP '00: Proceedings of the fifth ACM SIGPLAN international conference on Functional programming},
}
@inproceedings{peytonjones2000a,
author = {Peyton Jones, Simon},
title = {A Single Intermediate Language That Supports Multiple Implementations of Exceptions},
booktitle = {ACM SIGPLAN '00 Conference on Programming Language Design and Implementation (PLDI)},
year = {2000},
month = {January},
abstract = {We present mechanisms that enable our compiler-target language, C--, to express four of the best known techniques for implementing exceptions, all within a single, uniform framework. We define the mechanisms precisely, using a formal operational semantics. We also show that exceptions need not require special treatment in the optimizer; by introducing extra dataflow edges, we make standard optimization techniques work even on programs that use exceptions. Our approach clarifies the design space of exception-handling techniques, and it allows a single optimizer to handle a variety of implementation techniques, uniformly. Our ultimate goal is to allow a source-language compiler the freedom to choose its exception-handling policy, while encapsulating the (architecture-dependent) mechanisms and their optimization in an implementation of C-- that can be used by compilers for many source languages.

Related work is on the C-- page},
url = {https://www.microsoft.com/en-us/research/publication/single-intermediate-language-supports-multiple-implementations-exceptions/},
pages = {285-298},
edition = {ACM SIGPLAN '00 Conference on Programming Language Design and Implementation (PLDI)},
}
@techreport{hinze2000derivable,
author = {Hinze, Ralf and Peyton Jones, Simon},
title = {Derivable type classes},
series = {Technical Reports},
year = {2000},
month = {September},
abstract = {Generic programming allows you to write a function once, and use it many times at different types. A lot of good foundational work on generic programming has been done. The goal of this paper is to propose a practical way of supporting generic programming within the Haskell language, while going "with the grain" of the language.

On the way, we came across a separate issue, concerning type-class overloading where higher kinds are involved. We propose a simple type-system extension to allow the programmer to write richer contexts than is currently possible.},
url = {https://www.microsoft.com/en-us/research/publication/derivable-type-classes/},
edition = {Proceedings of the 2000 Haskell Workshop, Montreal},
number = {NOTTCS-TR-00-1},
note = {Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence (UAI1990)},
}
@inproceedings{jones2000composing,
author = {Jones, SL Peyton and Eber, J-M and Seward, J and Peyton Jones, Simon},
title = {Composing contracts: an adventure in financial engineering},
booktitle = {ACM SIGPLAN International Conference on Functional Programming (ICFP'00)},
year = {2000},
month = {September},
abstract = {Financial and insurance contracts do not sound like promising territory for functional programming and formal semantics, but in fact we have discovered that insights from programming languages bear directly on the complex subject of describing and valuing a large class of contracts.

We introduce a combinator library that allows us to describe such contracts precisely, and a compositional denotational semantics that says what such contracts are worth. We sketch an implementation of our combinator library in Haskell. Interestingly, lazy evaluation plays a crucial role.

 	PowerPoint slides

A revised and updated version of this paper appeared as How to write a financial contract, a chapter in "The Fun of Programming", ed Gibbons and de Moor, Palgrave Macmillan 2003.

Anton van Staten has a written a  self-contained, well-documented Haskell library of composable contracts, which looks like a great resource if you want to try executing some contracts.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/composing-contracts-an-adventure-in-financial-engineering/},
pages = {280-292},
edition = {ACM SIGPLAN International Conference on Functional Programming (ICFP'00)},
}
@inproceedings{achten2000porting,
author = {Achten, Peter and Peyton Jones, Simon},
title = {Porting the Clean Object I/O library to Haskell},
series = {Lecture Notes in Computer Science},
booktitle = {Proceedings of the 12th International workshop on the Implementation of Functional Languages, Aachen (IFL'00), selected papers},
year = {2000},
month = {September},
abstract = {Pure, functional programming languages offer several solutions to construct Graphical User Interfaces. One of these approaches is the Clean Object I/O library. It employs an explicit environment passing scheme, based on the uniqueness type system of Clean. Graphical User Interface elements are defined on a high level of abstraction by means of algebraic data types. Composite elements are constructed by means of type constructor combinators. The behaviour of an interactive element is defined by higher order functions. These functions can use global and local state. The Object I/O system supports interleaved interactive processes. Interactive elements can communicate internally by means of message passing. Solutions for Graphical User Interfaces for the programming language Haskell are based on monads, using an implicit environment passing scheme. In this paper we investigate how the Clean Object I/O library can be ported to Haskell. We give an implementation of a small fragment of the Object I/O library to show the feasibility. We take especial consideration for the relevant design choices.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/porting-the-clean-object-io-library-to-haskell/},
pages = {194-213},
edition = {Proceedings of the 12th International workshop on the Implementation of Functional Languages, Aachen (IFL'00), selected papers},
}
@inbook{peytonjones2001tackling,
author = {Peyton Jones, Simon},
title = {Tackling the awkward squad: monadic input/output, concurrency, exceptions, and foreign-language calls in Haskell},
booktitle = {Engineering theories of software construction},
year = {2001},
month = {January},
abstract = {I've revised the notes significantly, with the help of feedback from many people. Last update: 21 Feb 2001.

 	PowerPoint slides 
 	Writing High-Performance Server Applications in Haskell, Case Study: A Haskell Web Server, Simon Marlow, Haskell Workshop, Montreal, Canada, Sept 2000. This paper describes the running example in the notes.

 

This tutorial focuses on explaining the "bits round the edges" of Haskell programs, rather than the beautiful functional core we all know and love. More specifically, it gives, in a single framework, an account of

 	monadic input/output (the I/O monad)
 	concurrency (threads, MVars)
 	exceptions (both synchronous and asynchronous)
 	foreign language interfaces

The common feature of all of these is, of course, the ubiquitous I/O monad. All except the first (basic I/O) involve proposed extensions to Haskell that are implemented in GHC, and I have tried hard to make the tutorial use exactly the same function names as GHC does. All of the extensions are described in conference papers (also available from my home page), but these papers are not tutorials, and were written with varying nomenclature over a period of several years. I hope that this tutorial gives a more comprehensible overview of the big picuture, using a common vocabulary.

The tutorial also gives an operational semantics for everything described except the foreign-language interface part. For this I borrow the framework of operational semantics --- but don't worry! My intention is that you don't need to know a thing about operational semantics to understand the paper.

I occasionally update this tutorial, and I would very much appreciate your help in improving it. If you read it, please let me know of any errors you find and suggestions for improvement.

 },
publisher = {IOS Press},
url = {https://www.microsoft.com/en-us/research/publication/tackling-awkward-squad-monadic-inputoutput-concurrency-exceptions-foreign-language-calls-haskell/},
pages = {47-96},
isbn = {ISBN 1 58603 1724},
}
@unpublished{peytonjones2001featherweight,
author = {Peyton Jones, Simon and Ramsey, Norman},
title = {Featherweight concurrency in a portable assembly language},
year = {2001},
month = {January},
abstract = {What abstractions should a reusable code generator, such as C--, provide to make it easy for a language implementor to compile a highly concurrent language? The implementation of concurrency is typically tightly interwoven with the code generator and run-time system of the high-level language. Our contribution is to tease out the tricky low-level concurrency mechanisms and to package them in an elegant way, so they can be reused by many front ends.

(This paper was rejected by PLDI'01 and is still awaiting a New Life.)

 },
url = {https://www.microsoft.com/en-us/research/publication/featherweight-concurrency-in-a-portable-assembly-language/},
}
@inproceedings{shields2001object-oriented,
author = {Shields, Mark and Peyton Jones, Simon},
title = {Object-Oriented Style Overloading for Haskell},
booktitle = {Workshop on Multi-Language Infrastructure and Interoperability (BABEL'01)},
year = {2001},
month = {September},
abstract = {Haskell has a sophisticated mechanism for overloading identiﬁers with multiple deﬁnitions at distinct types. Object-oriented programming has a similar notion of overriding and overloading for methods names. Unfortunately, it is not possible to encode object-oriented overloading directly using Haskell overloading. This deﬁciency becomes particularly tiresome when Haskell programs wish to call methods imported from an object-oriented library. We present two reﬁnements of Haskell’s type class system: Closed classes and overlapping instances. We demonstrate how we may exploit the reﬁned system so as to be able to encode object-oriented classes within Haskell. This encoding allows us to mimic, within Haskell, the overloading resolution rules employed by object-oriented languages without the need for additional type annotations or name mangling. As a consequence, object-oriented class libraries are very convenient to import and use within Haskell.
Errata (in both versions]

 	Fig 2, page 14 (conference version) or page 12 (tech report version): the declaration
  class SubE e

should read
  class (SubI e, SubJ e) => SubE e

Similarly, in the same Figure, the declaration for class SubF should read
  class (SubE e) => SubF e


Other versions

 	powerpoint slides

A technical report version of this paper is also available. 31 pages.

 	A4 pdf 

 },
url = {https://www.microsoft.com/en-us/research/publication/object-oriented-style-overloading-for-haskell/},
edition = {Workshop on Multi-Language Infrastructure and Interoperability (BABEL'01)},
}
@inproceedings{peytonjones2001playing,
author = {Peyton Jones, Simon and Tolmach, Andrew and Hoare, Tony},
title = {Playing by the rules: rewriting as a practical optimisation technique in GHC},
organization = {ACM SIGPLAN},
booktitle = {2001 Haskell Workshop},
year = {2001},
month = {September},
abstract = {We describe a facility for improving optimization of Haskell programs using rewrite rules. Library authors can use rules to express domain-specific optimizations that the compiler cannot discover for itself. The compiler can also generate rules internally to propagate information obtained from automated analyses. The rewrite mechanism is fully implemented in the released Glasgow Haskell Compiler.

Our system is very simple, but can be effective in optimizing real programs. We describe two practical applications involving short-cut deforestation, for lists and for rose trees, and document substantial performance improvements on a range of programs.},
url = {https://www.microsoft.com/en-us/research/publication/playing-by-the-rules-rewriting-as-a-practical-optimisation-technique-in-ghc/},
edition = {2001 Haskell Workshop},
}
@unpublished{peytonjones2002lexically,
author = {Peyton Jones, Simon and Shields, Mark},
title = {Lexically scoped type variables},
year = {2002},
month = {January},
abstract = {As type inference systems become more sophisticated, it becomes increasingly important to allow the programmer to give type annotations that both document the program and guide type inference. In Haskell 98, it is not possible to write certain type annotations, because they must mention a type that is “in scope” and the language provides no way to name such types. The obvious solution is to provide language support for lexically scoped type variables, an area whose design space has not been systematically explored. Our contribution is to bring together the relevant folk lore, in coherent form, and make it accessible to a much larger community than hitherto. In particular, we describe and contrast two main alternative designs — the “type-lambda” approach of SML 97, and an alternative “type-sharing” approach which is used by GHC and OCaml — and survey some alternative design choices. Scoped type variables will play a key role in the type systems of the future; they can no longer be added as an afterthought to language implementations.},
url = {https://www.microsoft.com/en-us/research/publication/lexically-scoped-type-variables/},
note = {Microsoft Research},
}
@inproceedings{shields2002first,
author = {Shields, Mark and Peyton Jones, Simon},
title = {First class modules for Haskell},
booktitle = {9th International Conference on Foundations of Object-Oriented Languages (FOOL 9), Portland, Oregon},
year = {2002},
month = {January},
abstract = {Though Haskell’s module language is quite weak, its core language is highly expressive. Indeed, it is tantalisingly close to being able to express much of the structure traditionally delegated to a seperate module language. However, the encodings are awkward, and some situations can’t be encoded at all. In this paper we reﬁne Haskell’s core language to support ﬁrst-class modules with many of the features of ML-style modules. Our proposal cleanly encodes signatures, structures and functors with the appropriate type abstraction and type sharing, and supports recursive modules. All of these features work across compilation units, and interact harmoniously with Haskell’s class system. Coupled with support for staged computation, we believe our proposal would be an elegant approach to run-time dynamic linking of structured code. Our work builds directly upon Jones’ work on parameterised signatures, Odersky and La¨ufer’s system of higher-ranked type annotations, Russo’s semantics of ML modules using ordinary existential and universal quantiﬁcation, and Odersky and Zenger’s work on nested types. We motivate the system by examples, and include a more formal presentation in the appendix.},
url = {https://www.microsoft.com/en-us/research/publication/first-class-modules-for-haskell/},
pages = {28-40},
edition = {9th International Conference on Foundations of Object-Oriented Languages (FOOL 9), Portland, Oregon},
}
@article{peytonjones2002secrets,
author = {Peyton Jones, Simon and Marlow, Simon},
title = {Secrets of the Glasgow Haskell Compiler inliner},
year = {2002},
month = {July},
abstract = {Higher-order languages, such as Haskell, encourage the programmer to build abstractions by composing functions. A good compiler must inline many of these calls to recover an efficiently executable program.

In principle, inlining is dead simple: just replace the call of a function by an instance of its body. But any compiler-writer will tell you that inlining is a black art, full of delicate compromises that work together to give good performance without unnecessary code bloat.

The purpose of this paper is, therefore, to articulate the key lessons we learned from a full-scale ``production'' inliner, the one used in the Glasgow Haskell compiler. We focus mainly on the algorithmic aspects, but we also provide some indicative measurements to substantiate the importance of various aspects of the inliner.

The "Related File" link above is an earlier tech-report version of the paper, but the JFP version is the one to read (the "View publication" button).},
url = {https://www.microsoft.com/en-us/research/publication/secrets-of-the-glasgow-haskell-compiler-inliner/},
pages = {393-434},
journal = {Journal of Functional Programming},
volume = {12},
}
@inproceedings{sheard2002template,
author = {Sheard, Tim and Peyton Jones, Simon},
title = {Template meta-programming for Haskell},
booktitle = {Proceedings of the 2002 Haskell Workshop, Pittsburgh},
year = {2002},
month = {October},
abstract = {We propose a new extension to the purely functional programming language Haskell that supports compile-time meta-programming. The purpose of the system is to support the algorithmic construction of programs at compile-time.

The ability to generate code at compile time allows the programmer to implement such features as polytypic programs, macro-like expansion, user directed optimization (such as inlining), and the generation of supporting data structures and functions from existing data structures and functions.

Our design is being implemented in the Glasgow Haskell Compiler, ghc.

 },
url = {https://www.microsoft.com/en-us/research/publication/template-meta-programming-for-haskell/},
pages = {1-16},
edition = {Proceedings of the 2002 Haskell Workshop, Pittsburgh},
}
@inproceedings{lmmel2003scrap,
author = {Lämmel, Ralf and Peyton Jones, Simon},
title = {Scrap your boilerplate: a practical approach to generic programming},
booktitle = {ACM SIGPLAN International Workshop on Types in Language Design and Implementation (TLDI'03)},
year = {2003},
month = {January},
abstract = {We describe a design pattern that for writing programs that traverse data structures built from rich mutually-recursive data types. Such programs often have a great deal of "boilerplate" code that simply walks the structure, hiding a small amount of "real" code that constitutes the reason for the traversal.

Our technique allows most of this boilerplate to be written once and for all (perhaps even mechanically generated), leaving the programmer free to concentrate on the important part of the algorithm. These generic programs are much more robust to data structure evolution because they contain many fewer lines of type-specific code.

Our approach is simple to understand, reasonably efficient, and it handles all the data types found in conventional functional programming languages. It makes essential use of rank-2 polymorphism, an extension found in some implementations of Haskell.

 	PowerPoint slides},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/scrap-your-boilerplate-a-practical-approach-to-generic-programming/},
pages = {26-37},
edition = {ACM SIGPLAN International Workshop on Types in Language Design and Implementation (TLDI'03)},
}
@unpublished{peytonjones2003wearing,
author = {Peyton Jones, Simon},
title = {Wearing the hair shirt: a retrospective on Haskell (2003)},
year = {2003},
month = {January},
abstract = {Haskell was 15 years old at the POPL'03 meeting, when I presented this talk: it was born at a meeting at the 1987 conference on Functional Programming and Computer Architecture (FPCA'87).

In this talk, which is very much a personal view, I take a look back at the language, and try to tease out what we have learned from the experience of designing and implementing it. The main areas I discuss are: syntax (briefly), laziness (the hair shirt of the title), type classes, and sexy types.

On the way, I try to identify a few open questions that I think merit further study.

 },
url = {https://www.microsoft.com/en-us/research/publication/wearing-hair-shirt-retrospective-haskell-2003/},
edition = {invited talk at POPL 2003},
note = {invited talk at POPL 2003},
}
@inproceedings{peytonjones2003a,
author = {Peyton Jones, Simon and Burnett, Margaret and Blackwell, Alan},
title = {A User-Centred Approach to Functions in Excel},
booktitle = {International Conference on Functional Programming (ICFP'03)},
year = {2003},
month = {June},
abstract = {We describe extensions to the Excel spreadsheet that integrate user-defined functions into the spreadsheet grid, rather than treating them as a "bolt-on". Our case study is unusual in that it highlights the way that programming language insights can be applied to a product not normally considered as a programming language.

Even more unusual, our design is ruthlessly driven by principles of user-centred design developed by the HCI community, extending them to programming language design. Unlike other programming language research that focuses on usability, our project involves the evolution of the design of a well-established language, which raises compatibility with previous versions as a major issue, but also gives us access to a user base who are able to offer feedback in the user-centred design process.

In this paper we present our extensions and the HCI design principles that lead to our design choices.

If you are interested in this paper, you may also be interested in the European Spreadsheet Risk Interest Group (EuSpRIG).},
url = {https://www.microsoft.com/en-us/research/publication/a-user-centred-approach-to-functions-in-excel/},
}
@inproceedings{robertennalsandpeytonjones2003optimistic,
author = {, Robert Ennals and Peyton Jones, Simon},
title = {Optimistic Evaluation: a fast evaluation strategy for non-strict programs},
booktitle = {ACM International Conference on Functional Programming (ICFP'03)},
year = {2003},
month = {August},
abstract = {Lazy programs are beautiful, but slow. A great deal of work has been done on static analyses (such as strictness analysis, or cheapness analysis) that conservatively estimate where call-by-need can be changed to call-by-value without changing the meaning of the program.

Our measurements show that many of the thunks that remain after such analyses are in fact always evaluated, or are always cheap. In this paper we describe a new evaluation strategy, optimistic evaluation, that explores the space between call-by-need and call-by-value. Optimistic evaluation complements compile-time analyses with run-time experiments: it evaluates a thunk speculatively, but has an abortion mechanism to back out if it makes a bad choice. We add a run-time adaption mechanism so that the system can avoid making the same bad choice again.

We have implemented optimistic evaluation in the Glasgow Haskell Compiler. The results are encouraging: many programs speed up significantly (5-25%), some are dramatically faster, and very few go slower.

Adaptive evaluation of non-strict programs
Robert Ennals, PhD thesis, University of Cambridge, 2004. This is Robert's PhD thesis, which goes into much more detail.

 	PhD thesis (PDF)},
url = {https://www.microsoft.com/en-us/research/publication/optimistic-evaluation-fast-evaluation-strategy-non-strict-programs/},
edition = {ACM International Conference on Functional Programming (ICFP'03)},
}
@inproceedings{duck2004sound,
author = {Duck, Gregory and Peyton Jones, Simon and Sulzmann, Martin and Stuckey, Peter},
title = {Sound and Decidable Type Inference for Functional Dependencies},
series = {Lecture Notes in Computer Science},
booktitle = {European Sumposium on Programming (ESPO'04)},
year = {2004},
month = {January},
abstract = {Functional dependencies are a popular and useful extension to Haskell style type classes. In this paper, we give a reformulation of functional dependencies in terms of Constraint Handling Rules (CHRs). In previous work, CHRs have been employed for describing user-programmable type extensions in the context of Haskell style type classes. Here, we make use of CHRs to provide for the first time a concise result that under some sufficient conditions, functional dependencies allow for sound, complete and decidable type inference. The sufficient conditions imposed on functional dependencies can be very limiting. We show how to safely relax these conditions.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/sound-and-decidable-type-inference-for-functional-dependencies/},
pages = {49-63},
volume = {2986},
edition = {European Sumposium on Programming (ESPO'04)},
}
@article{baker-finch2004constructed,
author = {Baker-Finch, Clem and Glynn, Kevin and Peyton Jones, Simon},
title = {Constructed Product Result Analysis for Haskell},
year = {2004},
month = {March},
abstract = {Compilers for ML and Haskell typically go to a good deal of trouble to arrange that multiple arguments can be passed efficiently to a procedure. For some reason, less effort seems to be invested in ensuring that multiple results can also be returned efficiently.

In the context of the lazy functional language Haskell, we describe an analysis, Constructed Product Result (CPR) analysis, that determines when a function can profitably return multiple results in registers. The analysis is based only on a function's definition, and not on its uses (so separate compilation is easily supported) and the results of the analysis can be expressed by a transformation of the function definition alone. We discuss a variety of design issues that were addressed in our implementation, and give measurements of the effectiveness of our approach across a substantial benchmark set.

Overall, the price/performance ratio is good: the benefits are modest in general (though occasionally dramatic), but the costs in both complexity and compile time, are low.

 },
url = {https://www.microsoft.com/en-us/research/publication/constructed-product-result-analysis-haskell/},
pages = {211-245},
journal = {Journal of Functional Programming},
volume = {14},
number = {2},
}
@inproceedings{blackwell2004champagne,
author = {Blackwell, Alan and Burnett, Margaret and Peyton Jones, Simon},
title = {Champagne Prototyping: A Research Technique for Early Evaluation of Complex End-User Programming Systems},
booktitle = {IEEE Symposium on Visual Languages and Human Centric Computing (VLHCC)},
year = {2004},
month = {September},
abstract = {Although a variety of evaluation techniques are available to researchers of visual and end-user programming systems, they are primarily suited to evaluation of research systems. It is important to have evaluation techniques suitable for real-world programming environments, in order to satisfy realworld product managers of the usefulness of proposed new features.

To help fill this gap, we present a new evaluation technique, based in part on Cognitive Dimensions and Attention Investment, called "Champagne Prototyping". The technique is an early-evaluation technique that is inexpensive to do, yet features the credibility that comes from being based on the real commercial environment of interest, and from working with real users of the environment.

If you are interested in this paper, you may also be interested in our earlier paper "A user-centred approach to functions in Excel"; and in the European Spreadsheet Risk Interest Group (EuSpRIG).

 },
publisher = {IEEE},
url = {https://www.microsoft.com/en-us/research/publication/champagne-prototyping-research-technique-early-evaluation-complex-end-user-programming-systems/},
pages = {47-54},
}
@techreport{peytonjones2004wobbly,
author = {Peyton Jones, Simon and Washburn, Geoffrey and Weirich, Stephanie},
title = {Wobbly Types: Type Inference For Generalised Algebraic Data Types},
year = {2004},
month = {July},
abstract = {Generalised algebraic data types (GADTs), sometimes known as "guarded recursive data types" or "first-class phantom types", are a simple but powerful generalisation of the data types of Haskell and ML. Recent works have given compelling examples of the utility of GADTs, although type inference is known to be difficult. It is time to pluck the fruit. Can GADTs be added to Haskell, without losing type inference, or requiring unacceptably heavy type annotations? Can this be done without completely rewriting the already-complex Haskell type-inference engine, and without complex interactions with (say) type classes? We answer these questions in the affirmative, giving a type system that explains just what type annotations are required, and a prototype implementation that implements it. Our main technical innovation is wobbly types, which express in a declarative way the uncertainty caused by the incremental nature of typical type-inference algorithms.},
url = {https://www.microsoft.com/en-us/research/publication/wobbly-types-type-inference-for-generalised-algebraic-data-types/},
number = {MS-CIS-05-26},
note = {Microsoft Research},
}
@inproceedings{marlow2004extending,
author = {Marlow, Simon and Peyton Jones, Simon},
title = {Extending the Haskell Foreign Function Interface with Concurrency},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell},
year = {2004},
month = {September},
abstract = {A Haskell system that includes both the Foreign Function Interface and the Concurrent Haskell extension must consider how Concurrent Haskell threads map to external Operating System threads for the purposes of specifying in which thread a foreign call is made.

Many concurrent languages take the easy route and specify a one-to-one correspondence between the language's own threads and external OS threads. However, OS threads tend to be expensive, so this choice can limit the performance and scalability of the concurrent language.

The main contribution of this paper is a language design that provides a neat solution to this problem, allowing the implementor of the language enough flexibility to provide cheap lightweight threads, while still providing the programmer with control over the mapping between internal threads and external threads where necessary.},
url = {https://www.microsoft.com/en-us/research/publication/extending-the-haskell-foreign-function-interface-with-concurrency/},
pages = {57-68},
edition = {Proceedings of the ACM SIGPLAN workshop on Haskell},
}
@inproceedings{peytonjones2004how,
author = {Peyton Jones, Simon},
title = {How to make a fast curry: push/enter vs eval/apply},
booktitle = {International Conference on Functional Programming},
year = {2004},
month = {September},
abstract = {Higher-order languages that encourage currying are typically implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other.

Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell.

Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.

 	Conference version (2004) 
 	Slides of talk 

 },
url = {https://www.microsoft.com/en-us/research/publication/make-fast-curry-pushenter-vs-evalapply/},
pages = {4-15},
edition = {International Conference on Functional Programming},
}
@inproceedings{marlow2004exploring,
author = {Marlow, Simon and Peyton Jones, Simon},
title = {Exploring the Barrier to Entry: Incremental Generational Garbage Collection for Haskell},
booktitle = {International Symposium on Memory Management},
year = {2004},
month = {October},
abstract = {We document the design and implementation of a "production" incremental garbage collector for GHC 6.02. It builds on our earlier work (Non-stop Haskell) that exploited GHC's dynamic dispatch mechanism to hijack object code pointers so that objects in to-space automatically scavenge themselves when the mutator attempts to enter " them. This paper details various optimisations based on code specialisation that remove the dynamic space, and associated time, overheads that accompanied our earlier scheme. We detail important implementation issues and provide a detailed evaluation of a range of design alternatives in comparison with Non-stop Haskell and GHC's current generational collector. We also show how the same code specialisation techniques can be used to eliminate the write barrier in a generational collector.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/exploring-the-barrier-to-entry-incremental-generational-garbage-collection-for-haskell/},
edition = {International Symposium on Memory Management},
}
@article{peytonjones2005practical,
author = {Peyton Jones, Simon and Vytiniotis, Dimitrios and Weirich, Stephanie and Shields, Mark},
title = {Practical type inference for arbitrary-rank types},
year = {2005},
month = {January},
abstract = {Very minor post-JFP revision: Nov 2006 Final minor revision: Feb 2006
Second major revision: July 2005
Major revision: April 2004

 	Technical Appendix to the paper
 	Prototype implementation in Haskell
 	Related papers

Haskell's popularity has driven the need for ever more expressive type system features, most of which threaten the decidability and practicality of Damas-Milner type inference. One such feature is the ability to write functions with higher-rank types --- that is, functions that take polymorphic functions as their arguments.

Complete type inference is known to be undecidable for higher-rank (impredicative) type systems, but in practice programmers are more than willing to add type annotations to guide the type inference engine, and to document their code. However, the choice of just what annotations are required, and what changes are required in the type system and its inference algorithm, has been an ongoing topic of research.

We take as our starting point a lambda-calculus proposed by Odersky and Laufer. Their system supports arbitrary-rank polymorphism through the exploitation of type annotations on lambda-bound arguments and arbitrary sub-terms. Though elegant, and more convenient than some other proposals, Odersky and Laufer's system requires many annotations. We show how to use local type inference (invented by Pierce and Turner) to greatly reduce the annotation burden, to the point where higher-rank types become eminently usable.

Higher-rank types have a very modest impact on type inference. We substantiate this claim in a very concrete way, by presenting a complete type-inference engine, written in Haskell, for a traditional Damas-Milner type system, and then showing how to extend it for higher-rank types. We write the type-inference engine using a monadic framework: it turns out to be a particularly compelling example of monads in action.

The paper is long, but is strongly tutorial in style.},
url = {https://www.microsoft.com/en-us/research/publication/practical-type-inference-for-arbitrary-rank-types/},
pages = {1-82},
journal = {Journal of Functional Programming},
volume = {17},
edition = {Journal of Functional Programming},
note = {Submitted to the Journal of Functional Programming},
}
@inproceedings{chakravarty2005associated,
author = {Chakravarty, Manuel and Keller, Gabriele and Peyton Jones, Simon},
title = {Associated Type Synonyms},
booktitle = {ACM SIGPLAN International Conference on Functional Programming (ICFP'05)},
year = {2005},
month = {January},
abstract = {Haskell programmers often use a multi-parameter type class in which one or more type parameters are functionally dependent on the first. Although such functional dependencies have proved quite popular in practice, they express the programmer's intent somewhat indirectly. Developing earlier work on associated data types, we propose to add functionally-dependent types as type synonyms to type-class bodies. These associated type synonyms constitute an interesting new alternative to explicit functional dependencies.},
url = {https://www.microsoft.com/en-us/research/publication/associated-type-synonyms/},
edition = {ACM SIGPLAN International Conference on Functional Programming (ICFP'05)},
}
@inproceedings{harris2005composable,
author = {Harris, Tim and Marlow, Simon and Peyton Jones, Simon},
title = {Composable memory transactions},
booktitle = {PPoPP '05: Proceedings of the tenth ACM SIGPLAN symposium on Principles and practice of parallel programming},
year = {2005},
month = {January},
abstract = {Writing concurrent programs is notoriously difﬁcult, and is of increasing practical importance. A particular source of concern is that even correctly-implemented concurrency abstractions cannot be composed together to form larger abstractions. In this paper we present a new concurrency model, based on transactional memory, that offers far richer composition. All the usual beneﬁts of transactional memory are present (e.g. freedom from deadlock), but in addition we describe new modular forms of blocking and choice that have been inaccessible in earlier work.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/composable-memory-transactions/},
pages = {48-60},
isbn = {1-59593-080-9},
edition = {PPoPP '05: Proceedings of the tenth ACM SIGPLAN symposium on Principles and practice of parallel programming},
}
@unpublished{dybvig2005a,
author = {Dybvig, Kent and Peyton Jones, Simon and Sabry, Amr},
title = {A Monadic Framework for Delimited Continuations},
year = {2005},
month = {January},
abstract = {Delimited continuations are more expressive than traditional abortive continuations and they apparently require a framework beyond traditional continuation-passing style (CPS). We show that this is not the case: standard CPS is sufficient to explain the common control operators for delimited continuations. We demonstrate this fact and present an implementation as a Scheme library. We then investigate a typed account of delimited continuations that makes explicit where control effects can occur. This results in a monadic framework for typed and encapsulated delimited continuations which we design and implement as a Haskell library.},
url = {https://www.microsoft.com/en-us/research/publication/a-monadic-framework-for-delimited-continuations/},
note = {Submitted to Journal of Functional Programming},
}
@inproceedings{peytonjones2005associated,
author = {Peyton Jones, Simon},
title = {Associated types with class},
booktitle = {POPL '05: Proceedings of the 32nd ACM SIGPLAN-SIGACT sysposium on Principles of programming languages},
year = {2005},
month = {January},
abstract = {In this paper, we explore an extension to Haskell type classes that allows a type class declaration to define data types as well as values (or methods). Similarly, an instance declaration gives a witness for such data types, as well as a witness for each method. It turns out that this extension directly supports the idea of a type-indexed type, and is useful in many applications, especially for self-optimising libraries that adapt their data representations and algorithms in a type-directed manner.
Crucially, just as Haskell's existing type-class mechanism can be explained by translation into System F, so we can explain our extension by translation into System F, and we do so in full detail. This is a valuable property since it ensures that the addition of associated data types to an existing Haskell compiler leads to changes in the front end only. assoc




In this paper, we explore an extension to Haskell type classes that allows a type class declaration to define data types as well as values (or methods). Similarly, an instance declaration gives a witness for such data types, as well as a witness for each method. It turns out that this extension directly supports the idea of a type-indexed type, and is useful in many applications, especially for self-optimising libraries that adapt their data representations and algorithms in a type-directed manner.

Crucially, just as Haskell's existing type-class mechanism can be explained by translation into System F, so we can explain our extension by translation into System F, and we do so in full detail. This is a valuable property since it ensures that the addition of associated data types to an existing Haskell compiler leads to changes in the front end only.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/associated-types-with-class/},
pages = {1–13},
isbn = {1-58113-830-X},
edition = {POPL '05: Proceedings of the 32nd ACM SIGPLAN-SIGACT sysposium on Principles of programming languages},
}
@inproceedings{harris2005haskell,
author = {Harris, Tim and Marlow, Simon and Peyton Jones, Simon},
title = {Haskell on a Shared-Memory Multiprocessor},
booktitle = {Haskell '05: Proceedings of the 2005 ACM SIGPLAN workshop on Haskell},
year = {2005},
month = {September},
abstract = {Multi-core processors are coming, and we need ways to program them. The combination of purely-functional programming and explicit, monadic threads, communicating using transactional memory, looks like a particularly promising way to do so. This paper describes a full-scale implementation of shared-memory parallel Haskell, based on the Glasgow Haskell Compiler. Our main technical contribution is a lock-free mechanism for evaluating shared thunks that eliminates the major performance bottleneck in parallel evaluation of a lazy language. Our results are preliminary but promising: we can demonstrate wall-clock speedups of a serious application (GHC itself), even with only two processors, compared to the same application compiled for a uni-processor.},
url = {https://www.microsoft.com/en-us/research/publication/haskell-on-a-shared-memory-multiprocessor/},
pages = {49-61},
edition = {Haskell '05: Proceedings of the 2005 ACM SIGPLAN workshop on Haskell},
}
@unpublished{sulzmann2006understanding,
author = {Sulzmann, Martin and Duck, Gregory and Peyton Jones, Simon and Stuckey, Peter},
title = {Understanding functional dependencies via constraint handling rules},
year = {2006},
month = {January},
abstract = {Functional dependencies are a popular and useful extension to Haskell style type classes. In this paper, we give a reformulation of functional dependencies in terms of Constraint Handling Rules (CHRs). In previous work, CHRs have been employed for describing user-programmable type extensions in the context of Haskell style type classes. Here, we make use of CHRs to provide for the first time a concise result that under some sufficient conditions, functional dependencies allow for sound, complete and decidable type inference. The sufficient conditions imposed on functional dependencies can be very limiting. We show how to safely relax these conditions and suggest several sound extensions of functional dependencies. Our results allow for a better understanding of functional dependencies and open up the opportunity for new applications.},
url = {https://www.microsoft.com/en-us/research/publication/understanding-functional-dependencies-via-constraint-handling-rules/},
edition = {To appear in the Journal of Functional Programming},
note = {To appear in the Journal of Functional Programming},
}
@inproceedings{vytiniotis2006boxy,
author = {Vytiniotis, Dimitrios and Weirich, Stephanie and Peyton Jones, Simon},
title = {Boxy type inference for higher-rank types and impredicativity},
booktitle = {ICFP 2006},
year = {2006},
month = {January},
abstract = {Languages with rich type systems are beginning to employ a blend of type inference and type checking, so that the type inference engine is guided by programmer-supplied type annotations. In this paper we show, for the ﬁrst time, how to combine the virtues of two well-established ideas: uniﬁcation-based inference, and bidirectional propagation of type annotations. The result is a type system that conservatively extends Hindley-Milner, and yet supports both higher-rank types and impredicativity.

 	Accompanying technical report PDF 
 	Related papers},
url = {https://www.microsoft.com/en-us/research/publication/boxy-type-inference-for-higher-rank-types-and-impredicativity/},
pages = {251-262},
edition = {ICFP 2006},
}
@inproceedings{peytonjones2006haskell,
author = {Peyton Jones, Simon},
title = {Haskell Is Not Not ML},
booktitle = {European Symposium on Programming, ESOP},
year = {2006},
month = {January},
abstract = {We present a typed calculus IL ("intermediate language") which supports the embedding of ML-like (strict, eager) and Haskell-like (non-strict, lazy) languages, without favoring either. IL's type system includes negation (continuations), but not implication (function arrow). Within IL we find that lifted sums and products can be represented as the double negation of their unlifted counterparts. We exhibit a compilation function from IL to AM --- an abstract von Neumann machine --- which maps values of ordinary and doubly negated types to heap structures resembling those found in practical implementations of languages in the ML and Haskell families. Finally, we show that a small variation in the design of AM allows us to treat any ML value as a Haskell value at runtime without cost, and project a Haskell value onto an ML type with only the cost of a Haskell deepSeq. This suggests that IL and AM may be useful as a compilation and execution model for a new language which combines the best features of strict and non-strict functional programming.},
url = {https://www.microsoft.com/en-us/research/publication/haskell-is-not-not-ml/},
pages = {38-53},
edition = {European Symposium on Programming, ESOP},
}
@inproceedings{harris2006lock,
author = {Harris, Tim and Marlow, Simon and Peyton Jones, Simon and Singh, Satnam},
title = {Lock Free Data Structures using STMs in Haskell},
booktitle = {FLOPS '06: Proceedings of the Eighth International Symposium on Functional and Logic Programming, to appear},
year = {2006},
month = {April},
abstract = {This paper explores the feasibility of re-expressing concurrent algorithms with explicit locks in terms of lock free code written using Haskell’s implementation of software transactional memory. Experimental results are presented which show that for multi-processor systems the simpler lock free implementations offer superior performance when compared to their corresponding lock based implementations.},
url = {https://www.microsoft.com/en-us/research/publication/lock-free-data-structures-using-stms-in-haskell/},
edition = {FLOPS '06: Proceedings of the Eighth International Symposium on Functional and Logic Programming, to appear},
}
@inproceedings{vytiniotis2006simple,
author = {Vytiniotis, Dimitrios and Weirich, Stephanie and Peyton Jones, Simon},
title = {Simple unification-based type inference for GADTs},
organization = {ACM SIGPLAN},
booktitle = {International Conference on Functional Programming (ICFP'06)},
year = {2006},
month = {April},
abstract = {Generalized algebraic data types (GADTs), sometimes known as "guarded recursive data types" or "first-class phantom types", are a simple but powerful generalization of the data types of Haskell and ML. Recent works have given compelling examples of the utility of GADTs, although type inference is known to be difficult. Our contribution is to show how to exploit programmer-supplied type annotations to make the type inference task almost embarrassingly easy. Our main technical innovation is wobbly types, which express in a declarative way the uncertainty caused by the incremental nature of typical type-inference algorithms.

 	Related papers},
url = {https://www.microsoft.com/en-us/research/publication/simple-unification-based-type-inference-for-gadts/},
note = {2016 ACM SIGPLAN Most Influential ICFP Paper Award},
}
@inproceedings{harris2006transactional,
author = {Harris, Tim and Peyton Jones, Simon},
title = {Transactional memory with data invariants},
booktitle = {First ACM SIGPLAN Workshop on Languages, Compilers, and Hardware Support for Transactional Computing (TRANSACT'06)},
year = {2006},
month = {June},
abstract = {This paper introduces a mechanism for asserting invariants that are maintained by a program that uses atomic memory transactions. The idea is simple: a programmer writes check E where E is an expression that should be preserved by every atomic update for the remainder of the program's execution. We have extended STM Haskell to dynamically evaluate check statements atomically with the user's updates: the result is that we can identify precisely which update is the first one to break an invariant.},
url = {https://www.microsoft.com/en-us/research/publication/transactional-memory-data-invariants/},
edition = {First ACM SIGPLAN Workshop on Languages, Compilers, and Hardware Support for Transactional Computing (TRANSACT'06)},
}
@misc{peytonjones2006demand,
author = {Peyton Jones, Simon and Sestoft, Peter and Hughes, John},
title = {Demand Analysis},
year = {2006},
month = {July},
abstract = {Any decent optimising compiler for a lazy language like Haskell must include a strictness analyser. The results of this analysis allow the compiler to use call-by-value instead of call-by-need, and that leads to big performance improvements. It turns out that strictness analysis is an interesting problem from a theoretical point of view, and the 1980's saw a huge rash of papers on the subject. There were fewer, many, many fewer, papers that described real implementations.

This paper presents the fruits of a decade-long experience with strictness analysis, in the context of the Glasgow Haskell Compiler, an optimising compiler for Haskell. In particular, we recently re-engineered the existing strictness analyser that used forward abstract interpretation, replacing it with a new one that uses backward analysis instead.

This (never published) version of the paper is subsumed by our later revision, and is left here only for historical interest.

 

 },
url = {https://www.microsoft.com/en-us/research/publication/demand-analysis/},
}
@inproceedings{marlow2006asynchronous,
author = {Marlow, Simon and Peyton Jones, Simon and Moran, Andrew and Reppy, John},
title = {Asynchronous exceptions in Haskell},
booktitle = {ACM Conference on Programming Languages Design and Implementation (PLDI'01)},
year = {2006},
month = {December},
abstract = {Asynchronous exceptions, such as timeouts, are important for robust, modular programs, but are extremely difficult to program with --- so much so that most programming languages either heavily restrict them or ban them altogether. We extend our earlier work, in which we added synchronous exceptions to Haskell, to support asynchronous exceptions too. Our design introduces scoped combinators for blocking and unblocking asynchronous interrupts, along with a somewhat surprising semantics for operations that can suspend. Uniquely, we also give a formal semantics for our system.

This paper is a heavily-rewritten version of the paper we presented at the Workshop on High Level Concurrent Languages, Montreal, Sept 2000 (no proceedings).},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/asynchronous-exceptions-haskell-3/},
pages = {274-285},
edition = {ACM Conference on Programming Languages Design and Implementation (PLDI'01)},
}
@inbook{peytonjones2007beautiful,
author = {Peyton Jones, Simon},
title = {Beautiful concurrency},
booktitle = {Beautiful code},
year = {2007},
month = {January},
abstract = {The free lunch is over. We have grown used to the idea that our programs will go faster when we buy a next-generation processor, but that time has passed. While that next-generation chip will have more CPUs, each individual CPU will be no faster than the previous year's model. If we want our programs to run faster, we must learn to write parallel programs.

Parallel programs execute in a non-deterministic way, so they are hard to test and bugs can be almost impossible to reproduce. For me, a beautiful program is one that is so simple and elegant that it obviously has no mistakes, rather than merely having no obvious mistakes. If we want to write parallel programs that work reliably, we must pay particular attention to beauty. Sadly, parallel programs are often less beautiful than their sequential cousins; in particular they are, as we shall see, less modular.

In this tutorial chapter I describe Software Transactional Memory (STM), a promising new approach to programming shared-memory parallel processors, that seems to support modular programs in a way that current technology does not. By the time we are done, I hope you will be as enthusiastic as I am about STM. It is not a solution to every problem, but it is a beautiful and inspiring attack on the daunting ramparts of concurrency.

 	Code download (Cabalised) 
 	Discussion wiki page

 },
publisher = {O'Reilly},
url = {https://www.microsoft.com/en-us/research/publication/beautiful-concurrency/},
edition = {Beautiful code},
}
@inproceedings{chakravarty2007data,
author = {Chakravarty, Manuel and Leshchinskiy, Roman and Peyton Jones, Simon and Keller, Gabriele},
title = {Data Parallel Haskell: a status report},
booktitle = {ACM Sigplan Workshop on Declarative Aspects of Multicore Programming},
year = {2007},
month = {January},
abstract = {We describe the design and current status of our effort to implement the programming model of nested data parallelism into the Glasgow Haskell Compiler. We extended the programming model and its implementation, both of which were first popularised by the NESL language, in terms of expressiveness as well as efficiency of its implementation. Our current aim is to provide a convenient programming environment for SMP parallelism, and especially multicore architectures. Preliminary benchmarks show that we are, at least for some programs, able to achieve good absolute performance and excellent speedups.

 	Slides of a talk about Data Parallel Haskell: PDF},
url = {https://www.microsoft.com/en-us/research/publication/data-parallel-haskell-a-status-report/},
edition = {ACM Sigplan Workshop on Declarative Aspects of Multicore Programming},
}
@unpublished{peytonjones2007call-pattern,
author = {Peyton Jones, Simon},
title = {Call-pattern specialisation for Haskell programs},
year = {2007},
month = {January},
abstract = {User-defined data types, pattern-matching, and recursion are ubiquitous features of Haskell programs. Sometimes a function is called with arguments that are statically known to already be in constructor form, so that the work of pattern-matching is wasted. Even worse, the argument is sometimes freshly-allocated, only to be immediately decomposed by the function.

In this paper we describe a simple, modular transformation that specialises recursive functions according to their argument ``shapes''. We show that such a transformation has a simple, modular implementation, and that it can be extremely effective in practice, eliminating both pattern-matching and heap allocation. We describe our implementation of this constructor specialisation transformation in the Glasgow Haskell Compiler, and give measurements of its effectiveness.

See also "Stream Fusion From Lists to Streams to Nothing at All" by Coutts, Leshchinskiy, and Stewart.

 	Wiki talk page for discussion

 },
url = {https://www.microsoft.com/en-us/research/publication/system-f-with-type-equality-coercions-2/},
edition = {Submitted to ICFP 2007},
note = {Submitted to ICFP 2007},
}
@misc{schrijvers2007towards,
author = {Schrijvers, Tom and Sulzmann, Martin and Peyton Jones, Simon and Chakravarty, Manuel},
title = {Towards open type functions for Haskell},
year = {2007},
month = {January},
abstract = {We report on an extension of Haskell with type(-level) functions and equality constraints. We illustrate their usefulness in the context of phantom types, GADTs and type classes. Problems in the context of type checking are identified and we sketch our solution: a decidable type checking algorithm for a restricted class of type functions. Moreover, functional dependencies are now obsolete: we show how they can be encoded as type functions.},
url = {https://www.microsoft.com/en-us/research/publication/towards-open-type-functions-haskell/},
edition = {Presented at the Implementing Functional Languages workshop, Sept 2007 (IFL07), but not part of its post-refereed proceedings.},
note = {Presented at the Implementing Functional Languages workshop, Sept 2007 (IFL07), but not part of its post-refereed proceedings.},
}
@inproceedings{peytonjones2007a,
author = {Peyton Jones, Simon},
title = {A History of Haskell: being lazy with class},
booktitle = {The Third ACM SIGPLAN History of Programming Languages Conference (HOPL-III)},
year = {2007},
month = {June},
abstract = {This long (55-page) paper describes the history of Haskell, including its genesis and principles, technical contributions, implementations and tools, and applications and impact.

You might also be interested in Simon's POPL'03 talk: A retrospective on Haskell

Watch below a video of the talk, the video starts a minute or so into the talk, but nothing important is missing.},
url = {https://www.microsoft.com/en-us/research/publication/a-history-of-haskell-being-lazy-with-class/},
edition = {The Third ACM SIGPLAN History of Programming Languages Conference (HOPL-III)},
}
@inproceedings{peytonjones2007comprehensive,
author = {Peyton Jones, Simon and Wadler, Philip},
title = {Comprehensive comprehensions: comprehensions with "order by" and "group by"},
booktitle = {Haskell Workshop 2007},
year = {2007},
month = {September},
abstract = {We propose an extension to list comprehensions that makes it easy to express the kind of queries one would write in SQL using ORDER BY, GROUP BY, and LIMIT. Our extension adds expressive power to comprehensions, and generalises the SQL constructs that inspired it. Moreover, it is easy to implement, using simple desugaring rules.

For example, consider this SQL query
 SELECT dept, SUM(salary)
FROM employees
GROUP BY dept
ORDER BY SUM(salary) DESCENDING
LIMIT 5 
The GROUP BY clause groups records together; the ORDER BY sorts the departments in order of salary bill; and the LIMIT clause picks just the first five records. This support for grouping and sorting is extremely useful in practice, but is not available in list comprehensions.

In this paper we propose an extension to list comprehensions that makes it easy to express the kind of queries one would write in SQL using ORDER BY, GROUP BY, and LIMIT. Here, for example, is how the above SQL query would be rendered in our extension.
 [ (the dept, sum salary)
| (name, dept, salary) <- employees
, group by dept
, order by Down (sum salary)
, order using take 5 ] 
Moreover, our extensions are significantly more general than SQL's facilities.

 	Wiki talk page for discussion},
url = {https://www.microsoft.com/en-us/research/publication/comprehensive-comprehensions-comprehensions-with-order-by-and-group-by/},
pages = {61-72},
edition = {Haskell Workshop 2007},
}
@inproceedings{li2007lightweight,
author = {Li, Peng and Tolmach, Andrew and Marlow, Simon and Peyton Jones, Simon},
title = {Lightweight concurrency primitives for GHC},
booktitle = {Haskell Workshop 2007},
year = {2007},
month = {September},
abstract = {The Glasgow Haskell Compiler (GHC) has quite sophisticated support for concurrency in its runtime system, which is written in low-level C code. As GHC evolves, the runtime system becomes increasingly complex, error-prone, difficult to maintain and difficult to add new concurrency features.

This paper presents an alternative approach to implement concurrency in GHC. Rather than hard-wiring all kinds of concurrency features, the runtime system is a thin substrate providing only a small set of concurrency primitives, and the rest of concurrency features are implemented in software libraries written in Haskell. This design improves the safety of concurrency support; it also provides more customizability of concurrency features, as new concurrency features can be developed as Haskell library packages and deployed modularly.

 	Wiki talk page for discussion},
url = {https://www.microsoft.com/en-us/research/publication/lightweight-concurrency-primitives-for-ghc/},
edition = {Haskell Workshop 2007},
}
@inproceedings{peytonjones2007faster,
author = {Peyton Jones, Simon},
title = {Faster laziness using dynamic pointer tagging},
booktitle = {ICFP '07: Proceedings of the ACM SIGPLAN international conference on Functional programming},
year = {2007},
month = {October},
abstract = {In the light of evidence that Haskell programs compiled by GHC exhibit large numbers of mispredicted branches on modern processors, we re-examine the "tagless" aspect of the STG-machine that GHC uses as its evaluation model.

We propose two tagging strategies: a simple strategy called semi-tagging that seeks to avoid one common source of unpredictable indirect jumps, and a more complex strategy called dynamic pointer-tagging that uses the spare low bits in a pointer to encode information about the pointed-to object. Both of these strategies have been implemented and exhaustively measured in the context of a production compiler, GHC, and the paper contains detailed descriptions of the implementations. Our measurements demonstrate significant performance improvements (14% for dynamic pointer-tagging with only a 2% increase in code size), and we further demonstrate that much of the improvement can be attributed to the elimination of mispredicted branch instructions.

As part of our investigations we also discovered that one optimisation in the STG-machine, vectored-returns, is no longer worthwhile and we explain why.

 	Wiki talk page for discussion},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/faster-laziness-using-dynamic-pointer-tagging/},
edition = {ICFP '07: Proceedings of the ACM SIGPLAN international conference on Functional programming},
}
@inproceedings{chakravarty2008partial,
author = {Chakravarty, Manuel MT and Leshchinskiy, Roman and Peyton Jones, Simon and Keller, Gabriele},
title = {Partial vectorisation of Haskell programs},
booktitle = {Proc ACM Workshop on Declarative Aspects of Multicore Programming},
year = {2008},
month = {January},
abstract = {Vectorisation for functional programs, also called the flattening transformation, relies on drastically reordering computations and restructuring the representation of data types. As a result, it only applies to the purely functional core of a fully-fledged functional language, such as Haskell or ML. A concrete implementation needs to apply vectorisation selectively and integrate vectorised with unvectorised code. This is challenging, as vectorisation alters the data representation, which must be suitably converted between vectorised and unvectorised code. In this paper, we present an approach to partial vectorisation that selectively vectorises sub-expressions and data types, and also, enables linking vectorised with unvectorised modules.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/partial-vectorisation-of-haskell-programs/},
edition = {Proc ACM Workshop on Declarative Aspects of Multicore Programming},
}
@inproceedings{schrijvers2008type,
author = {Schrijvers, Tom and Peyton Jones, Simon and Chakravarty, Manuel and Sulzmann, Martin},
title = {Type Checking with Open Type Functions},
booktitle = {ICFP 2008},
year = {2008},
month = {April},
abstract = {We report on an extension of Haskell with open type-level functions and equality constraints that unifies earlier work on GADTs, functional dependencies, and associated types. The contribution of the paper is that we identify and characterise the key technical challenge of entailment; and we give a novel, decidable, sound, and complete algorithm to solve it, together with some practically-important variants. Our system is implemented in GHC, and is already in active use.},
url = {https://www.microsoft.com/en-us/research/publication/type-checking-with-open-type-functions/},
edition = {ICFP 2008},
note = {Submitted to ICFP'08},
}
@inproceedings{marlow2008parallel,
author = {Marlow, Simon and Harris, Tim and Peyton Jones, Simon},
title = {Parallel Generational-Copying Garbage Collection with a Block-Structured Heap},
booktitle = {ISMM '08: Proceedings of the 7th international symposium on Memory management},
year = {2008},
month = {June},
abstract = {We present a parallel generational-copying garbage collector implemented for the Glasgow Haskell Compiler. We use a block-structured memory allocator, which provides a natural granularity for dividing the work of GC between many threads, leading to a simple yet effective method for parallelising copying GC. The results are encouraging: we demonstrate wall-clock speedups of on average a factor of 2 in GC time on a commodity 4-core machine with no programmer intervention, compared to our best sequential GC.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/parallel-generational-copying-garbage-collection-with-a-block-structured-heap/},
edition = {ISMM '08: Proceedings of the 7th international symposium on Memory management},
}
@inproceedings{jay2008scrap,
author = {Jay, Barry and Peyton Jones, Simon},
title = {Scrap your type applications},
booktitle = {Mathematics of Program Construction (MPC'08)},
year = {2008},
month = {July},
abstract = {System F is ubiquitous in logic, theorem proving, language meta-theory, compiler intermediate languages, and elsewhere. Along with its type abstractions come type applications, but these often appear redundant. This redundancy is both distracting and costly for type-directed compilers.

We introduce System IF[], for implicit System F, in which many type applications can be made implicit. It supports decidable type checking and strong normalisation. Experiments with Haskell suggest that it could be used to reduce the amount of intermediate code in compilers that employ System F.

System IF constitutes a first foray into a new area in the design space of typed lambda calculi, that is both useful in practice and interesting in its own right.

 },
url = {https://www.microsoft.com/en-us/research/publication/scrap-your-type-applications/},
edition = {Mathematics of Program Construction (MPC'08)},
}
@inproceedings{peytonjones2008static,
author = {Peyton Jones, Simon},
title = {Static Contract Checking for Haskell},
organization = {University of Cambridge},
booktitle = {POPL'09},
year = {2008},
month = {August},
abstract = {Program errors are hard to detect and are costly both to programmers who spend significant efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C#, but few have been applied to a higher-order lazy functional language, like Haskell. In this paper, we describe a sound and automatic static verification tool for Haskell, that is based on contracts and symbolic execution. Our approach is modular and gives precise blame assignments at compile-time in the presence of higher-order functions and laziness.

Errata. In Figure 2, in the right hand side of rule [E-match1], the ai and xi should both have vector arrows over them.

 	Slides (PDF) of a talk given at the Midlands Graduate School Christmas Lectures, 2007.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/static-contract-checking-for-haskell/},
pages = {41-52},
edition = {POPL'09},
}
@inproceedings{vytiniotis2008fph,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Weirich, Stephanie},
title = {FPH: First-class polymorphism for Haskell},
booktitle = {Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming},
year = {2008},
month = {September},
abstract = {Languages supporting polymorphism typically have ad-hoc restrictions on where polymorphic types may occur. Supporting "firstclass" polymorphism, by lifting those restrictions, is obviously desirable, but it is hard to achieve this without sacrificing type inference. We present a new type system for higher-rank and impredicative polymorphism that improves on earlier proposals: it is an extension of Damas-Milner; it relies only on System F types; it has a simple, declarative specification; it is robust to program transformations; and it enjoys a complete and decidable type inference algorithm.},
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/fph-first-class-polymorphism-for-haskell/},
edition = {Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming},
}
@inproceedings{peytonjones2008harnessing,
author = {Peyton Jones, Simon and Leshchinskiy, Roman and Keller, Gabriele and Chakravarty, Manuel MT},
title = {Harnessing the multicores: Nested Data Parallelism in Haskell},
booktitle = {Foundations of Software Technology and Theoretical Computer Science (FSTTCS'08)},
year = {2008},
month = {December},
abstract = {If you want to program a parallel computer, a purely functional language like Haskell is a promising starting point. Since the language is pure, it is by-default safe for parallel evaluation, whereas imperative languages are by-default unsafe. But that doesn’t make it easy! Indeed it has proved quite difficult to get robust, scalable performance increases through parallel functional programming, especially as the number of processors increases.

A particularly promising and well-studied approach to employing large numbers of processors is data parallelism. Blelloch’s pioneering work on NESL showed that it was possible to combine a rather flexible programming model (nested data parallelism) with a fast, scalable execution model (flat data parallelism). In this paper we describe Data Parallel Haskell, which embodies nested data parallelism in a modern, general-purpose language, implemented in a state-of-the-art compiler, GHC.We focus particularly on the vectorisation transformation, which transforms nested to flat data parallelism.

Slides of a talk on this paper, given at North Eastern April 2010:

 	Slides in PowerPoint 
 	Slides in PDF 

 },
url = {https://www.microsoft.com/en-us/research/publication/harnessing-the-multicores/},
edition = {Foundations of Software Technology and Theoretical Computer Science (FSTTCS'08)},
}
@unpublished{peytonjones2009haskell,
author = {Peyton Jones, Simon},
title = {Haskell and Erlang: growing up together (2009)},
year = {2009},
month = {January},
abstract = {Haskell and Erlang were both born around 1990, with a common commitment to functional programmin. Although they have very different genealogies, and subsequent evolution paths, they are both gaining increasing mind-share as 2010 approaches. In my talk I'll contrast the two languages, paying particular attention to (a) types and (b) concurrency.},
url = {https://www.microsoft.com/en-us/research/publication/haskell-erlang-growing-together-2009/},
edition = {My invited talk from the Erlang Factory meeting, in June 2009},
note = {My invited talk from the Erlang Factory meeting, in June 2009},
}
@misc{kiselyov2009fun,
author = {Kiselyov, Oleg and Peyton Jones, Simon and Shan, Chung-chieh},
title = {Fun with type functions},
year = {2009},
month = {April},
abstract = {Tony Hoare has always been a leader in writing down and proving properties of programs. To prove properties of programs automatically, the most widely used technology today is by far the ubiquitous type checker. Alas, static type systems inevitably exclude some good programs and allow some bad ones. This dilemma motivates us to describe some fun we've been having with Haskell, by making the type system more expressive without losing the benefits of automatic proof and compact expression.

Haskell's type system extends Hindley-Milner with two distinctive features: polymorphism over type constructors and overloading using type classes. These features have become integral to Haskell, and they are widely used and appreciated. More recently, Haskell has been enriched with type families, which allows functions on types to be expressed as straightforwardly as functions on values. This facility makes it easier for programmers to effectively extend the compiler by writing functional programs that execute during type-checking.

This paper gives a programmer's tour of type families as they are supported in GHC today.

 	wiki page for comment and discussion
 	source code
 	slides

 },
url = {https://www.microsoft.com/en-us/research/publication/fun-type-functions/},
edition = {Presented at Tony Hoare's 75th birthday celebration, Cambridge, 17 April 2009.},
note = {Presented at Tony Hoare's 75th birthday celebration, Cambridge, 17 April 2009.},
}
@inbook{singh2009a,
author = {Singh, Satnam and Peyton Jones, Simon},
title = {A Tutorial on Parallel and Concurrent Programming in Haskell},
series = {Lecture Notes in Computer Science},
booktitle = {Advanced Functional Programming Summer School 2008},
year = {2009},
month = {May},
abstract = {This practical tutorial introduces the features available in Haskell for writing parallel and concurrent programs. We first describe how to write semi-explicit parallel programs by using annotations to express opportunities for parallelism and to help control the granularity of parallelism for effective execution on modern operating systems and processors. We then describe the mechanisms provided by Haskell for writing explicitly parallel programs with a focus on the use of software transactional memory to help share information between threads. Finally, we show how nested data parallelism can be used to write deterministically parallel programs which allows programmers to use rich data types in data parallel programs which are automatically transformed into flat data parallel versions for efficient execution on multi-core processors.},
publisher = {Springer Verlag},
url = {https://www.microsoft.com/en-us/research/publication/a-tutorial-on-parallel-and-concurrent-programming-in-haskell/},
edition = {Advanced Functional Programming Summer School 2008},
}
@inproceedings{allwood2009finding,
author = {Allwood, Tristan and Peyton Jones, Simon and Eisenbach, Susan},
title = {Finding the needle: stack tracing for GHC},
booktitle = {ACM Symposium on Haskell},
year = {2009},
month = {May},
abstract = {Even Haskell programs can occasionally go wrong. Programs calling head onanemptylist,andincompletepatternsinfunctiondefinitions can cause program crashes, reporting little more than the preciselocationwhere error wasultimatelycalled.Beingtoldthat one application of the head function in your program went wrong, withoutknowingwhichuseofhead wentwrongcanbeinfuriating. Wepresentourworkonaddingtheabilitytogetstacktracesout of GHC, for example that our crashing head was used during the evaluation of foo, which was called during the evaluation of bar, during the evaluation of main. We provide a transformation that converts GHC Core programs into ones that pass a stack around, and a stack library that ensures bounded heap usage despite the highly recursive nature of Haskell. We call our extension to GHC StackTrace.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/finding-the-needle-stack-tracing-for-ghc/},
edition = {ACM Symposium on Haskell},
}
@inproceedings{peytonjones2009types,
author = {Peyton Jones, Simon and Bolingbroke, Max},
title = {Types are calling conventions},
booktitle = {ACM Haskell Symposium},
year = {2009},
month = {May},
abstract = {It is common for compilers to derive the calling convention of a function from its type. Doing so is simple and modular but misses many optimisation opportunities, particularly in lazy, higher-order functional languages with extensive use of currying. We restore the lost opportunities by defining Strict Core, a new intermediate language whose type system makes the missing distinctions: laziness is explicit, and functions take multiple arguments and return multiple results.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/types-are-calling-conventions/},
edition = {ACM Haskell Symposium},
}
@unpublished{peytonjones2009classes,
author = {Peyton Jones, Simon},
title = {Classes, Jim, but not as we know them (2009)},
year = {2009},
month = {July},
abstract = {Haskell is now quite widely used, but its most important contributions are the ideas that it embodies. In this talk I will focus on one of these ideas, namely type classes, with a few anecdotes and reflections along the way about the process of developing the language.

Type classes are probably Haskell's most distinctive feature. The original idea is very neat and, better still, it led to a long series of subsequent generalisations and innovations. Indeed, although the language is now nineteen years old, Haskell's type system is still in a state of furious development. For example, I am involved in adding type-level functions to Haskell, as I will briefly describe.

I will explain what type classes are, how they differ from the classes of mainstream object oriented languages, why I think they are so cool, and what the hot topics are. I'll give plenty of examples, so you don't need to already know Haskell.

 },
url = {https://www.microsoft.com/en-us/research/publication/classes-jim-not-know-2009/},
edition = {This is my invited talk for ECOOP 2009},
note = {This is my invited talk for ECOOP 2009},
}
@inproceedings{schrijvers2009complete,
author = {Schrijvers, Tom and Peyton Jones, Simon and Sulzmann, Martin and Vytiniotis, Dimitrios},
title = {Complete and Decidable Type Inference for GADTs},
booktitle = {Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
year = {2009},
month = {September},
abstract = {GADTs have proven to be an invaluable language extension, a.o. for ensuring data invariants and program correctness. Unfortunately, they pose a tough problem for type inference: we lose the principal-type property, which is necessary for modular type inference.

We present a novel and simplified type inference approach for local type assumptions from GADT pattern matches. Our approach is complete and decidable, while more liberal than previous such approaches.


 

The main PDF above is a slightly corrected version of the paper as published by ACM, which is here.

 },
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/complete-and-decidable-type-inference-for-gadts/},
edition = {Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
note = {This new paper comes with a prototype implementation for a Haskell-like language, available for download.},
}
@inproceedings{marlow2009runtime,
author = {Marlow, Simon and Peyton Jones, Simon and Singh, Satnam},
title = {Runtime Support for Multicore Haskell},
booktitle = {Submitted to the International on Functional Programming (ICFP) 2009},
year = {2009},
month = {September},
abstract = {Purely functional programs should run well on parallel hardware because of the absence of side effects, but it has proved hard to realise this potential in practice. Plenty of papers describe promising ideas, but vastly fewer describe real implementations with good wall-clock performance. We describe just such an implementation, and quantitatively explore some of the complex design tradeoffs that make such implementations hard to build. Our measurements are necessarily detailed and specific, but they are reproducible, and we believe that they offer some general insights.},
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/runtime-support-for-multicore-haskell/},
edition = {Submitted to the International on Functional Programming (ICFP) 2009},
}
@inproceedings{vytiniotis2010let,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Schrijvers, Tom},
title = {Let Should Not Be Generalised},
booktitle = {Proceedings of the 5th ACM SIGPLAN Workshop on Types in Language Design and Implementation},
year = {2010},
month = {January},
abstract = {From the dawn of time, all derivatives of the classic Hindley-Milner type system have supported implicit generalisation of local let-bindings. Yet, as we will show, for more sophisticated type systems implicit let-generalisation imposes a disproportionate complexity burden. Moreover, it turns out that the feature is very seldom used, so we propose to eliminate it. The payoff is a substantial simplification, both of the specification of the type system, and of its implementation.},
publisher = {Association for Computing Machinery, Inc.},
url = {https://www.microsoft.com/en-us/research/publication/let-should-not-be-generalised/},
edition = {Proceedings of the 5th ACM SIGPLAN Workshop on Types in Language Design and Implementation},
}
@inproceedings{keller2010regular,
author = {Keller, Gabriele and Chakravarty, Manuel and Leshchinskiy, Roman and Peyton Jones, Simon},
title = {Regular, shape-polymorphic, parallel arrays in Haskell},
booktitle = {To appear at ICFP'10},
year = {2010},
month = {January},
abstract = {We present a novel approach to regular, multi-dimensional arrays in Haskell. The main highlights of our approach are that it (1) is purely functional, (2) supports reuse through shape polymorphism, (3) avoids unnecessary intermediate structures rather than relying on subsequent loop fusion, and (4) supports transparent parallelisation. We show how to embed two forms of shape polymorphism into Haskell's type system using type classes and type families. In particular, we discuss the generalisation of regular array transformations to arrays of higher rank, and introduce a type-safe specification of array slices. We discuss the runtime performance of our approach for three standard array algorithms. We achieve absolute performance comparable to handwritten C code. At the same time, our implementation scales well up to 8 processor cores.

 	Online tutorial about Repa},
url = {https://www.microsoft.com/en-us/research/publication/regular-shape-polymorphic-parallel-arrays-in-haskell/},
edition = {To appear at ICFP’10},
}
@inproceedings{bolingbroke2010supercompilation,
author = {Bolingbroke, Max and Peyton Jones, Simon},
title = {Supercompilation by evaluation},
booktitle = {Haskell Symposium 2010},
year = {2010},
month = {January},
abstract = {Supercompilation is a technique due to Turchin which allows for the construction of program optimisers that are both simple and extremely powerful. Supercompilation is capable of achieving transformations such as deforestation, function specialisation and constructor specialisation. Inspired by Mitchell's promising results (ICFP'10), we show how the call-by-need supercompilation algorithm can be recast to be based explicitly on an evaluator, and in the process extend it to deal with recursive let-expressions.},
url = {https://www.microsoft.com/en-us/research/publication/supercompilation-by-evaluation/},
edition = {Haskell Symposium 2010},
}
@misc{ramsey2010hoopl,
author = {Ramsey, Norman and Dias, John and Peyton Jones, Simon},
title = {Hoopl: A Modular, Reusable Library for Dataflow Analysis and Transformation},
year = {2010},
month = {January},
abstract = {Dataflow analysis and transformation of control-flow graphs is pervasive in optimizing compilers, but it is typically tightly interwoven with the details of a particular compiler. We describe Hoopl, a reusable Haskell library that makes it unusually easy to define new analyses and transformations for any compiler. Hoopl's interface is modular and polymorphic, and it offers unusually strong static guarantees. The implementation is also far from routine: it encapsulates state-of-the-art algorithms (interleaved analysis and rewriting, dynamic error isolation), and it cleanly separates their tricky elements so that they can be understood independently.

An earlier version of this paper was rejected by POPL 2010. The new paper is quite different to the old, so the latter may still be of some interest because it gives more examples of Hoopl clients. POPL submission PDF},
url = {https://www.microsoft.com/en-us/research/publication/hoopl-modular-reusable-library-dataflow-analysis-transformation/},
edition = {Haskell Symposium 2010},
note = {Haskell Symposium 2010},
}
@inproceedings{weirich2011generative,
author = {Weirich, Stephanie and Vytiniotis, Dimitrios and Peyton Jones, Simon and Zdancewic, Steve},
title = {Generative type abstraction and type-level computation},
booktitle = {Proceedings of the 38th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {2011},
month = {January},
abstract = {Modular languages support generative type abstraction, ensuring that an abstract type is distinct from its representation, except inside the implementation where the two are synonymous. We show that this well-established feature is in tension with the non-parametric features of newer type systems, such as indexed type families and GADTs. In this paper we solve the problem by using kinds to distinguish between parametric and non-parametric contexts. The result is directly applicable to Haskell, which is rapidly developing support for type-level computation, but the same issues should arise whenever generativity and non-parametric features are combined.},
publisher = {ACM SIGPLAN},
url = {https://www.microsoft.com/en-us/research/publication/generative-type-abstraction-and-type-level-computation/},
edition = {Proceedings of the 38th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
}
@inproceedings{peytonjones2011a,
author = {Peyton Jones, Simon},
title = {A Monad for Deterministic Parallelism},
booktitle = {Haskell '11: Proceedings of the Fourth ACM SIGPLAN Symposium on Haskell},
year = {2011},
month = {January},
abstract = {We present a new programming model for deterministic parallel computation in a pure functional language. The model is monadic and has explicit granularity, but allows dynamic construction of dataflow networks that are scheduled at runtime, while remaining deterministic and pure. The implementation is based on monadic concurrency, which has until now only been used to simulate concurrency in functional languages, rather than to provide parallelism. We present the API with its semantics, and argue that parallel execution is deterministic. Furthermore, we present a complete work-stealing scheduler implemented as a Haskell library, and we show that it performs at least as well as the existing parallel programming models in Haskell.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/a-monad-for-deterministic-parallelism/},
edition = {Haskell '11: Proceedings of the Fourth ACM SIGPLAN Symposium on Haskell},
}
@inproceedings{bolingbroke2011improving,
author = {Bolingbroke, Max and Peyton Jones, Simon},
title = {Improving supercompilation: tag-bags, rollback, speculation, normalisation, and generalisation},
booktitle = {ICFP},
year = {2011},
month = {January},
abstract = {Supercompilation is a technique due to Turchin Supercompilation is a powerful technique for program optimisation and theorem proving. In this paper we describe and evaluate three improvements to the Cambridge Haskell Supercompiler (CHSC). We reduce supercompiled program size by the use of a weak normaliser and aggressive rollback, and we improve the performance of supercompiled programs by heap speculation and generalisation. Our generalisation method is simpler than those in the literature, and is better at generalising computations involving primitive operations such as those on machine integers. We also provide the first comprehensive account of the tag-bag termination mechanism.},
url = {https://www.microsoft.com/en-us/research/publication/improving-supercompilation-tag-bags-rollback-speculation-normalisation-and-generalisation/},
edition = {ICFP},
}
@inproceedings{peytonjones2011efficient,
author = {Peyton Jones, Simon and Lippmeier, Ben and Keller, Gabriele},
title = {Efficient Parallel Stencil Convolution in Haskell},
booktitle = {Submitted to ICFP 2011},
year = {2011},
month = {January},
abstract = {Stencil convolution is a fundamental building block of many scientific and image processing algorithms. We present a declarative approach to writing such convolutions in Haskell that is both efficient at runtime and implicitly parallel. To achieve this we extend our prior work on the Repa array library with two new features: partitioned and cursored arrays. Combined with careful management of the interaction between GHC and its back-end code generator LLVM, we achieve performance comparable to the standard OpenCV library.},
url = {https://www.microsoft.com/en-us/research/publication/efficient-parallel-stencil-convolution-in-haskell/},
edition = {Submitted to ICFP 2011},
}
@inproceedings{sulzmann2007system,
author = {Sulzmann, Martin and Chakravarty, Manuel and Peyton Jones, Simon and Donnelly, Kevin},
title = {System F with type equality coercions},
booktitle = {ACM SIGPLAN International Workshop on Types in Language Design and Implementation (TLDI'07)},
year = {2007},
month = {January},
abstract = {We introduce a variant of System F that uses a single mechanism to enable the type preserving translation of generalised abstract data types (GADTs), type classes with associated types and functional dependencies, as well as closed type functions. The core idea is to pass around explicit evidence for type equalities, just like System F passes types explicitly. We use this evidence to justify type casts encoding non-syntactic type equalities induced by the mentioned source language features. In particular, we don't need special typing rules for pattern matching on GADTs, we can easily combine GADTs with type classes, and we can relax restrictions on programs involving associated types or functional dependencies.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/system-f-with-type-equality-coercions/},
pages = {53-66},
isbn = {1-59593-393-X},
edition = {ACM SIGPLAN International Workshop on Types in Language Design and Implementation (TLDI'07)},
}
@inproceedings{peytonjones2011multicore,
author = {Peyton Jones, Simon},
title = {Multicore Garbage Collection with Local Heaps},
booktitle = {ISMM '11: Proceedings of the 10th International Symposium on Memory Management},
year = {2011},
month = {June},
abstract = {In a parallel, shared-memory, language with a garbage collected heap, it is desirable for each processor to perform minor garbage collections independently. Although obvious, it is difficult to make this idea pay off in practice, especially in languages where mutation is common. We present several techniques that substantially improve the state of the art. We describe these techniques in the context of a full-scale implementation of Haskell, and demonstrate that our local-heap collector substantially improves scaling, peak performance, and robustness.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/multicore-garbage-collection-with-local-heaps/},
edition = {ISMM '11: Proceedings of the 10th International Symposium on Memory Management},
}
@article{vytiniotis2011outsidein,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Schrijvers, Tom and Sulzmann, Martin},
title = {OutsideIn(X): Modular type inference with local assumptions},
year = {2011},
month = {September},
abstract = {Advanced type system features, such as GADTs, type classes and type families, have proven to be invaluable language extensions for ensuring data invariants and program correctness. Unfortunately, they pose a tough problem for type inference when they are used as local type assumptions. Local type assumptions often result in the lack of principal types and cast the generalisation of local let-bindings prohibitively difficult to implement and specify. User-declared axioms only make this situation worse. In this paper, we explain the problems and-perhaps controversially-argue for abandoning local let-binding generalisation. We give empirical results that local let generalisation is only sporadically used by Haskell programmers. Moving on, we present a novel constraint-based type inference approach for local type assumptions. Our system, called OutsideIn(X), is parameterised over the particular underlying constraint domain X, in the same way as HM(X). This stratification allows us to use a common metatheory and inference algorithm. OutsideIn(X) extends the constraints of X by introducing implication constraints on top. We describe the strategy for solving these implication constraints, which, in turn, relies on a constraint solver for X. We characterise the properties of the constraint solver for X so that the resulting algorithm only accepts programs with principal types, even when the type system specification accepts programs that do not enjoy principal types. Going beyond the general framework, we give a particular constraint solver for X = type classes + GADTs + type families, a non-trivial challenge in its own right. This constraint solver has been implemented and distributed as part of GHC 7.},
publisher = {Cambridge University Press},
url = {https://www.microsoft.com/en-us/research/publication/outsideinx-modular-type-inference-with-local-assumptions/},
pages = {333-412},
journal = {Journal of Functional Programming},
volume = {21},
edition = {Journal of Functional Programming},
}
@inproceedings{epstein2011towards,
author = {Epstein, Jeff and Black, Andrew and Peyton Jones, Simon},
title = {Towards Haskell in the cloud},
booktitle = {Haskell Symposium},
year = {2011},
month = {September},
abstract = {We present Cloud Haskell, a domain-specific language for developing programs for a distributed-memory computing environment. Implemented as a shallow embedding in Haskell, it provides a message-passing communication model, inspired by Erlang, without introducing incompatibility with Haskell's established shared-memory concurrency. A key contribution is a method for serializing function closures for transmission across the network. Cloud Haskell has been implemented; we present example code and some preliminary performance measurements.

 	Jeff Epstein's MPhil thesis 

Errata

Just before 4.1, the code for ping2 should read like this
data Ping2 = Ping2 (SendPort Pong2)   -- Sent by ping-process
                                      -- received by pong-process
data Pong2 = Pong2 (SendPort Ping2)   -- Sent by pong-process
                                      -- received by ping-process

ping2 :: SendPort Pong2 -> ReceivePort Pong2 -> ProcessM ()
ping2 pongout pongin = do [ Pong2 ping_port <- receiveChan pongin
                          ; sendChan ping_port (Ping2 pongout)
                          ; ping2 pongout pongin ]
..similarly pong2…
 },
url = {https://www.microsoft.com/en-us/research/publication/towards-haskell-cloud/},
edition = {Haskell Symposium},
}
@inproceedings{bolingbroke2011termination,
author = {Bolingbroke, Maximilian and Peyton Jones, Simon and Vytiniotis, Dimitrios},
title = {Termination Combinators Forever},
booktitle = {ACM Haskell Symposium, Tokyo},
year = {2011},
month = {September},
abstract = {We describe a library-based approach to constructing termination tests suitable for controlling termination of symbolic methods such as partial evaluation, supercompilation and theorem proving. With our combinators, all termination tests are correct by construction. We show how the library can be designed to embody various optimisations of the termination tests, which the user of the library takes advantage of entirely transparently.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/termination-combinators-forever/},
edition = {ACM Haskell Symposium, Tokyo},
}
@inproceedings{yorgey2012giving,
author = {Yorgey, Brent and Weirich, Stephanie and Cretin, Julien and Peyton Jones, Simon and Vytiniotis, Dimitrios and Magalhaes, Jose Pedro},
title = {Giving Haskell a Promotion},
booktitle = {Proceedings of TLDI'12},
year = {2012},
month = {January},
abstract = {Static type systems strive to be richly expressive while still being simple enough for programmers to use. We describe an experiment that enriches Haskell’s kind system with two features promoted from its type system: data types and polymorphism. The new system has a very good power-to-weight ratio: it offers a signiﬁcant improvement in expressiveness, but, by re-using concepts that programmers are already familiar with, the system is easy to understand and implement.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/giving-haskell-a-promotion/},
edition = {Proceedings of TLDI'12},
}
@inbook{marlow2012the,
author = {Marlow, Simon and Peyton Jones, Simon},
title = {The Glasgow Haskell Compiler},
booktitle = {The Architecture of Open Source Applications, Volume 2},
year = {2012},
month = {January},
abstract = {The Glasgow Haskell Compiler (GHC) started as part of an academic research project funded by the UK government at the beginning of the 1990’s, with several goals in mind:

 	To make freely available a robust and portable compiler for Haskell that generates high performance code;
 	To provide a modular foundation that other researchers can extend and develop;
 	To learn how real programs behave, so that we can design and build better compilers.

GHC is now over 20 years old, and has been under continuous active development since its inception. Today, GHC releases are downloaded by hundreds of thousands of people, the online repository of Haskell libraries has over 3,000 packages, GHC is used to teach Haskell in many undergraduate courses, and there are a growing number of instances of Haskell being depended upon commercially.},
publisher = {Lulu},
url = {https://www.microsoft.com/en-us/research/publication/the-glasgow-haskell-compiler/},
edition = {The Architecture of Open Source Applications, Volume 2},
}
@inproceedings{lippmeier2012work,
author = {Lippmeier, Ben and Chakravarty, Manuel and Keller, Gabriele and Leshchinskiy, Roman and Peyton Jones, Simon},
title = {Work Efficient Higher-Order Vectorisation},
booktitle = {ICFP'12},
year = {2012},
month = {September},
abstract = {Existing approaches to higher-order vectorisation, also known as flattening nested data parallelism, do not preserve the asymptotic work complexity of the source program. Straightforward examples, such as sparse matrix-vector multiplication, can suffer a severe blow-up in both time and space, which limits the practicality of this method. We discuss why this problem arises, identify the mis-handling of index space transforms as the root cause, and present a solution using a refined representation of nested arrays. We have implemented this solution in Data Parallel Haskell (DPH) and present benchmarks showing that realistic programs, which used to suffer the blow-up, now have the correct asymptotic work complexity. In some cases, the asymptotic complexity of the vectorised program is even better than the original.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/work-efficient-higher-order-vectorisation/},
edition = {ICFP’12},
}
@inproceedings{peytonjones2012safe,
author = {Peyton Jones, Simon},
title = {Safe Haskell},
booktitle = {Haskell '12: Proceedings of the Fifth ACM SIGPLAN Symposium on Haskell},
year = {2012},
month = {September},
abstract = {Though Haskell is predominantly type-safe, implementations contain a few loopholes through which code can bypass typing and module encapsulation. This paper presents Safe Haskell, a language extension that closes these loopholes. Safe Haskell makes it possible to confine and safely execute untrusted, possibly malicious code. By strictly enforcing types, Safe Haskell allows a variety of different policies from API sandboxing to information-flow control to be implemented easily as monads. Safe Haskell is aimed to be as unobtrusive as possible. It enforces properties that programmers tend to meet already by convention. We describe the design of Safe Haskell and an implementation (currently shipping with GHC) that infers safety for code that lies in a safe subset of the language. We use Safe Haskell to implement an online Haskell interpreter that can securely execute arbitrary untrusted code with no overhead. The use of Safe Haskell greatly simplifies this task and allows the use of a large body of existing code and tools.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/safe-haskell/},
edition = {Haskell '12: Proceedings of the Fifth ACM SIGPLAN Symposium on Haskell},
}
@inproceedings{keller2012vectorisation,
author = {Keller, Gabriele and Chakravarty, Manuel and Leshchinskiy, Roman and Lippmeier, Ben and Peyton Jones, Simon},
title = {Vectorisation avoidance},
booktitle = {Haskell Symposium},
year = {2012},
month = {September},
abstract = {Flattening nested parallelism is a vectorising code transform that converts irregular nested parallelism into flat data parallelism. Although the result has good asymptotic performance, flattening thoroughly restructures the code. Many intermediate data structures and traversals are introduced, which may or may not be eliminated by subsequent optimisation. We present a novel program analysis to identify parts of the program where flattening would only introduce overhead, without appropriate gain. We present empirical evidence that avoiding vectorisation in these cases leads to more efficient programs than if we had applied vectorisation and then relied on array fusion to eliminate intermediates from the resulting code},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/vectorisation-avoidance/},
edition = {Haskell Symposium},
}
@inproceedings{lippmeier2012guiding,
author = {Lippmeier, Ben and Chakravarty, Manuel and Keller, Gabriele and Peyton Jones, Simon},
title = {Guiding parallel array fusion with index types},
booktitle = {Haskell Symposium, Copenhagen},
year = {2012},
month = {September},
abstract = {We present a refined approach to parallel array fusion that uses indexed types to specify the internal representation of each array. Our approach aids the client programmer in reasoning about the performance of their program in terms of the source code. It also makes the intermediate code easier to transform at compile-time, resulting in faster compilation and more reliable runtimes. We demonstrate how our new approach improves both the clarity and performance of several end-user written programs, including a fluid flow solver and an interpolator for volumetric data.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/guiding-parallel-array-fusion-with-index-types/},
edition = {Haskell Symposium, Copenhagen},
}
@inproceedings{vytiniotis2013halo,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Claessen, Koen and Rosén, Dan},
title = {HALO: Haskell to Logic Through Denotational Semantics},
series = {POPL '13},
booktitle = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
year = {2013},
month = {January},
abstract = {Even well-typed programs can go wrong in modern functional languages, by encountering a pattern-match failure, or simply returning the wrong answer. An increasingly-popular response is to allow programmers to write contracts that express semantic properties, such as crash-freedom or some useful post-condition. We study the static verification of such contracts. Our main contribution is a novel translation to first-order logic of both Haskell programs, and contracts written in Haskell, all justified by denotational semantics. This translation enables us to prove that functions satisfy their contracts using an off-the-shelf first-order logic theorem prover.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/halo-haskell-to-logic-through-denotational-semantics/},
pages = {431-442},
isbn = {978-1-4503-1832-7},
edition = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
}
@inproceedings{kolling2013bringing,
author = {Kolling, Michael and Crick, Tom and Peyton Jones, Simon and Humphreys, Simon and Sentance, Sue},
title = {Bringing Computer Science Back Into Schools: Lessons from the UK},
booktitle = {SIGCSE'13},
year = {2013},
month = {March},
abstract = {Computer science in UK schools is a subject in decline: the ratio of Computing to Maths A-Level students (i.e. ages 16-18) has fallen from 1:2 in 2003 to 1:20 in 2011 and in 2012. In 2011 and again in 2012, the ratio for female students was 1:100, with less than 300 female students taking Computing A-Level in the whole of the UK each year. Similar problems have been observed in the USA and other countries, despite the increased need for computer science skills caused by IT growth in industry and society.

In the UK, the Computing At School (CAS) working group was formed to try to improve the state of computer science in schools. Using a combination of grassroots teacher activities and policy lobbying at a national level, CAS has been able to rapidly gain traction in the fight for computer science in schools. We examine the reasons for this success, the challenges and dangers that lie ahead, and suggest how the experience of CAS in the UK can benefi other similar organisations, such as the CSTA in the USA.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/bringing-computer-science-back-into-schools/},
edition = {SIGCSE’13},
}
@unpublished{peytonjones2013computing,
author = {Peyton Jones, Simon and Humphreys, Simon and Mitchell, Bill},
title = {Computing at school in the UK: from guerrilla to gorilla},
year = {2013},
month = {May},
abstract = {This paper summarises the rapid and radical developments during 2012-2013 in the K-12 school computing curriculum in UK. We draw out lessons from our experience that may be useful to others.},
url = {https://www.microsoft.com/en-us/research/publication/computing-at-school-in-the-uk-from-guerrilla-to-gorilla/},
edition = {Submitted to CACM},
note = {Submitted to CACM},
}
@inproceedings{peytonjones2013exploiting,
author = {Peyton Jones, Simon and Mainland, Geoff and Marlow, Simon and Leshchinskiy, Roman},
title = {Exploiting vector instructions with generalized stream fusion},
booktitle = {ACM SIGPLAN International Conference on Functional Programming (ICFP '13)},
year = {2013},
month = {September},
abstract = {Stream fusion is a powerful technique for automatically transforming high-level sequence-processing functions into efficient implementations. It has been used to great effect in Haskell libraries for manipulating byte arrays, Unicode text, and unboxed vectors. However, some operations, like vector append, still do not perform well within the standard stream fusion framework. Others, like SIMD computation using the SSE and AVX instructions available on modern x86 chips, do not seem to fit in the framework at all.

In this paper we introduce generalized stream fusion, which solves these issues. The key insight is to bundle together multiple stream representations, each tuned for a particular class of stream consumer. We also describe a stream representation suited for efficient computation with SSE instructions. Our ideas are implemented in modified versions of the GHC compiler and vector library. Benchmarks show that high-level Haskell code written using our compiler and libraries can produce code that is competitive with hand-tuned assembly.},
url = {https://www.microsoft.com/en-us/research/publication/exploiting-vector-instructions-with-generalized-stream-fusion/},
edition = {ACM SIGPLAN International Conference on Functional Programming (ICFP ’13)},
}
@inproceedings{sergey2014modular,
author = {Sergey, Ilya and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Modular, Higher-order Cardinality Analysis in Theory and Practice},
series = {POPL '14},
booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
year = {2014},
month = {January},
abstract = {Since the mid '80s, compiler writers for functional languages (especially lazy ones) have been writing papers about identifying and exploiting thunks and lambdas that are used only once. However it has proved difficult to achieve both power and simplicity in practice. We describe a new, modular analysis for a higher-order language, which is both simple and effective, and present measurements of its use in a full-scale, state of the art optimising compiler. The analysis finds many single-entry thunks and one-shot lambdas and enables a number of program optimisations.

The extended version has a technical appendix.

(This paper represents a completely new, and much simpler, attack on the problem, compared to our earlier work on usage polymorphism.)},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/modular-higher-order-cardinality-analysis-in-theory-and-practice-2/},
pages = {335-347},
isbn = {978-1-4503-2544-8},
edition = {POPL 2014},
}
@inproceedings{eisenberg2014closed,
author = {Eisenberg, Richard A. and Vytiniotis, Dimitrios and Peyton Jones, Simon and Weirich, Stephanie},
title = {Closed Type Families with Overlapping Equations},
series = {POPL '14},
booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
year = {2014},
month = {January},
abstract = {Open, type-level functions are a recent innovation in Haskell that move Haskell towards the expressiveness of dependent types, while retaining the look and feel of a practical programming language. This paper shows how to increase expressiveness still further, by adding closed type functions whose equations may overlap, and may have non-linear patterns over an open type universe. Although practically useful and simple to implement, these features go beyond conventional dependent type theory in some respects, and have a subtle metatheory.

Here is an extended version with proofs.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/closed-type-families-with-overlapping-equations/},
pages = {671-683},
isbn = {978-1-4503-2544-8},
edition = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
}
@inproceedings{kilpatrick2014backpack,
author = {Kilpatrick, Scott and Dreyer, Derek and Peyton Jones, Simon and Marlow, Simon},
title = {Backpack: retrofitting Haskell with interfaces},
booktitle = {POPL '14},
year = {2014},
month = {January},
abstract = {Module systems like that of Haskell permit only a weak form of modularity in which module implementations directly depend on other implementations and must be processed in dependency order. Module systems like that of ML, on the other hand, permit a stronger form of modularity in which explicit interfaces express assumptions about dependencies, and each module can be typechecked and reasoned about independently.

In this paper, we present Backpack, a new language for building separately-typecheckable packages on top of a weak module system like Haskell's. The design of Backpack is inspired by the MixML module calculus of Rossberg and Dreyer, but differs significantly in detail. Like MixML, Backpack supports explicit interfaces and recursive linking. Unlike MixML, Backpack supports a more flexible applicative semantics of instantiation. Moreover, its design is motivated less by foundational concerns and more by the practical concern of integration into Haskell, which has led us to advocate simplicity --- in both the syntax and semantics of Backpack --- over raw expressive power. The semantics of Backpack packages is defined by elaboration to sets of Haskell modules and binary interface files, thus showing how Backpack maintains interoperability with Haskell while extending it with separate typechecking. Lastly, although Backpack is geared toward integration into Haskell, its design and semantics are largely agnostic with respect to the details of the underlying core language.

 	Appendix},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/backpack-retrofitting-haskell-with-interfaces/},
edition = {POPL ’14},
}
@inproceedings{breitner2014safe,
author = {Breitner, Joachin and Eisenberg, Richard and Peyton Jones, Simon and Weirich, Stephanie},
title = {Safe, zero-cost coercions for Haskell},
booktitle = {ICFP 2014},
year = {2014},
month = {June},
abstract = {Generative type abstractions -- present in Haskell, OCaml, and other languages -- are useful concepts to help prevent programmer errors. They serve to create new types that are distinct at compile time but share a run-time representation with some base type. We present a new mechanism that allows for zero-cost conversions between generative type abstractions and their representations, even when such types are deeply nested. We prove type safety in the presence of these conversions and have implemented our work into GHC.

 	Extended version with proofs},
url = {https://www.microsoft.com/en-us/research/publication/safe-coercions/},
edition = {ICFP 2014},
}
@inproceedings{vazou2014refinement,
author = {Vazou, Niki and Seidel, Eric L. and Jhala, Ranjit and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Refinement Types for Haskell},
series = {ICFP '14},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
year = {2014},
month = {September},
abstract = {SMT-based checking of refinement types for call-by-value languages is a well-studied subject. Unfortunately, the classical translation of refinement types to verification conditions is unsound under lazy evaluation. When checking an expression, such systems implicitly assume that all the free variables in the expression are bound to values. This property is trivially guaranteed by eager, but does not hold under lazy, evaluation. Thus, to be sound and precise, a refinement type system for Haskell and the corresponding verification conditions must take into account which subset of binders actually reduces to values. We present a stratified type system that labels binders as potentially diverging or not, and that (circularly) uses refinement types to verify the labeling. We have implemented our system in LIQUIDHASKELL and present an experimental evaluation of our approach on more than 10,000 lines of widely used Haskell libraries. We show that LIQUIDHASKELL is able to prove 96% of all recursive functions terminating, while requiring a modest 1.7 lines of termination-annotations per 100 lines of code},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/refinement-types-for-haskell/},
pages = {269-282},
isbn = {978-1-4503-2873-9},
edition = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
}
@inproceedings{stolarek2015injective,
author = {Stolarek, Jan and Eisenberg, Richard and Peyton Jones, Simon},
title = {Injective type families for Haskell},
booktitle = {ACM Haskell Symposium 2015},
year = {2015},
month = {August},
abstract = {Haskell, as implemented by the Glasgow Haskell Compiler (GHC), allows expressive type-level programming. The most popular type-level programming extension is TypeFamilies, which allows users to write functions on types. Yet, using type functions can cripple type inference in certain situations. In particular, lack of injectivity in type functions means that GHC can never infer an instantiation of a type variable appearing only under type functions. In this paper, we describe a small modification to GHC that allows type functions to be annotated as injective. GHC naturally must check validity of the injectivity annotations. The algorithm to do so is surprisingly subtle. We prove soundness for a simplification of our algorithm, and state and prove a completeness property, though the algorithm is not fully complete. As much of our reasoning surrounds functions defined by a simple pattern-matching structure, we believe our results extend beyond just Haskell. We have implemented our solution on a branch of GHC and plan to make it available to regular users with the next stable release of the compiler.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/injective-type-families-haskell/},
pages = {118-128},
edition = {ACM Haskell Symposium 2015},
}
@inproceedings{karachalias2015gadts,
author = {Karachalias, Georgios and Schrijvers, Tom and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {GADTs meet their match: pattern-matching warnings that account for GADTs, guards, and laziness},
booktitle = {ACM International Conference on Functional Programming 2015 (ICFP'15)},
year = {2015},
month = {August},
abstract = {For ML and Haskell, accurate warnings when a function definition has redundant or missing patterns are mission critical. But today's compilers generate bogus warnings when the programmer uses guards (even simple ones), GADTs, pattern guards, or view patterns. We give the first algorithm that handles all these cases in a single, uniform framework, together with an implementation in GHC, and evidence of its utility in practice.},
url = {https://www.microsoft.com/en-us/research/publication/gadts-meet-their-match-pattern-matching-warnings-that-account-for-gadts-guards-and-laziness/},
}
@inproceedings{mokhov2016non-recursive,
author = {Mokhov, Andrey and Mitchell, Neil and Peyton Jones, Simon and Marlow, Simon},
title = {Non-recursive Make Considered Harmful},
booktitle = {Proceedings of the 9th International Symposium on Haskell},
year = {2016},
month = {September},
abstract = {Most build systems start small and simple, but over time grow into hairy monsters that few dare to touch. As we demonstrate in this paper, there are a few issues that cause build systems major scalability challenges, and many pervasively used build systems (e.g. Make) do not scale well.

This paper presents a solution to the challenges we identify. We use functional programming to design abstractions for build systems, and implement them on top of the Shake library, which allows us to describe build rules and dependencies. To substantiate our claims, we engineer a new build system for the Glasgow Haskell Compiler. The result is more scalable, faster, and spectacularly more maintainable than its Make-based predecessor.},
url = {https://www.microsoft.com/en-us/research/publication/non-recursive-make-considered-harmful/},
pages = {170-181},
edition = {Haskell Symposium 2016},
}
@unpublished{peytonjones2016backpack,
author = {Peyton Jones, Simon and Yang, Edward and Kilpatrick, Scott and Dreyer, Derek},
title = {Backpack to work: towards practical mixin linking for Haskell},
year = {2016},
month = {March},
abstract = {In this paper, we describe an evolution of the Backpack mixin package system which respects the division between package manager and compiler in the Haskell ecosystem: Backpack. Programs written in Backpack are processed in two phases: first, a mixin linking phase which computes a "wiring diagram" of components indifferent to the actual Haskell source code, and then a typechecking phase on the output of mixin linking which processes Haskell source. This is not merely a paper design: our architecture was principally motivated by our experiences implementing Backpack in the GHC compiler and the Cabal package system.},
url = {https://www.microsoft.com/en-us/research/publication/backpack-to-work-towards-practical-mixin-linking-for-haskell/},
edition = {In submission},
note = {In submission},
}
@inproceedings{downen2016sequent,
author = {Downen, Paul and Maurer, Luke and Ariola, Zena and Peyton Jones, Simon},
title = {Sequent calculus as a compiler intermediate language},
booktitle = {International Conference on Functional Programming (ICFP'16)},
year = {2016},
month = {September},
abstract = {The lambda-calculus is popular as an intermediate language for practical compilers. But in the world of logic it has a lesser-known twin, born at the same time, called the sequent calculus. Perhaps that would be a good intermediate language, too? To explore this question we designed Sequent Core, a practically-oriented variant of sequent calculus, and used it to re-implement a substantial chunk of the Glasgow Haskell Compiler.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/sequent-calculus-as-a-compiler-intermediate-language/},
pages = {74-88},
edition = {International Conference on Functional Programming (ICFP'16)},
}
@article{sivaramakrishnan2016composable,
author = {Sivaramakrishnan, KC and Harris, Tim and Marlow, Simon and Peyton Jones, Simon},
title = {Composable Scheduler Activations for Haskell},
year = {2016},
month = {June},
abstract = {The runtime for a modern, concurrent, garbage collected language like Haskell is like an operating system: sophisticated, complex, performant, but alas very hard to change. If more of the runtime system were in Haskell it would become far more modular and malleable. In this paper we describe a new concurrency design that allows the scheduler for concurrent and parallel programs to be written in Haskell. In particular, this substrate allows new primitives to be constructed modularly, obviating the need to re-engineer or reason about the interactions with GHC's existing concurrency support.

 	Earlier conference version, rejected by the 2013 Haskell Symposium.
 	Code on GitHub

 },
url = {https://www.microsoft.com/en-us/research/publication/composable-scheduler-activations-haskell/},
journal = {Journal of Functional Programming},
edition = {Journal of Functional Programming},
}
@inproceedings{zhang2015diagnosing,
author = {Zhang, Danfeng and Myers, Andrew C and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Diagnosing type errors with class},
booktitle = {Programming Languages Design and Implementation (PLDI'15)},
year = {2015},
month = {June},
abstract = {Type inference engines often give terrible error messages, and the more sophisticated the type system the worse the problem. We show that even with the highly expressive type system implemented by the Glasgow Haskell Compiler (GHC)—including type classes, GADTs, and type families—it is possible to identify the most likely source of the type error, rather than the first source that the inference engine trips over. To determine which are the likely error sources, we apply a simple Bayesian model to a graph representation of the typing constraints; the satisfiability or unsatisfiability of paths within the graph provides evidence for or against possible explanations. While we build on prior work on error diagnosis for simpler type systems, inference in the richer type system of Haskell requires extending the graph with new nodes. The augmentation of the graph creates challenges both for Bayesian reasoning and for ensuring termination. Using a large corpus of Haskell programs, we show that this error localization technique is practical and significantly improves accuracy over the state of the art.

ShErrLoc web site},
publisher = {ACN},
url = {https://www.microsoft.com/en-us/research/publication/diagnosing-type-errors-class/},
pages = {12-21},
volume = {50},
chapter = {6},
note = {PLDI Distinguished Paper Award},
}
@inproceedings{pickering2016pattern,
author = {Pickering, Matthew and Érdi, Gerg˝o and Peyton Jones, Simon and Eisenberg, Richard A.},
title = {Pattern Synonyms},
booktitle = {Haskell'16},
year = {2016},
month = {September},
abstract = {Pattern matching has proven to be a convenient, expressive way of inspecting data. Yet this language feature, in its traditional form, is limited: patterns must be data constructors of concrete data types.
No computation or abstraction is allowed. The data type in question must be concrete, with no ability to enforce any invariants. Any change in this data type requires all clients to update their code. This paper introduces pattern synonyms, which allow programmers to abstract over patterns, painting over all the shortcomings listed above. Pattern synonyms are assigned types, enabling a compiler to check the validity of a synonym independent of its definition. These types are intricate; detailing how to assign a type to a pattern synonym is a key contribution of this work. We have implemented pattern synonyms in the Glasgow Haskell Compiler, where they have enjoyed immediate popularity, but we believe this feature could easily be exported to other languages that support pattern matching.},
url = {https://www.microsoft.com/en-us/research/publication/pattern-synonyms/},
edition = {Haskell’16, September 22-23, 2016},
}
@inproceedings{marlow2016desugaring,
author = {Marlow, Simon and Peyton Jones, Simon and Kmett, Edward and Mokhov, Andrey},
title = {Desugaring Haskell's do-notation Into Applicative Operations},
booktitle = {Haskell Symposium},
year = {2016},
month = {September},
abstract = {Monads have taken the world by storm, and are supported by do-notation (at least in Haskell). Programmers are increasingly waking up to the usefulness and ubiquity of Applicatives, but they have so far been hampered by the absence of supporting notation. In this paper we show how to re-use the very same do-notation to work for Applicatives as well, providing efficiency benefits for some types that are both Monad and Applicative, and syntactic convenience for those that are merely Applicative. The result is fully implemented in GHC, and is in use at Facebook to make it easy to write highly-parallel queries in a distributed system.},
url = {https://www.microsoft.com/en-us/research/publication/desugaring-haskells-do-notation-into-applicative-operations/},
}
@unpublished{nemeth1998a,
author = {Nemeth, Laszlo and Peyton Jones, Simon},
title = {A design for warm fusion},
year = {1998},
month = {September},
abstract = {This is a rather old paper, and I don't have the Latex source. However I've scanned it, and here's the result.  The paper is not in the post-published Springer-Verlag proceedings of IFL 1998, so I think we probably didn't do the work to turn the draft into properly publishable paper.

Here, too, is Laszlo's thesis "Catamorphism-based program transformations for non-strict functional languages", which gives a much more detailed exposition of warm fusion.

 

 },
url = {https://www.microsoft.com/en-us/research/publication/a-design-for-warm-fusion/},
edition = {10th International Worskhop on the Implementation of Functional Languages (IFL'98),},
note = {10th International Worskhop on the Implementation of Functional Languages (IFL'98),},
}
@misc{peytonjones2016typed,
author = {Peyton Jones, Simon and Weirich, Stephanie and Eisenberg, Richard A. and Vytiniotis, Dimitrios},
title = {Typed reflection in Haskell},
year = {2016},
month = {April},
abstract = {The ability to perform type tests at runtime blurs the line between statically-typed and dynamically-checked languages. Recent developments in Haskell's type system allow even programs that use reflection to themselves be statically typed, using a type-indexed runtime representation of types called TypeRep. As a result we can build dynamic types as an ordinary, statically-typed library, on top of TypeRep in an open-world context.},
url = {https://www.microsoft.com/en-us/research/publication/typed-reflection-in-haskell/},
edition = {Proc Philip Wadler's 60th birthday Festschrift, Edinburgh, April 2016},
note = {Proc Philip Wadler's 60th birthday Festschrift, Edinburgh, April 2016},
}
@misc{peytonjones2011haskell,
author = {Peyton Jones, Simon},
title = {Haskell and transactional memory},
year = {2011},
month = {March},
abstract = {Slides in Japanese

O'Reilly wrote up the meeting. Here's the translation into English:

150 Haskeller were excited! "Haskellers Meeting 2010 Spring" was held in IIJ conference room, Kanda, Tokyo on April 16th. Simon Peyton Jones who is admired by Haskellers and also one of the authors of "Beautiful Code" gave a talk on "Haskell and Software Transaction Memory". This is a same topic described in chapter 24 of "Beautiful code" and chapter 28 of "Real World Haskell". The presentation of Simon-san was so attractive and wonderful just like he'd made legendary speech "How to give a good research talk". All we could sense his love for Haskell through his talk. Subsequently, Kazu Yamamoto who is the translation supervisor of our book "PGP" (unfortunately it is out of print) talked about "Experience on implementing a Web server in Haskell", and Nobuo Yamashita, who is one of the translators of "Real World Haskell" gave a speech of "Yet Another Purely Functional Expression for Interaction". The room was filled excitement because of Haskeller's terrible heat though the outside was so chilly that it snowed first time in 41 years for middle April.At the same time, Simon-san is also an interviewee of "Masterminds of Programming" which is our new book. This is an interview collection of creators of influential programming languages. Simon-san appears in chapter 8 HASKELL with Paul Hudak and Philip Wadler. The Japanese version will be published this fall if everything goes well. Don't miss it!},
url = {https://www.microsoft.com/en-us/research/publication/haskell-transactional-memory/},
}
@inproceedings{wansbrough2000simple,
author = {Wansbrough, Keith and Peyton Jones, Simon},
title = {Simple Usage Polymorphism},
booktitle = {3rd ACM SIGPLAN Workshop on Types in Compilation},
year = {2000},
month = {September},
abstract = {We present a novel inference algorithm for a type system featuring subtyping and usage (annotation) polymorphism. This algorithm infers simply-polymorphic types rather than the constrained-polymorphic types usual in such a setting; it achieves this by means of constraint approximation. The algorithm is motivated by practical considerations and experience of a previous system, and has been implemented in a production compiler with positive results. We believe the algorithm may well have applications in settings other than usage-type inference.

 },
url = {https://www.microsoft.com/en-us/research/publication/simple-usage-polymorphism/},
edition = {3rd ACM SIGPLAN Workshop on Types in Compilation},
}
@inproceedings{peytonjones2005scrap,
author = {Peyton Jones, Simon},
title = {Scrap your boilerplate with class: extensible generic functions},
booktitle = {ACM SIGPLAN International Conference on Functional Programming (ICFP'05)},
year = {2005},
month = {September},
abstract = {The "scrap your boilerplate" approach to generic programming allows the programmer to generic functions that can traverse arbitrary data structures, and yet have type-specific cases. However, the approach requires all the type-specific cases to be supplied at once, when the function is defined: the function is closed. In contrast, Haskell's type classes support open, or extensible functions, that can be extended with new type-specific cases as new data types are defined. In this paper we show how to extend the scrap-your-boilerplate approach to support this open style. On the way we demonstrate the desirablility of abstraction over type classes, and the usefulness of recursive dictionaries.

 	powerpoint slides 

 

 

 

 },
url = {https://www.microsoft.com/en-us/research/publication/scrap-your-boilerplate-with-class/},
edition = {ACM SIGPLAN International Conference on Functional Programming (ICFP'05)},
}
@unpublished{vytiniotis2011practical,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Practical aspects of evidence-based compilation in System FC},
year = {2011},
month = {March},
abstract = {System FC is an explicitly typed language that serves as the target language for Haskell source programs. System FC is based on System F with the addition of erasable but explicit type equality proof witnesses. This paper improves FC in two directions: The first contribution is extending term-level functions with the ability to return equality proof witnesses, which allows the smooth integration of equality superclasses and indexed constraint synonyms, features currently absent from Haskell. We show how to ensure soundness and satisfy the zero-cost requirement for equality witnesses using a familiar mechanism, already present in GHC: that of unlifted types. Our second contribution is an equality proof simplification algorithm, which greatly reduces the size of the target System FC terms.

 

This paper was completely rewritten and reborn as two separate papers "Equality proofs and deferred type errors" and "Evidence normalization in System FC".},
url = {https://www.microsoft.com/en-us/research/publication/practical-aspects-evidence-based-compilation-system-fc/},
}
@inproceedings{vytiniotis2013evidence,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Evidence normalization in System FC},
booktitle = {24th International Conference on Rewriting Techniques and Applications (RTA'13)},
year = {2013},
month = {June},
abstract = {System FC is an explicitly typed language that serves as the target language for Haskell source programs. System FC is based on System F with the addition of erasable but explicit type equality proof witnesses. Equality proof witnesses are generated from type inference performed on source Haskell programs. Such witnesses may be very large objects, which causes performance degradation in later stages of compilation, and makes it hard to debug the results of type inference and subsequent program transformations. In this paper we present an equality proof simplification algorithm, implemented in GHC, which greatly reduces the size of the target System FC programs.},
publisher = {LIPICS, Schloss Dagstuhl},
url = {https://www.microsoft.com/en-us/research/publication/evidence-normalization-system-fc-2/},
pages = {20-38},
edition = {24th International Conference on Rewriting Techniques and Applications (RTA'13)},
}
@inproceedings{erwig2000pattern,
author = {Erwig, Martin and Peyton Jones, Simon},
title = {Pattern Guards and Transformational Patterns},
booktitle = {Haskell Workshop 2000},
year = {2000},
month = {September},
abstract = {We propose three extensions to patterns and pattern matching in Haskell. The first, pattern guards, allows the guards of a guarded equation to match patterns and bind variables, as well as to test boolean condition. For this we introduce a natural generalization of guard expressions to guard qualifiers.

A frequently-occurring special case is that a function should be applied to a matched value, and the result of this is to be matched against another pattern. For this we introduce a syntactic abbreviation, transformational patterns, that is particularly useful when dealing with views. These proposals can be implemented with very modest syntactic and implementation cost. They are upward compatible with Haskell; all existing programs will continue to work.

We also offer a third, much more speculative proposal, which provides the transformational-pattern construct with additional power to explicitly catch pattern match failure.

We demonstrate the usefulness of the proposed extension by several examples, in particular, we compare our proposal with views, and we also discuss the use of the new patterns in combination with equational reasoning.

 },
url = {https://www.microsoft.com/en-us/research/publication/pattern-guards-and-transformational-patterns/},
edition = {Haskell Workshop 2000},
}
@techreport{peytonjones1984arbitrary,
author = {Peyton Jones, Simon},
title = {Arbitrary precision arithmetic using continued fractions},
booktitle = {INDRA Note 1530, University College London},
year = {1984},
month = {January},
abstract = {Functional languages supporting lazy evaluation invite novel applications, where conventional languages do not provide appropriate support for the problem.  In this paper we present an application of functional languages to arbitrary precision real arithmetic, using an unusual technique based on continued fractions, and depending crucially on lazy evaluation.

The precision of computer arithmetic calculations is normally decided by the programmer in advance, and is often hard to alter subsequently. Furthermore, without a formal analysis of the calculation, answers may be produced to spurious accuracy, and the computer gives no help in establishing error bounds for the result..  The technique presented here performs real arithmetic with guaranteed error bounds, in which the precision of the result can be arbitrarily increased without recommencing the calculation.

Here are two hard-to-find supporting publications

 	Gosper's Hackmem note on continued fractions
 	Continued fractions without tears (Richards, 1981)},
url = {https://www.microsoft.com/en-us/research/publication/arbitrary-precision-arithmetic-using-continued-fractions/},
number = {MSR-TR-2016-70},
}
@inbook{peytonjones1996on,
author = {Peyton Jones, Simon},
title = {On the importance of being the right size: the challenge of conducting realistic experiments},
booktitle = {Computing tomorrow: future research directions in computer science, ed Wand & Milner},
year = {1996},
month = {June},
abstract = {The process of building systems plays a critical, and under-valued, role in computing in general, and in Computer Science research in particular. In this paper I argue the case for valuing system-building more highly than the UK academic research community generally does.},
publisher = {Cambridge University Press},
url = {https://www.microsoft.com/en-us/research/publication/challenge-right-size/},
pages = {321-335},
}
@inproceedings{shaikhha2017using,
author = {Shaikhha, Amir and Fitzgibbon, Andrew and Peyton Jones, Simon and Vytiniotis, Dimitrios},
title = {Using Destination-Passing Style to Compile a Functional Language into Efficient Low-Level Code},
booktitle = {Workshop on Functional High-Performance Computing},
year = {2017},
month = {September},
abstract = {We show how to compile high-level functional array-processing programs, drawn from image processing and machine learning, into C code that runs as fast as hand-written C.  The key idea is to transform the program to destination passing style, which in turn enables a highly-efficient stack-like memory allocation discipline.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/using-destination-passing-style-compile-functional-language-efficient-low-level-code/},
}
@inproceedings{eisenberg2017levity,
author = {Eisenberg, Richard and Peyton Jones, Simon},
title = {Levity polymorphism},
booktitle = {ACM Conference on Programming Language Design and Implementation (PLDI'17)},
year = {2017},
month = {June},
abstract = {Parametric polymorphism is one of the lynchpins of modern typed programming. A function that can work seamlessly over a variety of types simplifies code, helps to avoid errors introduced through duplication, and is easy to  maintain. However, polymorphism comes at a very real cost, one that each language with support for polymorphism has paid in different ways. This paper describes this cost, proposes a theoretically simple way to reason about the  cost---that kinds, not types, are calling conventions---and details one approach to dealing with polymorphism that works in the context of a language, Haskell, that prizes both efficiency and a principled type system.

This approach, levity polymorphism, allows the user to abstract over calling conventions; we detail and verify restrictions that are necessary in order to compile levity-polymorphic functions. Levity polymorphism has opened up surprising new opportunities for library design in Haskell.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/levity-polymorphism/},
pages = {525-539},
}
@inproceedings{maurer2017compiling,
author = {Maurer, Luke and Ariola, Zena and Downen, Paul and Peyton Jones, Simon},
title = {Compiling without continuations},
booktitle = {ACM Conference on Programming Languages Design and Implementation (PLDI'17)},
year = {2017},
month = {June},
abstract = {Many fields of study in compilers give rise to the concept of  a join point --- a place where different execution paths come together.   While they have often been treated by representing them as functions or  continuations, we believe it is time to study them in their own right. We show  that adding them to a direct-style functional intermediate language allows new optimizations to be performed, including a functional version of  loop-invariant code motion. Finally, we report on recent work on the Glasgow  Haskell Compiler which added join points to the Core language.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/compiling-without-continuations/},
pages = {482-494},
}
@article{najd2017trees,
author = {Najd, Shayan and Peyton Jones, Simon},
title = {Trees that grow},
year = {2017},
month = {January},
abstract = {We study the notion of extensibility in functional data types, as a new approach to the problem of decorating abstract syntax trees with additional information. We observed the need for such extensibility while redesigning the data types representing Haskell abstract syntax inside Glasgow Haskell Compiler (GHC).

Specifically, we describe a programming idiom that exploits type-level functions to allow a particular form of extensibility.  The approach scales to support existentials and generalised algebraic data types, and we can use pattern synonyms to make it quite convenient in practice.},
url = {https://www.microsoft.com/en-us/research/publication/trees-that-grow/},
pages = {47-62},
journal = {Journal of Universal Computer Science (JUCS)},
volume = {23},
chapter = {1},
}
@article{sergey2016modular,
author = {Sergey, Ilya and Vytiniotis, Dimitrios and Breitner, Joachim and Peyton Jones, Simon},
title = {Modular, higher-order cardinality analysis in theory and practice},
year = {2016},
month = {December},
abstract = {Since the mid '80s, compiler writers for functional languages (especially lazy ones) have been writing papers about identifying and exploiting thunks and lambdas that are used only once.  However, it has proved difficult to achieve both power and simplicity in practice.  In this paper we describe a new, modular analysis for a higher-order language, which is both simple and effective. We prove the analysis sound with respect to a standard call-by-need semantics, and present measurements of its use in a full-scale, state-of-the-art optimising compiler. The analysis finds many single-entry thunks and one-shot lambdas and enables a number of
program optimisations.

This paper extends our earlier conference publication (POPL'14) with proofs, expanded report on evaluation and a detailed examination of the factors causing the loss of precision in the analysis.

To appear in the Journal of Functional Programming},
url = {https://www.microsoft.com/en-us/research/publication/modular-higher-order-cardinality-analysis-theory-practice/},
journal = {Journal of Functional Programming},
}
@techreport{peytonjones1991a,
author = {Peyton Jones, Simon},
title = {A practical technique for designing asynchronous finite-state machines},
year = {1991},
month = {April},
abstract = {The literature asynchronous logic design is mostly of a fairly theoretical nature.  We present here a practical technique for generating asynchronous finite-state machines from a description of their states and transitions. The technique has been used successfully to design a number of state machines in the GRIP multiprocessor.},
publisher = {Dept of Computing Science, University of Glasgow},
url = {https://www.microsoft.com/en-us/research/publication/practical-technique-designing-asynchronous-finite-state-machines/},
}
@unpublished{sergey2014theory,
author = {Sergey, Ilya and Peyton Jones, Simon and Vytiniotis, Dimitrios},
title = {Theory and practice of demand analysis in Haskell},
year = {2014},
month = {June},
abstract = {Any decent optimising compiler for a lazy language like Haskell must include a strictness analyser. The results of this analysis allow the compiler to use call-by-value instead of call-by-need, and that leads to big performance improvements. It turns out that strictness analysis is an interesting problem from a theoretical point of view, and the 1980’s saw a huge rash of papers on the subject. There were fewer, many, many fewer, papers that described real implementations.

This paper presents the fruits of a decade-long experience with strictness analysis, in the context of the Glasgow Haskell Compiler, an optimising compiler for Haskell. In particular, we recently re-engineered the existing strictness analyser that used forward abstract interpretation, replacing it with a new one that uses backward analysis instead.

This unpublished draft is better explained, and much closer to the actual implementation in GHC, than our earlier version.},
url = {https://www.microsoft.com/en-us/research/publication/theory-practice-demand-analysis-haskell/},
note = {Unpublished draft},
}
@phdthesis{sansom1994execution,
author = {Sansom, Patrick and Peyton Jones, Simon},
title = {Execution profiling for non-strict functional languages},
organization = {University of Glasgow},
year = {1994},
month = {September},
abstract = {Profiling tools, which measure and display the dynamic space and time behaviour of programs, are essential for identifying execution bottlenecks. A variety of such tools exist for conventional languages, but almost none for non-strict functional languages. There is a good reason for this: lazy evaluation means that the program is executed in an order which is not immediately apparent from the source code, so it is difficult to relate dynamically-gathered statistics back to the original source.
This thesis examines the difficulties of profiling lazy higher-order functional languages and develops a profiling tool which overcomes them. It relates information about both the time and space requirements of the program back to the original source expressions identified by the programmer. Considerable attention is paid to the cost semantics with two abstract cost semantics, lexical scoping and evaluation scoping, being investigated.
Experience gained from the two profiling schemes led to the development of a hybrid cost semantics. All three schemes are described and compared in a single formal framework.
These abstract cost semantics are mapped onto an operational semantics and an implementation based on the STG-machine is developed. The manipulation of cost centres is made precise by extending the state-transition operational semantics of the STG-machine.
The profiling tool has been incorporated into the Glasgow Haskell compiler ghc. Our approach preserves the correct cost attribution of costs while allowing program optimisation to proceed largely unhindered. So far as we know ghc is the only lazy functional language compiler to support source-level time profiling. The use of the profiler has lead to significant performance improvements in the compiler itself and other large application programs.
[NB: I have listed myself as an author only so that it appears on my home page; it is Patrick's thesis.]},
url = {https://www.microsoft.com/en-us/research/publication/execution-profiling-non-strict-functional-languages/},
}
@phdthesis{santos1995compilation,
author = {Santos, Andre and Peyton Jones, Simon},
title = {Compilation by transformation for non-strict functional languages},
organization = {University of Glasgow},
year = {1995},
month = {July},
abstract = {In this thesis we present and analyse a set of automatic source-to-source program transformations that are suitable for incorporation in optimising compilers for lazy functional languages.  These transformations improve the quality of code in many different respects, such as execution time and memory usage.

The transformations presented are divided into two sets: global transformations, which are performed once (or perhaps twice) during compilation; and a set of local transformations with are performed before and after each of the global transformations, so that they can simplify the code before applying the global transformations, and take advantage of them afterwards.

Many of the local transformations are simple, well known, and do not have major effects on their own.  They become important as they interact with each other and with global transformations, sometimes in non-obvious ways.  We present how and why they improve the code, and perform extensive experiments with real application programs.

We describe four global transformations, two of which have not been used in any lazy functional compiler we know of: the static argument transformations and let-floating transformations.  The other two are well known for lazy functional languages, but no major studies of their effects have been performed: full laziness and lambda lifting.  We also study and measure the effects of different inlining strategies.

We also present a Cost Semantics as a way to reason about the effects of program transformations in lazy functional languages.

[I have listed myself as an author only so that this thesis appears on my home page; it is Andre's thesis!]},
url = {https://www.microsoft.com/en-us/research/publication/compilation-transformation-non-strict-functional-languages/},
}
@inproceedings{serrano2018guarded,
author = {Serrano, Alejandro and Hage, Jurriaan and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Guarded impredicative polymorphism},
booktitle = {Proc ACM SIGPLAN Conference on Programming Languages Design and Implementation (PLDI'18)},
year = {2018},
month = {June},
abstract = {The design space for type systems that support impredicative instantiation is extremely complicated, in which one needs to strike a balance between expressiveness, simplicity for both the end programmer and the type system implementor, and how easily the system can be integrated with other advanced type system concepts. In this paper, we propose a new point in the design space, which we call guarded impredicativity. Its key idea is that impredicative instantiation in an application is allowed for type variables that occur under a type constructor.

The resulting type system has a clean declarative specification --- making it easy for programmers to predict what will type and what will not --- allows for a smooth integration with GHC's OutsideIn(X) constraint solving framework, while giving up very little in terms of expressiveness compared to systems like HMF, HML, FPH and MLF. We give a sound and complete inference algorithm, and prove a principal type property for our system.

The PDF is for an extended version of the PLDI 2018 paper, including some Appendices.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/guarded-impredicative-polymorphism/},
}
@article{zhang2017sherrloc,
author = {Zhang, Danfeng and Myers, Andrew C and Peyton Jones, Simon and Vytiniotis, Dimitrios},
title = {SHErrLoc: a static holistic error locator},
year = {2017},
month = {August},
abstract = {We introduce a general way to locate programmer mistakes that are detected by static analyses. The program analysis is expressed in a general constraint language that is powerful enough to model type checking, information flow analysis, dataflow analysis, and points-to analysis. Mistakes in program analysis result in unsatisfiable constraints. Given an unsatisfiable system of constraints, both satisfiable and unsatisfiable constraints are analyzed to identify the program expressions most likely to be the cause of unsatisfiability. The likelihood of different error explanations is evaluated under the assumption that the programmer’s code is mostly correct, so the simplest explanations are chosen, following Bayesian principles. For analyses that rely on programmer-stated assumptions, the diagnosis also identifies assumptions likely to have been omitted.
The new error diagnosis approach has been implemented as a tool called SHErrLoc, which is applied to three very different program analyses, such as type inference for a highly expressive type system implemented by the Glasgow Haskell Compiler—including type classes, Generalized Algebraic Data Types (GADTs), and type families. The effectiveness of the approach is evaluated using previously collected programs containing errors. The results show that when compared to existing compilers and other tools, SHErrLoc consistently identifies the location of programmer errors significantly more accurately, without any language-specific heuristics.
This is a journal version of our earlier conference paper Diagnosing Type Errors With Class (PLDI'15).},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/sherrloc-static-holistic-error-locator/},
journal = {Transactions on Programming Languages and Systems},
volume = {34},
number = {4},
}
@inproceedings{bernardy2018linear,
author = {Bernardy, Jean-Philippe and Boespflug, Mathieu and Newton, Ryan R. and Peyton Jones, Simon and Spiwack, Arnaud},
title = {Linear Haskell: practical linearity in a higher-order polymorphic language},
booktitle = {Principles of Programming Languages 2018 (POPL 2018)},
year = {2018},
month = {January},
abstract = {Linear type systems have a long and storied history, but not a clear path forward to integrate with existing languages such as OCaml or Haskell. In this paper, we study a linear type system designed with two crucial properties in mind: backward-compatibility and code reuse across linear and non-linear users of a library. Only then can the benefits of linear types permeate conventional functional programming. Rather than bifurcate types into linear and non-linear counterparts, we instead attach linearity to function arrows. Linear functions can receive inputs from linearly-bound values, but can also operate over unrestricted, regular values.

To demonstrate the efficacy of our linear type system - both how easy it can be integrated into an existing language implementation and how streamlined it makes it to write programs with linear types - we implemented our type system in GHC, the leading Haskell compiler, and demonstrate two kinds of applications of linear types: mutable data with pure interfaces; and enforcing protocols in I/O-performing functions.

Here is my talk at Curry On, July 2018},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/linear-haskell-practical-linearity-higher-order-polymorphic-language/},
}
@inproceedings{mokhov2018build,
author = {Mokhov, Andrey and Mitchell, Neil and Peyton Jones, Simon},
title = {Build systems a la carte},
booktitle = {Proc International Conference on Functional Programming (ICFP'18)},
year = {2018},
month = {September},
abstract = {Build systems are awesome, terrifying -- and unloved. They are used by every developer around the world, but are rarely the object of study. In this paper we offer a systematic, and executable, framework for developing and comparing build systems, viewing them as related points in landscape rather than as isolated phenomena. By teasing apart existing build systems, we can recombine their components, allowing us to prototype new build systems with desired properties.

All the code is available in this Git repository, and also as a Hackage library.

An expanded journal version of this paper is available (JFP, 2020)},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/},
}
@article{breitner2016safe,
author = {Breitner, Joachim and Eisenberg, Richard and Peyton Jones, Simon and Weirich, Stephanie},
title = {Safe zero-cost coercions for Haskell},
year = {2016},
month = {July},
abstract = {Generative type abstractions – present in Haskell, OCaml, and other languages – are useful concepts to help prevent programmer errors. They serve to create new types that are distinct at compile time but share a run-time representation with some base type. We present a new mechanism that allows for zero-cost conversions between generative type abstractions and their representations, even when such types are deeply nested. We prove type safety in the presence of these conversions and have implemented our work in GHC.
This is a journal version of our earlier ICFP 2014 paper of the same title.
 },
publisher = {Cambridge University Press},
url = {https://www.microsoft.com/en-us/research/publication/safe-zero-cost-coercions-haskell/},
journal = {Journal of Functional Programming},
volume = {26},
}
@inproceedings{eisenberg2018type,
author = {Eisenberg, Richard and Breitner, Joachim and Peyton Jones, Simon},
title = {Type variables in patterns},
booktitle = {Proc ACM Haskell Symposium (Haskell '18)},
year = {2018},
month = {September},
abstract = {For many years, GHC has implemented an extension to Haskell that allows type variables to be bound in type signatures and patterns, and to scope over terms. This extension was never properly specified. We rectify that oversight here. With the formal specification in hand, the otherwise-labyrinthine path toward a design for binding type variables in patterns becomes blindingly clear. We thus extend ScopedTypeVariables to bind type variables explicitly, obviating the Proxy workaround to the dustbin of history.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/type-variables-patterns/},
}
@inproceedings{sarkar2018calculation,
author = {Sarkar, Advait and Gordon, Andy and Peyton Jones, Simon and Toronto, Neil},
title = {Calculation View: multiple-representation editing in spreadsheets},
booktitle = {IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
year = {2018},
month = {October},
abstract = {Spreadsheet errors are ubiquitous and costly, an unfortunate combination that is well-reported. A large class of these errors can be attributed to the inability to clearly see the underlying computational structure, as well as poor support for abstraction (encapsulation, re-use, etc). In this paper we propose a novel solution: a multiple-representation spreadsheet containing additional representations that allow abstract operations, without altering the conventional grid representation or its formula syntax. Through a user study, we demonstrate that the use of multiple representations can significantly improve user performance when performing spreadsheet authoring and debugging tasks. We close with a discussion of design implications and outline future directions for this line of inquiry.},
publisher = {IEEE},
url = {https://www.microsoft.com/en-us/research/publication/calculation-view-multiple-representation-editing-in-spreadsheets/},
pages = {85-93},
}
@article{mccutchen2020elastic,
author = {McCutchen, Matt and Borghouts, Judith and Gordon, Andy and Peyton Jones, Simon and Sarkar, Advait},
title = {Elastic Sheet-Defined Functions: Generalising Spreadsheet Functions to Variable-Size Input Arrays},
year = {2020},
month = {August},
abstract = {Sheet-defined functions (SDFs) bring modularity and abstraction to the world of spreadsheets. Alas, end users naturally write SDFs that work over fixed-size arrays, which limits their re-usability. To help end user programmers write more re-usable SDFs, we describe a principled approach to generalising such functions to become elastic SDFs that work over inputs of arbitrary size. We prove that under natural, checkable conditions our algorithm returns the principal generalisation of an input SDF. We describe a formal semantics and several efficient implementation strategies for elastic SDFs. A user study with spreadsheet users compares the human experience of programming with elastic SDFs to the alternative of relying on array processing combinators. Our user study finds that the cognitive load of elastic SDFs is lower than for SDFs with map/reduce array combinators, the closest alternative solution.},
url = {https://www.microsoft.com/en-us/research/publication/elastic-sheet-defined-functions-generalising-spreadsheet-functions-to-variable-size-input-arrays/},
journal = {Journal of Functional Programming},
volume = {30},
number = {e26},
}
@inproceedings{kiss2019higher-order,
author = {Kiss, Csongor and Eisenbach, Susan and Field, Tony and Peyton Jones, Simon},
title = {Higher-order type-level programming in Haskell},
booktitle = {International Conference on Functional Programming (ICFP'19)},
year = {2019},
month = {August},
abstract = {Type family applications in Haskell must be fully saturated. This means that all type-level functions have to be first-order, leading to code that is both messy and longwinded. In this paper we detail an extension to GHC that removes this restriction. We augment Haskell's existing type arrow, (->), with an  unmatchable arrow, (~>), that supports partial application of type families without compromising soundness. A soundness proof is provided.

We show how the techniques described can lead to substantial code-size reduction (circa 80%) i the type-level logic of commonly-used type-level libraries whilst simultaneously improving code quality and readability.

 },
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/higher-order-type-level-programming-in-haskell/},
}
@inproceedings{downen2019making,
author = {Downen, Paul and Sullivan, Zachary and Ariola, Zena and Peyton Jones, Simon},
title = {Making a faster curry with extensional types},
booktitle = {Haskell Symposium},
year = {2019},
month = {August},
abstract = {Curried functions apparently take one argument at a time, which is slow. So optimizing compilers for higher-order languages invariably have some mechanism for working around currying by passing several arguments at once, as many as the function can handle, which is known as its arity. But such mechanisms are often ad-hoc, and do not work at all in higher-order functions. We show how extensional, call-by-name functions have the correct behaviour for directly expressing the arity of curried functions. And these extensional functions can stand side-by-side with functions native to practical programming languages, which do not use call-by-name evaluation. Integrating call-by-name with other evaluation strategies in the same intermediate language expresses the arity of a function in its type and gives a principled and compositional account of multi-argument curried functions. An unexpected, but significant, bonus is that our approach is equally suitable for a call-by-value language and a call-by-need language, and it can be readily integrated into an existing compilation framework},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/making-a-faster-curry-with-extensional-types/},
pages = {58-70},
}
@inproceedings{shaikhha2019efficient,
author = {Shaikhha, Amir and Fitzgibbon, Andrew and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Efficient differentiable programming in a functional array-processing language},
booktitle = {International Conference on Functional Programming (ICFP'19)},
year = {2019},
month = {July},
abstract = {We present a system for the automatic differentiation (AD) of a higher-order functional array-processing language. The core functional language underlying this system simultaneously supports both source-to-source forward-mode AD and global optimisations such as loop transformations. In combination, gradient computation with forward-mode AD can be as efficient as reverse mode, and that the Jacobian matrices required for numerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be efficiently computed.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/efficient-differentiable-programming-in-a-functional-array-processing-language/},
}
@misc{peytonjones2019type,
author = {Peyton Jones, Simon},
title = {Type inference as constraint solving: how GHC's type inference engine actually works},
howpublished = {Zurihac keynote talk},
year = {2019},
month = {June},
abstract = {The Haskell compiler GHC includes a type inference engine for a rather sophisticated type system.  You might worry that a complicated type system leads to a very complicated type inference engine.   You'd be right, but we have learned a lot about how to structure type inference so that the complexity does not get out of control.

In this talk, given at Zurihac 2019, I explain how GHC's type inference engine actually works by first generating constraints and then solving them.

Here are

 	Video of my talk at ZuriHac 2019, sadly missing the end part of the talk
 	Video of the same talk at Lambdale 2019 (in a pub!)
 	Slides from the talk

 

 

 },
url = {https://www.microsoft.com/en-us/research/publication/type-inference-as-constraint-solving-how-ghcs-type-inference-engine-actually-works/},
}
@inproceedings{downen2019codata,
author = {Downen, Paul and Sullivan, Zachary and Ariola, Zena and Peyton Jones, Simon},
title = {Codata in action},
booktitle = {European Symposium on Programming (ESOP'19)},
year = {2019},
month = {April},
abstract = {Computer scientists are well-versed in dealing with data structures. The same cannot be said about their dual: codata. Even though codata is pervasive in category theory, universal algebra, and logic, the use of codata for programming has been mainly relegated to representing infinite objects and processes. Our goal is to demonstrate the benefits of codata as a general-purpose programming abstraction independent of any specific language: eager or lazy, statically or dynamically typed, and functional or object-oriented. While codata is not featured in many programming languages today, we show how codata can be easily adopted and implemented by offering simple inter-compilation techniques between data and codata. We believe codata is a common ground between the functional and object-oriented paradigms; ultimately, we hope to utilize the Curry-Howard isomorphism to further bridge the gap.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/codata-in-action/},
pages = {119-146},
}
@inproceedings{serrano2020a,
author = {Serrano, Alejandro and Hage, Jurriaan and Peyton Jones, Simon and Vytiniotis, Dimitrios},
title = {A quick look at impredicativity},
organization = {ACM},
booktitle = {International Conference on Functional Programming (ICFP'20)},
year = {2020},
month = {August},
abstract = {Type inference for parametric polymorphism is wildly successful, but has always suffered from an embarrassing flaw: polymorphic types are themselves not first class. We present Quick Look, a practical, implemented, and deployable design for impredicative type inference. To demonstrate our claims, we have modified GHC, a production-quality Haskell compiler, to support impredicativity.  The changes required are modest, localised, and are fully compatible with GHC's myriad other type system extensions.

Here is a video of Simon giving a talk on the ideas in the paper

 },
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/a-quick-look-at-impredicativity/},
}
@inproceedings{vytiniotis2012equality,
author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Magalhães, José Pedro},
title = {Equality proofs and deferred type errors},
organization = {ACM},
booktitle = {International Conference on Functional Programming (ICFP'12)},
year = {2012},
month = {September},
abstract = {The Glasgow Haskell Compiler is an optimizing compiler that expresses and manipulates first-class equality proofs in its intermediate language. We describe a simple, elegant technique that exploits these equality proofs to support deferred type errors. The technique requires us to treat equality proofs as possibly-divergent terms; we show how to do so without losing either soundness or the zero-overhead cost model that the programmer expects.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/equality-proofs-and-deferred-type-errors/},
pages = {341-352},
}
@inproceedings{downen2020kinds,
author = {Downen, Paul and Ariola, Zena and Peyton Jones, Simon and Eisenberg, Richard},
title = {Kinds are calling conventions},
organization = {ACM},
booktitle = {International Conference on Functional Programming (ICFP'20)},
year = {2020},
month = {August},
abstract = {A language supporting polymorphism is a boon to programmers: they can express complex ideas once and reuse functions in a variety of situations. However, polymorphism is pain for compilers tasked with producing efficient code that manipulates concrete values.

This paper presents a new intermediate language that allows efficient static compilation, while still supporting flexible polymorphism. Specifically, it permits polymorphism over not only the types of values, but also the representation of values, the arity of machine functions, and the evaluation order of arguments---all three of which are useful in practice. The key insight is to encode information about a value's calling convention in the kind of its type, rather than in the type itself.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/kinds-are-calling-conventions/},
}
@inproceedings{peytonjones2020lower,
author = {Peyton Jones, Simon and Graf, Sebastian and Scott, Ryan},
title = {Lower your guards: a compositional pattern-match coverage checker},
organization = {ACM},
booktitle = {International Conference on Functional Programming (ICFP'20)},
year = {2020},
month = {August},
abstract = {One of a compiler's roles is to warn if a function defined by pattern matching does not cover its inputs---that is, if there are missing or redundant patterns. Generating such warnings accurately is difficult for modern languages due to the myriad of interacting language features when pattern matching. This is especially true in Haskell, a language with a complicated pattern language that is made even more complex by extensions offered by the Glasgow Haskell Compiler (GHC). Although GHC has spent a significant amount of effort towards improving its pattern-match coverage warnings, there are still several cases where it reports inaccurate warnings.

We introduce a coverage checking algorithm called Lower Your Guards, which boils down the complexities of pattern matching into guard trees.  While the source language may have many exotic forms of patterns, guard trees only have three different constructs, which vastly simplifies the coverage checking process. Our algorithm is modular, allowing for new forms of source-language patterns to be handled with little changes to the overall structure of the algorithm. We have implemented the algorithm in GHC and demonstrate places where it performs better than GHC's current coverage checker, both in accuracy and performance.

Here is a video of Simon giving a talk about this work at Code Mesh 2019},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/lower-your-guards-a-compositional-pattern-match-coverage-checker/},
}
@article{mokhov2020build,
author = {Mokhov, Andrey and Mitchell, Neil and Peyton Jones, Simon},
title = {Build systems a la carte: theory and practice},
year = {2020},
month = {April},
abstract = {Build systems are awesome, terrifying – and unloved. They are used by every developer around the world, but are rarely the object of study. In this paper we offer a systematic, and executable, framework for developing and comparing build systems, viewing them as related points in a landscape rather than as isolated phenomena. By teasing apart existing build systems, we can recombine their components, allowing us to prototype new build systems with desired properties.
This is a revised and expanded journal version of our ICFP'18 paper "Build systems a la carte", with more detail and a new section on our experience of turning theory into practice.

Executable code is available here.},
url = {https://www.microsoft.com/en-us/research/publication/build-systems-a-la-carte/},
journal = {Journal of Functional Programming},
volume = {30},
number = {E11},
note = {https://doi.org/10.1017/S0956796820000088},
}
@misc{wang2020diagnostic,
author = {Wang, Zichao and Lamb, Angus and Saveliev, Evgeny and Cameron, Pashmina and Zaykov, Yordan and Hernandez Lobato, Jose Miguel  and Turner, Richard  and Baraniuk, Richard and Barton, Craig and Peyton Jones, Simon and Woodhead, Simon and Zhang, Cheng},
title = {Diagnostic Questions: The NeurIPS 2020 Education Challenge},
year = {2020},
month = {July},
abstract = {Digital technologies are becoming increasingly prevalent in education, enabling personalized, high quality education resources to be accessible by students across the world. Importantly, among these resources are diagnostic questions: the answers that the students give to these questions reveal key information about the specific nature of misconceptions that the students may hold. Analyzing the massive quantities of data stemming from students' interactions with these diagnostic questions can help us more accurately understand the students' learning status and thus allow us to automate learning curriculum recommendations. In this competition, participants will focus on the students' answer records to these multiple-choice diagnostic questions, with the aim of 1) accurately predicting which answers the students provide; 2) accurately predicting which questions have high quality; and 3) determining a personalized sequence of questions for each student that best predicts the student's answers. These tasks closely mimic the goals of a real-world educational platform and are highly representative of the educational challenges faced today. We provide over 20 million examples of students' answers to mathematics questions from Eedi, a leading educational platform which thousands of students interact with daily around the globe. Participants to this competition have a chance to make a lasting, real-world impact on the quality of personalized education for millions of students across the world.},
url = {https://www.microsoft.com/en-us/research/publication/diagnostic-questions-the-neurips-2020-education-challenge/},
}
@inproceedings{maziarz2021hashing,
author = {Maziarz, Krzysztof and Ellis, Tom and Lawrence, Alan and Fitzgibbon, Andrew and Peyton Jones, Simon},
title = {Hashing Modulo Alpha-Equivalence},
organization = {ACM},
booktitle = {ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI'21)},
year = {2021},
month = {June},
abstract = {In many applications one wants to identify identical subtrees of a program syntax tree.  This identification should ideally be robust to alpha-renaming of the program, but no existing technique has been shown to achieve this with good efficiency (better than O(n^2) in expression size). We present a new, asymptotically efficient way to hash modulo alpha-equivalence. A key insight of our method is to use a weak (commutative) hash combiner at exactly one point in the construction, which admits an algorithm with O(n*(log n)^2) time complexity. We prove that the use of the commutative combiner nevertheless yields a strong hash with low collision probability.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/hashing-modulo-alpha-equivalence-2/},
}
@inproceedings{wang2021results,
author = {Wang, Zichao and Lamb, Angus and Saveliev, Evgeny and Zaykov, Yordan and Cameron, Pashmina and Hernandez-Lobato,  Jose Miguel and Turner, Richard E. and Baraniuk,  Richard G. and Peyton Jones, Simon and Barton,  Craig and Woodhead,  Simon and Zhang, Cheng},
title = {Results and Insights from Diagnostic Questions: The NeurIPS 2020 Education Challenge},
booktitle = {NeurIPS Competition},
year = {2021},
month = {April},
abstract = {This competition concerns educational diagnostic questions, which are pedagogically effective, multiple-choice questions (MCQs) whose distractors embody misconceptions. With a large and ever-increasing number of such questions, it becomes overwhelming for teachers to know which questions are the best ones to use for their students. We thus seek to answer the following question: how can we use data on hundreds of millions of answers to MCQs to drive automatic personalized learning in large-scale learning scenarios where manual personalization is infeasible? Success in using MCQ data at scale helps build more intelligent, personalized learning platforms that ultimately improve the quality of education en masse. To this end, we introduce a new, large-scale, real-world dataset and formulate 4 data mining tasks on MCQs that mimic real learning scenarios and target various aspects of the above question in a competition setting at NeurIPS 2020. We report on our NeurIPS competition in which nearly 400 teams submitted approximately 4000 submissions, with encouragingly diverse and effective approaches to each of our tasks},
url = {https://www.microsoft.com/en-us/research/publication/results-and-insights-from-diagnostic-questions-the-neurips-2020-education-challenge/},
note = {To appear in PMLR proceeding of NeurIPS competition},
}
@techreport{morales-alvarez2021vicause,
author = {Morales-Alvarez, Pablo and Lamb, Angus and Woodhead, Simon and Peyton Jones, Simon and Allamanis, Miltos and Zhang, Cheng},
title = {VICAUSE: Simultaneous missing value imputation and causal discovery},
institution = {ICML 2021 workshop on the Neglected Assumptions in Causal Inference},
year = {2021},
month = {July},
abstract = {Missing values constitute an important challenge in real-world machine learning for both prediction and causal discovery tasks. However, only few methods in causal discovery can handle missing data in an efficient way, while existing imputation methods are agnostic to causality. In this work we propose VICAUSE, a novel approach to simultaneously tackle missing value imputation and causal discovery efficiently with deep learning. Particularly, we propose a generative model with a structured latent space and a graph neural network-based architecture, scaling to large number of variables. Moreover, our method can discover relationship between groups of variables which is useful in many real-world applications. VICAUSE shows improved performance compared to popular and recent approaches in both missing value imputation and causal discovery.},
url = {https://www.microsoft.com/en-us/research/publication/vicause-simultaneous-missing-value-imputation-and-causal-discovery/},
number = {MSR-TR-2021-14},
}
@unpublished{peytonjones2021triemaps,
author = {Peyton Jones, Simon and Eisenberg, Richard and Graf, Sebastian},
title = {Triemaps that match},
year = {2021},
month = {July},
abstract = {In applications such as compilers and theorem provers, we often want to match
a target term against multiple patterns (representing rewrite rules or axioms)
simultaneously. Efficient matching of this kind is well studied in the theorem prover
community, but much less so in the context of statically typed functional programming.
Doing so yields an interesting new viewpoint --- and a practically useful design
pattern, with good runtime performance.},
url = {https://simon.peytonjones.org/triemaps-that-match/},
note = {In submission},
}
@inproceedings{krawiec2021provably,
author = {Krawiec, Faustyna and Krishnaswami, Neel and Peyton Jones, Simon and Ellis, Tom and Fitzgibbon, Andrew and Eisenberg, Richard},
title = {Provably correct, asymptotically efficient, higher-order reverse-mode automatic differentiation},
booktitle = {POPL 2022},
year = {2021},
month = {August},
abstract = {In this paper, we give a simple and efficient implementation of reverse-mode automatic differentiation, which both extends easily to higher-order functions, and has run time and memory consumption linear in the run time of the original program. In addition to a formal description of the translation, we also describe an implementation of this algorithm, and prove its correctness by means of a logical relations argument.

Here is a video of Simon giving a talk about the paper.},
url = {https://www.microsoft.com/en-us/research/publication/provably-correct-asymptotically-efficient-higher-order-reverse-mode-automatic-differentiation/},
}